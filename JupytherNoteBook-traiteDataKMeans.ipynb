{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebook -traiteDataKMeans- Alexandre TABOT - Stagiaire Labo LIUM M2 Info ATAL -\n",
    "\n",
    "\n",
    "solution 01\n",
    "adresse site des td\n",
    "https://hebdo.framapad.org/p/m2ataltd1\n",
    "\n",
    "\n",
    "------------------------------------------------\n",
    "import pandas as pd\n",
    "pd.__version__\n",
    "\n",
    "    **Its double underscore before and after the word \"version\".\n",
    " \n",
    "---------------------------------------------------\n",
    "notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "commande installation des bibliotheques et autre\n",
    "\n",
    "#pip install --upgrade pip\n",
    "#!pip install mglearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des bibliotheques classiques Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importation des bibliotheques : OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "##import\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import scipy as sp\n",
    "import IPython\n",
    "import sklearn\n",
    "import mglearn\n",
    "import PIL\n",
    "import graphviz\n",
    "\n",
    "from scipy import sparse\n",
    "from IPython.display import display\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image as ImgPIL\n",
    "from IPython.display import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "\n",
    "#from mglearn.tools import discrete_scatter\n",
    "#from mglearn.plot_2d_separator import plot_2d_classification\n",
    "#from mglearn.plot_helpers import cm3\n",
    "\n",
    "##import propres au projet\n",
    "import string\n",
    "import csv\n",
    "import pickle\n",
    "import argparse\n",
    "import copy\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import xlwt\n",
    "import xlsxwriter\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "##Telerchargement package\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "\n",
    "print('Importation des bibliotheques : OK')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpusStringToFloat(corpusString) :\n",
    "    #Converti un corpus audioProsodie de un fichier vers une matrice corpus load corpusLoadTabDesAudio\n",
    "    \n",
    "    #Bibliotheques\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #Variables\n",
    "    corpusLoadTabDesAudio =[]\n",
    "    listFeatF0 =[]\n",
    "    listFeatMfcc =[]\n",
    "    listFeatSpRa =[]\n",
    "    listMfccMoy =[]\n",
    "    listMfccStd =[]\n",
    "    listMfccMax=[]\n",
    "    listMfccMin = []\n",
    "    listVectProsodie =[]\n",
    "    floatFeatDuree =0.0\n",
    "    nbDimTransforme = 4\n",
    "    nbDimUnFeat = 1\n",
    "    nbDimMfcc = 13\n",
    "    nbVal = 61\n",
    "    intIndiceDebut = 0\n",
    "    intIndiceFin = 0\n",
    "    intNbDecimale = 2\n",
    "    \n",
    "    #Corps\n",
    "    for vecteur in corpusString :\n",
    "        #Boucle de parcours de structure de donnees a 2 niveaux (dimension) classique en Machine Learning\n",
    "        vectFloat=[]\n",
    "        intIndiceDebut = 0\n",
    "        intIndiceFin = 0\n",
    "        for feature in vecteur :\n",
    "            try :\n",
    "                vectFloat.append(round(float(feature), intNbDecimale))\n",
    "            except :\n",
    "                print('feature-->', feature)\n",
    "            \n",
    "        #print('vectFloat-->', vectFloat)\n",
    "        # Reconstruction des features\n",
    "        intIndiceFin = intIndiceFin + nbDimTransforme\n",
    "        listFeatF0 = deepcopy(vectFloat[intIndiceDebut:intIndiceFin])\n",
    "        #print('listFeatF0-->', listFeatF0)\n",
    "        intIndiceDebut = intIndiceFin\n",
    "        intIndiceFin = intIndiceFin + nbDimMfcc\n",
    "        listMfccMoy = deepcopy(vectFloat[intIndiceDebut:intIndiceFin])\n",
    "        #print('listMfccMoy-->', listMfccMoy)\n",
    "        intIndiceDebut = intIndiceFin\n",
    "        intIndiceFin = intIndiceFin + nbDimMfcc\n",
    "        listMfccStd = deepcopy(vectFloat[intIndiceDebut:intIndiceFin])\n",
    "        #print('listMfccStd-->', listMfccStd)\n",
    "        intIndiceDebut = intIndiceFin\n",
    "        intIndiceFin = intIndiceFin + nbDimMfcc\n",
    "        listMfccMax = deepcopy(vectFloat[intIndiceDebut:intIndiceFin])\n",
    "        #print('listMfccMax-->', listMfccMax)\n",
    "        intIndiceDebut = intIndiceFin\n",
    "        intIndiceFin = intIndiceFin + nbDimMfcc\n",
    "        listMfccMin = deepcopy(vectFloat[intIndiceDebut:intIndiceFin])\n",
    "        #print('listMfccMin-->', listMfccMin)\n",
    "        #print('intIndiceFin-->', intIndiceFin)\n",
    "        #Reconstruction de la matrice de la feature des MFCC\n",
    "        listFeatMfcc = deepcopy([listMfccMoy, listMfccStd, listMfccMax, listMfccMin])\n",
    "        #print('listFeatMfcc-->', listFeatMfcc)\n",
    "        intIndiceDebut = intIndiceFin\n",
    "        intIndiceFin = intIndiceFin + nbDimTransforme\n",
    "        listFeatSpRa = deepcopy(vectFloat[intIndiceDebut:intIndiceFin])\n",
    "        #print('intIndiceFin-->', intIndiceFin)\n",
    "        #print('listFeatSpRa-->', listFeatSpRa)\n",
    "        #print('vectFloat-->',vectFloat)\n",
    "        #Recuperation de la duree de parole\n",
    "        floatFeatDuree = deepcopy(vectFloat[intIndiceFin])\n",
    "        #print('floatFeatDuree-->',floatFeatDuree)\n",
    "        #Reconctruction du vecteur de prosodie\n",
    "        listVectProsodie = deepcopy([listFeatF0, listFeatMfcc, listFeatSpRa, floatFeatDuree])\n",
    "        #print('listVectProsodie-->', listVectProsodie)\n",
    "        #Ajout au corpus retourne\n",
    "        corpusLoadTabDesAudio.append(deepcopy(listVectProsodie))\n",
    "        #print('corpusLoadTabDesAudio-->', corpusLoadTabDesAudio)\n",
    "        #sys.exit()\t\n",
    "    return corpusLoadTabDesAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpusStringToArray(corpusString) :\n",
    "    #Transforme un corpus save en string vers une array (pour kmeans)\n",
    "    \n",
    "    #Variables\n",
    "    corpusLoadArray = []\n",
    "    vectFloat=[]\n",
    "    intNbDecimale = 2\n",
    "    #Corps\n",
    "    for vecteur in corpusString :\n",
    "        #Boucle de parcours des niveaux du corpus\n",
    "        vectFloat=[]\n",
    "        for feature in vecteur :\n",
    "            try :\n",
    "                vectFloat.append(round(float(feature), intNbDecimale))\n",
    "            except :\n",
    "                print('featureInvalid-->', feature)\n",
    "        #Ajout du vecteur transforme de float au corpus de retour de fonction\n",
    "        corpusLoadArray.append(vectFloat)\n",
    "    \n",
    "    return corpusLoadArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplanirListMiltiDimToMonoDim(listMultiDim) :\n",
    "    #Aplanit une liste\n",
    "    \n",
    "    #corps\n",
    "    listPlate = sum(listMultiDim, [])\n",
    "    return listPlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retirerListeL2deListeL1(listL1, listL2) :\n",
    "    #Renvoie une liste qui est la listL1 retirer des element de listL2\n",
    "    \n",
    "    #bibliotheques necessaires\n",
    "    import copy\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #variables de la fonction\n",
    "    listDiff = deepcopy(listL1)\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    try :\n",
    "        #essai sur liste de meme nombre de dimensions\n",
    "        for elemSoustrait in listL2 :\n",
    "            #Boucle de parcours des elements a retirer\n",
    "            if elemSoustrait in listDiff :\n",
    "                #Verification de la presence de element elemSoustrait pour le soustraire\n",
    "                listDiff.remove(elemSoustrait)\n",
    "            \n",
    "    except :\n",
    "        print('Erreur de cohereance de dimensions des parametres de la fonction retirerListeL2deListeL1')\n",
    "        print('Retour liste vide')\n",
    "        return []\n",
    "    \n",
    "    #retour de la fonction\n",
    "    return listDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtListSelectVectFromListCorpus(listCorpus, listIndicesSelectVect) :\n",
    "    #Renvoie une liste de vecteurs selectionnes selon une liste de indices de vecteur a partir de un corpus\n",
    "    \n",
    "    #Bibliotheques\n",
    "    import numpy as np\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #Variables\n",
    "    listVectSelect = []\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    for indiceVect in listIndicesSelectVect :\n",
    "        #Boucle de parcours des indices de vecteurs selectionnes\n",
    "        listVectSelect.append(listCorpus[indiceVect])\n",
    "    \n",
    "    return listVectSelect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtCalibreArrayFromListCorpus(listCorpus, intCoteDimVect, intCoteDimMatrice, intPosFeature) :\n",
    "    #Renvoie une array calibree de la feature en position intPosFeature du vecteur, a partir de une liste Corpus a 2 dimension\n",
    "    \n",
    "    #Bibliotheques\n",
    "    import numpy as np\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #Variables\n",
    "    listVectCote = []\n",
    "    listArrayCalibree = []\n",
    "    intCptCoteVect = 0\n",
    "    intNbMinKmeans = 2\n",
    "    \n",
    "    #Corps\n",
    "    print(\"debut de la verification de la fonction builtCalibreArrayFromListCorpus\")\n",
    "    \n",
    "    #Feature F0 : [:] [3] constituee de vecteur de 4 elements\n",
    "    #Transfert de un nombre definit de elements pour le vecteur constitutif de array ( liste de vecteur)\n",
    "    #Reinitialisation avant boucle\n",
    "    for vectConstituant in listCorpus :\n",
    "            #Reinitialisation avant boucle\t\n",
    "        intCptCoteVect =0 \n",
    "        listVectCote = []\n",
    "        \n",
    "        #Traitement nature variable possible de vectConstituant\n",
    "        #Cas vectConstituant est une seule valeur\n",
    "        if(intCoteDimVect < intNbMinKmeans) :\n",
    "            #Verification valeur unique du vecteur constituant\n",
    "            #Ajout direct de la valeur a la liste calibree listArrayCalibree\n",
    "            listArrayCalibree.append(deepcopy(vectConstituant[intPosFeature]))\n",
    "        else :\n",
    "            #Cas General taille vectConstituant > 1, vectConstituant est iterable\n",
    "            for element in vectConstituant[intPosFeature] :\n",
    "                #Boucle de transfert avec double verification\n",
    "                #print('intCptCoteVect-->', intCptCoteVect)\n",
    "                if intCptCoteVect <intCoteDimVect :\n",
    "                    listVectCote.append(element)\n",
    "                    intCptCoteVect += 1\n",
    "                \n",
    "                if intCptCoteVect == intCoteDimVect :\n",
    "                    #print('Ajout de listVectCote a listArrayCalibree')\n",
    "                    listArrayCalibree.append(deepcopy(listVectCote))\n",
    "                    listVectCote =[]\n",
    "                    intCptCoteVect = intCptCoteVect + 1\n",
    "                \n",
    "        \n",
    "    npArrayCalibree = np.array(listArrayCalibree)\n",
    "    #Verification finale du calibrage de array\n",
    "    tupleDimArray = npArrayCalibree.shape\n",
    "    print('tupleDimArray-->', tupleDimArray)\n",
    "    \n",
    "    #Traitement nature variable possible de vectConstituant\n",
    "    \n",
    "    #Cas Valeur Unique\n",
    "    if(intCoteDimVect < intNbMinKmeans) :\n",
    "        #Verification valeur unique du vecteur constituant\n",
    "        if tupleDimArray[0] == intCoteDimMatrice :\n",
    "            #Verification correspondance taille de matrice\n",
    "            return npArrayCalibree\n",
    "        else :\n",
    "            print('Erreur de calibrage de la fonction builtCalibreArrayFromListCorpus, retour de liste vide ')\n",
    "            print('intCoteDimVect, intCoteDimMatrice-->', intCoteDimVect, intCoteDimMatrice)\n",
    "            print('tupleDimArray-->', tupleDimArray)\n",
    "            return []\n",
    "    else :\n",
    "            #Cas General taille vectConstituant > 1\n",
    "            if ( tupleDimArray[1] == intCoteDimVect and tupleDimArray[0] == intCoteDimMatrice) :\n",
    "                #Verification correspondance taille de matrice\n",
    "                print(\"Fin de la verification de la fonction builtCalibreArrayFromListCorpus\")\n",
    "        \n",
    "                return npArrayCalibree\n",
    "            else :\n",
    "                print('Erreur de calibrage de la fonction builtCalibreArrayFromListCorpus, retour de liste vide ')\n",
    "                print('intCoteDimVect, intCoteDimMatrice-->', intCoteDimVect, intCoteDimMatrice)\n",
    "                print('tupleDimArray-->', tupleDimArray)\n",
    "                return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtCalibreArrayFromMatrix3dCorpus(listCorpus, intCoteDimVect, intCoteDimMatrice, intPosFeature) :\n",
    "    #Renvoie une array calibree de la feature en position intPosFeature du vecteur, a partir de une liste Corpus a 3 dimension\n",
    "    \n",
    "    #Bibliotheques\n",
    "    import numpy as np\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #Variables\n",
    "    listVectCote = []\n",
    "    listArrayCalibree = []\n",
    "    intCptCoteVect = 0\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut de verification de la fonction builtCalibreArrayFromMatrix3dCorpus')\n",
    "    \n",
    "    #Feature MFCC : [:] [3] [12] constituee de matrice de 4 elements par 13 elements\n",
    "    #Transfert de un nombre definit de elements pour le vecteur constitutif de array ( liste de vecteur)\n",
    "    #Reinitialisation avant boucles\n",
    "    for vectConstituant in listCorpus :\n",
    "        #Reinitialisation avant boucle\n",
    "        intCptCoteVect =0\n",
    "        listVectCote = []\n",
    "        for elementVect in vectConstituant[intPosFeature] :\n",
    "            #niveau matrice 2d\n",
    "            for element in elementVect :\n",
    "                #Boucle de transfert avec double verification\n",
    "                #print('intCptCoteVect-->', intCptCoteVect)\n",
    "                if intCptCoteVect <intCoteDimVect :\n",
    "                    listVectCote.append(element)\n",
    "                    intCptCoteVect += 1\n",
    "                \n",
    "                if intCptCoteVect == intCoteDimVect :\n",
    "                    #print('Ajout de listVectCote a listArrayCalibree')\n",
    "                    listArrayCalibree.append(deepcopy(listVectCote))\n",
    "                    listVectCote =[]\n",
    "                    intCptCoteVect = intCptCoteVect + 1\n",
    "                \n",
    "            \n",
    "        \n",
    "    npArrayCalibree = np.array(listArrayCalibree)\n",
    "    #Verification finale du calibrage de array\n",
    "    tupleDimArray = npArrayCalibree.shape\n",
    "    if ( tupleDimArray[1] == intCoteDimVect and tupleDimArray[0] == intCoteDimMatrice) :\n",
    "        return npArrayCalibree\n",
    "    else :\n",
    "        print('Erreur de calibrage de la fonction builtCalibreArrayFromMatrix3dCorpus, retour de liste vide ')\n",
    "        print('intCoteDimVect, intCoteDimMatrice-->', intCoteDimVect, intCoteDimMatrice)\n",
    "        print('tupleDimArray-->', tupleDimArray)\n",
    "        return []\n",
    "    \n",
    "    #print('Fin de verification de la fonction builtCalibreArrayFromMatrix3dCorpus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def builtFusionArrayCalibre(npArrayCalibreFirst, npArrayCalibreSecond, intCoteDimVect, intCoteDimMatrice) :\n",
    "    #Renvoie une fusion calibree des array calibres\n",
    "    \n",
    "    #Bibliotheques necessaires\n",
    "    import numpy as np\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    listVectCote = []\n",
    "    listArrayFusionCalibree = []\n",
    "    intCptCoteVect = 0\n",
    "    intCptCoteMatrice = 0\n",
    "    intValeurMinDimVect = 2\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut de la verification de la fonction builtFusionArrayCalibre')\n",
    "    \n",
    "    #Fusion des vecteurs constituants les deux array a fusionner\n",
    "    # Verification de la concordonance des tailles des deux array\n",
    "    tupleDimArrayFirst = npArrayCalibreFirst.shape\n",
    "    tupleDimArraySecond = npArrayCalibreSecond.shape\n",
    "    \n",
    "    if (len(tupleDimArrayFirst)<intValeurMinDimVect) :\n",
    "        #Verification npArrayCalibreFirst superieur a une dimension\n",
    "        print('Erreur de taille minimale dimensionnelle de la fonction builtFusionArrayCalibre, inversion parametre')\n",
    "        print('Retour de liste vide')\n",
    "        return []\n",
    "    \n",
    "    #Traitement de nature des matrice numpy calibree npArrayCalibreSecond, ajout a matrice de grande dimension\n",
    "    #Cas de valeur unique du vecteur constituant, non iterable\n",
    "    if len(tupleDimArraySecond) < intValeurMinDimVect :\n",
    "        #Cas de valeur unique du vecteur constituant, non iterable\n",
    "        if ((tupleDimArrayFirst[1] + 1) != intCoteDimVect) :\n",
    "            #Verification taille des deux type de vecteurs constitutifs\n",
    "            print('Erreur sur somme de la fonction builtFusionArrayCalibre')\n",
    "            print('Erreur sur somme des tailles vecteur constitutifs, intCoteDimVect')\n",
    "            print('Retour de liste vide')\n",
    "            return []\n",
    "    else :\n",
    "        #Cas general\n",
    "        if ((tupleDimArrayFirst[1] + tupleDimArraySecond[1]) != intCoteDimVect) :\n",
    "            #Verification taille des deux type de vecteurs constitutifs\n",
    "            print('Erreur sur somme de la fonction builtFusionArrayCalibre')\n",
    "            print('Erreur sur somme des tailles vecteur constitutifs, intCoteDimVect')\n",
    "            print('Retour de liste vide')\n",
    "            return []\n",
    "        \n",
    "    if ( tupleDimArrayFirst[0] != intCoteDimMatrice or tupleDimArraySecond[0] != intCoteDimMatrice ) :\n",
    "        #Verification coherence des deux hauteurs de matrice\n",
    "        print('Erreur de coherance de la fonction builtFusionArrayCalibre')\n",
    "        print('Erreur de coherance de hauteur de matrice : hauteurs des deuc array a fusionner, sont differentes de intCoteDimMatrice ')\n",
    "        print('retour de la liste vide')\n",
    "        return []\n",
    "    #Reinitialisation des variables avant boucle\n",
    "    intCptCoteMatrice = 0\n",
    "    for vectLignes in npArrayCalibreFirst :\n",
    "        #Boucle parcours et concatenation des paires de vecteurs constitutifs\n",
    "        #Reinitialisation\n",
    "        listVectCote =[]\n",
    "        intCptCoteVect = 0\n",
    "        for element in vectLignes :\n",
    "            #Boucle Parcours des elements des vecteurs constitutifs de npArrayCalibreFirst \n",
    "            #Boucle de transfert avec double verification\n",
    "            #print('intCptCoteVect-->', intCptCoteVect)\n",
    "            if intCptCoteVect <intCoteDimVect :\n",
    "                listVectCote.append(element)\n",
    "                intCptCoteVect += 1\n",
    "            \n",
    "            if intCptCoteVect == intCoteDimVect :\n",
    "                #print('Ajout de listVectCote a listArrayFusionCalibree')\n",
    "                listArrayFusionCalibree.append(deepcopy(listVectCote))\n",
    "                listVectCote =[]\n",
    "                intCptCoteVect = intCptCoteVect + 1\n",
    "            \n",
    "        #Traitement de nature des matrice numpy calibree npArrayCalibreSecond, ajout a matrice de grande dimension\n",
    "        #Cas de valeur unique du vecteur constituant, non iterable\n",
    "        if len(tupleDimArraySecond) < intValeurMinDimVect :\n",
    "            #Cas de valeur unique du vecteur constituant, non iterable\n",
    "            #Ajout valeur unique a liste listVectCote qui est le vecteur constituant de listArrayFusionCalibree\n",
    "            if intCptCoteVect <intCoteDimVect :\n",
    "                listVectCote.append(npArrayCalibreSecond[intCptCoteMatrice])\n",
    "                intCptCoteVect += 1\n",
    "            \n",
    "            if intCptCoteVect == intCoteDimVect :\n",
    "                #print('Ajout de listVectCote a listArrayFusionCalibree')\n",
    "                listArrayFusionCalibree.append(deepcopy(listVectCote))\n",
    "                listVectCote =[]\n",
    "                intCptCoteVect = intCptCoteVect + 1\n",
    "            \n",
    "        else :\n",
    "            for element in npArrayCalibreSecond[intCptCoteMatrice] :\n",
    "                #Boucle Parcours des elements des vecteurs constitutifs de npArrayCalibreSecond\n",
    "                #Boucle de transfert avec double verification\n",
    "                #print('intCptCoteVect-->', intCptCoteVect)\n",
    "                if intCptCoteVect <intCoteDimVect :\n",
    "                    listVectCote.append(element)\n",
    "                    intCptCoteVect += 1\n",
    "                \n",
    "                if intCptCoteVect == intCoteDimVect :\n",
    "                    #print('Ajout de listVectCote a listArrayFusionCalibree')\n",
    "                    listArrayFusionCalibree.append(deepcopy(listVectCote))\n",
    "                    listVectCote =[]\n",
    "                    intCptCoteVect = intCptCoteVect + 1\n",
    "                \n",
    "    npArrayFusionCalibree = np.array(listArrayFusionCalibree)\n",
    "    #Verification finale du calibrage de array\n",
    "    tupleDimArrayFusion = npArrayFusionCalibree.shape\n",
    "    print('tupleDimArrayFusion-->', tupleDimArrayFusion)\n",
    "    if (tupleDimArrayFusion[1] == intCoteDimVect and tupleDimArrayFusion[0] == intCoteDimMatrice) :\n",
    "        return npArrayFusionCalibree\n",
    "    else :\n",
    "        print('Erreur de calibrage de la fonction builtFusionArrayCalibre, retour de liste vide ')\n",
    "        print('intCoteDimVect, intCoteDimMatrice-->', intCoteDimVect, intCoteDimMatrice)\n",
    "        print('tupleDimArrayFusion-->', tupleDimArrayFusion)\n",
    "        return []\n",
    "    \n",
    "    #print('Fin de la verification de la fonction builtFusionArrayCalibre')\n",
    "    \n",
    "    return npArrayFusionCalibree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtFusionArrayList1dCalibre(npArrayCalibreFirst, list1dCalibreSecond, intCoteDimVect, intCoteDimMatrice) :\n",
    "    #Renvoie une fusion calibree de l array et de la liste calibres\n",
    "    \n",
    "    #Bibliotheques necessaires\n",
    "    import numpy as np\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    listVectCote = []\n",
    "    listArrayFusionCalibree = []\n",
    "    intCptCoteVect = 0\n",
    "    intCptCoteMatrice = 0\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut de la verification de la fonction builtFusionArrayList1dCalibre')\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtFusionCorpusList(listCorpusBase, listCorpusAjout) :\n",
    "    #Renvoie la fusion de deux liste corpus de deux dimensions en ajoutant les lignes de une a suite de celles de autre\n",
    "    \n",
    "    #Variable de la fonction\n",
    "    listFusionCorpus = []\n",
    "    #Corps de la fonction\n",
    "    try :\n",
    "        #Fusion basique arithmetiques\n",
    "        listFusionCorpus = listCorpusBase + listCorpusAjout\n",
    "    except :\n",
    "        #Double boucle\n",
    "        try :\n",
    "            for lineBase in listCorpusBase :\n",
    "                #Boucle premier corpus\n",
    "                listFusionCorpus.append(lineBase)\n",
    "            for lineAjout in listCorpusAjout :\n",
    "                #Boucle ajout second corpus\n",
    "                listFusionCorpus.append(lineAjout)\n",
    "        except :\n",
    "            print('Erreur boucle ajout de la fonction builtFusionCorpusList')\n",
    "            print('retour liste vide')\n",
    "            return []\n",
    "    \n",
    "    #Retour de la fonction\n",
    "    return listFusionCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtSelectVectFeatArrayCalibree(npArrayCalibreCorpus, listIndSelectVect, listIndSelectFeat) :\n",
    "    #Renvoie la matrice des vecteurs seleactionnes de features selectionnees\n",
    "    \n",
    "    #Bibliotheques necessaires\n",
    "    import numpy as np\n",
    "    \n",
    "    #Variables de la fonctions\n",
    "    listSelectVectFeatCalibre = []\n",
    "    vectSelectFeat = []\n",
    "    intValeurMinDimVect = 2 # Nb valeurs minimal pour que constituants du vecteur soit iterable\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    #print(\"Debut verification de la fonction builtSelectVectFeatArrayCalibree\")\n",
    "    \n",
    "    #Verification nullite des parametres\n",
    "    if(npArrayCalibreCorpus == [] or listIndSelectVect == [] or listIndSelectFeat == []) :\n",
    "        print('npArrayCalibreCorpus-->', npArrayCalibreCorpus)\n",
    "        print('listIndSelectVect-->', listIndSelectVect)\n",
    "        print('listIndSelectFeat-->', listIndSelectFeat)\n",
    "        print('Erreur de parametres nuls de la fonction builtSelectVectFeatArrayCalibree, retour de la liste nulle')\n",
    "        return []\n",
    "    #Verification coherence des tailles des elements parametres de la fonction\n",
    "    tupleDimArrayCalibreCorpus = npArrayCalibreCorpus.shape\n",
    "    #Taille longueur matrice array\n",
    "    #Taille du vecteur interne de features, nb de features selectionnees\n",
    "    intCoteDimVect = len(listIndSelectFeat)\n",
    "    #Taille largeur matrice array\n",
    "    #Taille de la liste des vecteurs, nb de vecteurs selectionnes\n",
    "    intCoteDimMatrice = len(listIndSelectVect)\n",
    "    \n",
    "    #Verification vecteur constituant a valeur unique\n",
    "    if (len(tupleDimArrayCalibreCorpus) < intValeurMinDimVect) :\n",
    "        #Cas de valeur unique du vecteur constituant, non iterable\n",
    "        if(tupleDimArrayCalibreCorpus[0] < intCoteDimMatrice) :\n",
    "            print('Erreur de coherance de taille des parametres de la fonction builtSelectVectFeatArrayCalibree')\n",
    "            print('as de valeur unique du vecteur constituant, non iterable')\n",
    "            print('retour de liste vide ')\n",
    "            print('intCoteDimVect, intCoteDimMatrice-->', intCoteDimVect, intCoteDimMatrice)\n",
    "            print('tupleDimArrayCalibreCorpus-->', tupleDimArrayCalibreCorpus)\n",
    "            return []\n",
    "        #Ajout de la valeur unique constituante\n",
    "        for indSelectVect in listIndSelectVect :\n",
    "            #Boucle de parcours des indices des vecteurs selectionnes\n",
    "            #Ajout de la valeur unique a la liste des vecteurs de features selectionnes\n",
    "            listSelectVectFeatCalibre.append(npArrayCalibreCorpus[indSelectVect])\n",
    "            \n",
    "    else :\n",
    "        #Cas general, vecteur constituant iterable\n",
    "        if (tupleDimArrayCalibreCorpus[1] < intCoteDimVect  or tupleDimArrayCalibreCorpus[0] < intCoteDimMatrice) :\n",
    "            print('Erreur de coherance de taille des parametres de la fonction builtSelectVectFeatArrayCalibree')\n",
    "            print('retour de liste vide ')\n",
    "            print('intCoteDimVect, intCoteDimMatrice-->', intCoteDimVect, intCoteDimMatrice)\n",
    "            print('tupleDimArrayCalibreCorpus-->', tupleDimArrayCalibreCorpus)\n",
    "            return []\n",
    "        #Ajout du vecteur constituant\n",
    "        for indSelectVect in listIndSelectVect :\n",
    "            #Boucle de parcours des indicices selectionnes des vecteur')\n",
    "            #Reinitialisation\n",
    "            vectSelectFeat = []\n",
    "            for indSelectFeat in listIndSelectFeat :\n",
    "                #Boucle de parcours des features selectionnees et ajout au vecteur constituant vectSelectFeat')\n",
    "                vectSelectFeat.append(npArrayCalibreCorpus[indSelectVect][indSelectFeat])\n",
    "            #Ajout du vecteur constituant a la liste des vecteurs de features selectionnes\n",
    "            listSelectVectFeatCalibre.append(vectSelectFeat)\n",
    "            #print('listSelectVectFeatCalibre-->', listSelectVectFeatCalibre)\n",
    "        \n",
    "    #Transformation liste 2D Finale en numpy matrice    \n",
    "    npArraySelectVectFeatCalibre = np.array(listSelectVectFeatCalibre)\n",
    "    #Verification finale des tailles\n",
    "    tupleDimMatSelVectFeatCal = npArraySelectVectFeatCalibre.shape\n",
    "    #print('tupleDimArraySelectVectFeat-->', tupleDimArraySelectVectFeat)\n",
    "    \n",
    "    #Verification vecteur constituant a valeur unique\n",
    "    if (len(tupleDimArrayCalibreCorpus) < intValeurMinDimVect) :\n",
    "        #Cas de valeur unique du vecteur constituant, non iterable\n",
    "        if(tupleDimMatSelVectFeatCal[0] == intCoteDimMatrice) :\n",
    "            return npArraySelectVectFeatCalibre\n",
    "        else :\n",
    "            print('Erreur de calibrage de la fonction builtSelectVectFeatArrayCalibree, retour de liste vide ')\n",
    "            print('Cas de valeur unique du vecteur constituant, non iterable')\n",
    "            print('intCoteDimVect, intCoteDimMatrice-->', intCoteDimVect, intCoteDimMatrice)\n",
    "            print('tupleDimMatSelVectFeatCal-->', tupleDimMatSelVectFeatCal)\n",
    "            return []\n",
    "    else :\n",
    "        #Cas general, vecteur constituant iterable\n",
    "        if (tupleDimMatSelVectFeatCal[1] == intCoteDimVect and tupleDimMatSelVectFeatCal[0] == intCoteDimMatrice) :\n",
    "            return npArraySelectVectFeatCalibre\n",
    "        else :\n",
    "            print('Erreur de calibrage de la fonction builtSelectVectFeatArrayCalibree, retour de liste vide ')\n",
    "            print('intCoteDimVect, intCoteDimMatrice-->', intCoteDimVect, intCoteDimMatrice)\n",
    "            print('tupleDimMatSelVectFeatCal-->', tupleDimMatSelVectFeatCal)\n",
    "            return []\n",
    "    \n",
    "    #print('Fin de la verification de la fonction builtSelectVectFeatArrayCalibree')\n",
    "    \n",
    "    return npArraySelectVectFeatCalibre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtListIndVectParolePers(corpusPers, intPosIdPers, idPers, boolCorespStrict) :\n",
    "    #Renvoie la liste des indices de paroles de IdPers dans le corpus corpusPers des paroles de tous les personnages\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    intCptIdVect = 0\n",
    "    listIndParolePers = []\n",
    "    idPersCourant = ''\n",
    "    boolSameStrict = True\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    #Verification des parametres de la fonction\n",
    "    try :\n",
    "        idPersCourant = corpusPers[0][intPosIdPers]\n",
    "        boolSameStrict = bool(boolCorespStrict)\n",
    "    except :\n",
    "        print('Erreur de parametres intPosIdPers de la fonction builtListIndVectParolePers, retour liste vide')\n",
    "        return []\n",
    "    #Reinitialisation des variables avant boucle\n",
    "    intCptIdVect = 0\n",
    "    for vecteurFeat in corpusPers :\n",
    "        #Boucle de parcours des vecteurs paroles\n",
    "        idPersCourant = corpusPers[intCptIdVect][intPosIdPers]\n",
    "        #Verification correspondance idPers pour ajout a liste indice des paroles du personnage idPers avec ou sans\n",
    "        #correspondance stricte donnee par parametre boolCorespStrict\n",
    "        if (((idPers in idPersCourant) and not(boolSameStrict)) or ((idPersCourant == idPers) and boolSameStrict)) :\n",
    "            listIndParolePers.append(intCptIdVect)\n",
    "        \n",
    "        intCptIdVect += 1\n",
    "    \n",
    "    return listIndParolePers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtCorpusRegroupePersDesacord(corpusLabelPers, intPosIdPers, strIdFauxPersDesacord) :\n",
    "    #Renvoie un corpus de label de personnage en supprimant les desacord annotations a cause de strIdFauxPersDesacord\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    corpusLabelPersSansDesacord = []\n",
    "    strPersModif = 'pers'\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut de la verification de la fonction builtCorpusRegroupePersDesacord')\n",
    "    \n",
    "    #Verification des parametres de la fonction\n",
    "    if (corpusLabelPers == []) :\n",
    "        print('Corpus vide en parametre de la fonction builtCorpusRegroupePersDesacord, retour de la liste vide')\n",
    "        return []\n",
    "    \n",
    "    try :\n",
    "        #Verification donnees au bon format\n",
    "        #Initialisation avant boucle\n",
    "        corpusLabelPersSansDesacord = corpusLabelPers\n",
    "        \n",
    "        for vecteurLabelPers in corpusLabelPersSansDesacord :\n",
    "            #Boucle de parcours des vecteurs constitutifs du corpus\n",
    "            #Reconstruction du personnage de regroupement\n",
    "            strPersModif = vecteurLabelPers[intPosIdPers].split(strIdFauxPersDesacord)[0]\n",
    "            #Application de la modification\n",
    "            vecteurLabelPers[intPosIdPers] = strPersModif\n",
    "        \n",
    "    except :\n",
    "        print('Erreur de format de donnees de la fonction builtCorpusRegroupePersDesacord, retour de la liste vide')\n",
    "        return []\n",
    "    \n",
    "    return corpusLabelPersSansDesacord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtCorpusRegroupePers1EnPers2(corpusLabelPers, intPosIdPers, idPers1, idPers2) :\n",
    "    #Renvoie un corpus de label de personnages en regroupant le personnage idPers1 dans le personnage idPers2\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut de la verification de la fonction builtCorpusRegroupePers1EnPers2')\n",
    "    \n",
    "    #Verification des parametres de la fonction\n",
    "    if (corpusLabelPers == []) :\n",
    "        print('Corpus vide en parametre de la fonction builtCorpusRegroupePers1EnPers2, retour de la liste vide')\n",
    "        return []\n",
    "    \n",
    "    try :\n",
    "        #Verification donnees au bon format\n",
    "        \n",
    "        for vecteurLabelPers in corpusLabelPers :\n",
    "            #Boucle de parcours des vecteurs constitutifs du corpus\n",
    "            if(idPers1 in vecteurLabelPers[intPosIdPers]) :\n",
    "                #Verification presence personnage cible\n",
    "                #Application de la substitution\n",
    "                vecteurLabelPers[intPosIdPers] =  idPers2\n",
    "        \n",
    "    except :\n",
    "        print('Erreur de format de donnees de la fonction builtCorpusRegroupePers1EnPers2, retour de la liste vide')\n",
    "        return []\n",
    "    \n",
    "    return corpusLabelPers   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtCorpusGroupePersEtNonPers(corpusLabelPers, intPosIdOeuvre, intPosIdPers, idPers, idNonPers, strMonoOrMulti) :\n",
    "    #Renvoie un corpus de label de personnages en groupant les personnage idPers et les personnages non idPers\n",
    "    #dans deux groupes distincts sur un ensemble groupe a partir de un monocorpus ou multicorpus\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    strMultiCorpus ='multi'\n",
    "    strOeuvresGroupees = 'groupe_ensemble'\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut de la verification de la fonction builtCorpusGroupePersEtNonPers')\n",
    "    \n",
    "    #Verification des parametres de la fonction\n",
    "    if (corpusLabelPers == []) :\n",
    "        print('Corpus vide en parametre de la fonction builtCorpusGroupePersEtNonPers, retour de la liste vide')\n",
    "        return []\n",
    "    \n",
    "    try :\n",
    "        #Verification donnees au bon format\n",
    "        \n",
    "        for vecteurLabelPers in corpusLabelPers :\n",
    "            #Boucle de parcours des vecteurs constitutifs du corpus\n",
    "            if (strMonoOrMulti == strMultiCorpus):\n",
    "                #Verfication si le traitement de la fonction se fait sur plusieurs corpus regroupes\n",
    "                vecteurLabelPers[intPosIdOeuvre] = strOeuvresGroupees\n",
    "            #Niveau personnages\n",
    "            if(idPers in vecteurLabelPers[intPosIdPers]) :\n",
    "                #Verification presence personnage cible\n",
    "                #Application du groupement au Groupe idPers\n",
    "                vecteurLabelPers[intPosIdPers] =  idPers\n",
    "            else :\n",
    "                #Application du groupement au Groupe idNonPers\n",
    "                vecteurLabelPers[intPosIdPers] =  idNonPers\n",
    "        \n",
    "    except :\n",
    "        print('Erreur de format de donnees de la fonction builtCorpusGroupePersEtNonPers, retour de la liste vide')\n",
    "        return []\n",
    "    \n",
    "    return corpusLabelPers   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtCorpusGroupeSansPers(corpusLabelPers, corpusProsodie, intPosIdOeuvre, intPosIdPers, idPers, strMonoOrMulti) :\n",
    "    #Renvoie un corpus de label de personnages et de prosodie en excluant les personnages idPers\n",
    "    #sur un ensemble groupe a partir de un monocorpus ou multicorpus\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    strMultiCorpusRegroupe ='multiRegroupe'\n",
    "    strOeuvresGroupees = 'groupe_ensemble'\n",
    "    intPosBoucle = 0\n",
    "    listCorpusLabelSansPers = []\n",
    "    listCorpusProsodieSansPers = []\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    print('Debut de la verification de la fonction builtCorpusGroupeSansPers')\n",
    "    \n",
    "    #Verification des parametres de la fonction\n",
    "    if (corpusLabelPers == []) :\n",
    "        print('Corpus vide en parametre de la fonction builtCorpusGroupeSansPers, retour de la liste vide')\n",
    "        return []\n",
    "    \n",
    "    try :\n",
    "        #Verification donnees au bon format\n",
    "        #Reinitialisation avant boucle\n",
    "        intPosBoucle = 0\n",
    "        for vecteurLabelPers in corpusLabelPers :\n",
    "            #Boucle de parcours des vecteurs constitutifs du corpus\n",
    "            if (strMonoOrMulti == strMultiCorpusRegroupe):\n",
    "                #print('Nom oeuvre commun applique par la fonction builtCorpusGroupeSansPers')\n",
    "                #Verfication si le traitement de la fonction se fait sur plusieurs corpus regroupes\n",
    "                vecteurLabelPers[intPosIdOeuvre] = strOeuvresGroupees\n",
    "            #Niveau personnages\n",
    "            if not(idPers in vecteurLabelPers[intPosIdPers]) :\n",
    "                #Verification presence personnage cible\n",
    "                #Application exclusion a idPers\n",
    "                listCorpusLabelSansPers.append(corpusLabelPers[intPosBoucle])\n",
    "                listCorpusProsodieSansPers.append(corpusProsodie[intPosBoucle])\n",
    "            #Incrementation avant nouveau passage boucle\n",
    "            intPosBoucle = intPosBoucle +1\n",
    "        \n",
    "    except :\n",
    "        print('Erreur de format de donnees de la fonction builtCorpusGroupeSansPers, retour de la liste vide')\n",
    "        return []\n",
    "    \n",
    "    print('intPosBoucle-->', intPosBoucle)\n",
    "    print('Fin de la verification de la fonction builtCorpusGroupeSansPers')\n",
    "    \n",
    "    #retour fonction\n",
    "    return listCorpusLabelSansPers, listCorpusProsodieSansPers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtDicoPersLabelsClusters(listLabelClusters, listPersFeatures, intPosIdOeuvre, intPosIdPers, strMonoOrMulti):\n",
    "    #Renvoie le dico des nombres occurences de chaque labels de clusters pour chaque personnages de un mono ou multi\n",
    "    # corpus dont le type est indique par le parametre strMonoOrMulti\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    dictPersClusters ={}\n",
    "    dictPers = {}\n",
    "    dictLabelCluster = {}\n",
    "    intTailleListClusters = 0\n",
    "    intTailleListPers = 0\n",
    "    intPosCourante = 0\n",
    "    intPosNomAuteur = 0\n",
    "    intPosNomOeuvre = 1\n",
    "    idPersCourant = 'pers'\n",
    "    keyPers = '_'\n",
    "    strMultiCorpus ='multi'\n",
    "    strMultiCorpusReg = 'multiRegroupe'\n",
    "    strUnderScore ='_'\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut verification fonction builtDicoPersLabelsClusters')\n",
    "    \n",
    "    try :\n",
    "        #Verification de la coherence des parametre de la fonction\n",
    "        intTailleListClusters = len(listLabelClusters)\n",
    "        intTailleListPers = len(listPersFeatures)\n",
    "        idPersCourant = listPersFeatures[intPosIdPers]\n",
    "        if intTailleListClusters != intTailleListPers :\n",
    "            print('Erreur de coherence de parametres de la fonction builtDicoPersLabelsClusters')\n",
    "            print('taille des deux listes en paramètres non egales')\n",
    "            print('retour du dictionnaire vide')\n",
    "            return {}\n",
    "    except :\n",
    "        print('Position de idPers en dehors de la liste listPersFeatures, retour du dictionnaire vide')\n",
    "        return {}\n",
    "    \n",
    "    for vectPers in listPersFeatures :\n",
    "        #Boucle de parcours des personnages\n",
    "        #Reinitialisation\n",
    "        dictPers ={}\n",
    "        if ((strMonoOrMulti == strMultiCorpus) or (strMonoOrMulti== strMultiCorpusReg)):\n",
    "            #Verfication si le traitement de la fonction se fait sur plusieurs corpus regroupes\n",
    "            try :\n",
    "                #Bon format nom de oeuvre\n",
    "                strNomOeuvre = vectPers[intPosIdOeuvre].split(strUnderScore)[intPosNomAuteur] + strUnderScore + vectPers[intPosIdOeuvre].split(strUnderScore)[intPosNomOeuvre]\n",
    "                keyPers = strNomOeuvre + str('.') + vectPers[intPosIdPers]\n",
    "                #print('strMonoOrMulti-->', strMonoOrMulti)\n",
    "                #print('keyPers-->', keyPers)\n",
    "            except :\n",
    "                print('Erreur format nom oeuvre de la fonction builtDicoPersLabelsClusters')\n",
    "                print('format attendu : auteur_titre')\n",
    "                print('retour du dictionnaire vide')\n",
    "                return {}\n",
    "        else :\n",
    "            keyPers = vectPers[intPosIdPers]\n",
    "            #print('keyPers-->', keyPers)\n",
    "        \n",
    "        #Verification si presence du personnage\n",
    "        if keyPers in dictPersClusters :\n",
    "            #mise a jour du dictionnaire des clusters du personnage dictPers\n",
    "            dictPers = dictPersClusters[keyPers]\n",
    "            #Verification presence du label de cluster\n",
    "            keyCluster = listLabelClusters[intPosCourante]\n",
    "            if keyCluster in dictPers :\n",
    "                #Mise a jour des occurences du cluster pour le personnage\n",
    "                dictPers[keyCluster] +=1\n",
    "            else :\n",
    "                #Creation entree du nouveau cluster pour le personnage\n",
    "                dictPers[keyCluster] =1\n",
    "            #Update du dico dictPersClusters\n",
    "            dictPersClusters.update(dictPers)\n",
    "        else :\n",
    "            #Creation entree nouveau dico personnage\n",
    "            #Reinitialisation variable de construction\n",
    "            dictLabelCluster = {}\n",
    "            dictPers = {}\n",
    "            keyCluster = listLabelClusters[intPosCourante]\n",
    "            #Construction entree\n",
    "            dictLabelCluster = {keyCluster : 1}\n",
    "            dictPers = {keyPers : dictLabelCluster}\n",
    "            #Update du dico dictPersClusters\n",
    "            dictPersClusters.update(dictPers)\n",
    "        #Incrementation position courante avant nouveau tour de boucle de parcours des personnages\n",
    "        intPosCourante +=  1\n",
    "    \n",
    "    #print('Fin verification fonction builtDicoPersLabelsClusters')\n",
    "    \n",
    "    return dictPersClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belongToCluster(idPers, dictPersClusters) :\n",
    "    #Renvoie id du cluster auquel appartient le personnage, revoie -1 si appartient a aucun\n",
    "    \n",
    "    #variables de la fonction\n",
    "    intNbOccurClusterMax = 0\n",
    "    idClusterBelong = -1\n",
    "    idClusterBelong ='pers'\n",
    "    \n",
    "    \n",
    "    #corps de la fonction\n",
    "    \n",
    "    #print('Debut verification fonction belongToCluster')\n",
    "    \n",
    "    try :\n",
    "        dictCluster = dictPersClusters[idPers]\n",
    "        if dictCluster == {} :\n",
    "            #Si pas de cluster de presence\n",
    "            #print('idPers-->', idPers)\n",
    "            #print('dico dictPersClusters des clusters de precence du personnage, est vide, retour de idCluster vide')\n",
    "            return ''\n",
    "    except :\n",
    "        print('idPers introuvable dans le dico dictPersClusters, retour de idCluster vide')\n",
    "        return ''\n",
    "    \n",
    "    #print('dictCluster-->', dictCluster)\n",
    "    \n",
    "    for keyClusters in dictCluster.keys() :\n",
    "        #Boucle de parcours des clusters attribues au personnage\n",
    "        #Condition de initialisation\n",
    "        if intNbOccurClusterMax < 1 :\n",
    "            #Attribution valeur occurence et id cluster courants\n",
    "            intNbOccurClusterMax = dictCluster[keyClusters]\n",
    "            idClusterBelong = keyClusters\n",
    "        \n",
    "        #print('intNbOccurClusterMax-->', intNbOccurClusterMax)\n",
    "        #print('dictCluster[keyClusters]-->', dictCluster[keyClusters])\n",
    "        \n",
    "        if dictCluster[keyClusters] > intNbOccurClusterMax :\n",
    "            #Si nb occurence pour cluster courant plus grand que maximum occurence avant, alors mis a jour\n",
    "            #Attribution valeur occurence et id cluster courants\n",
    "            intNbOccurClusterMax = dictCluster[keyClusters]\n",
    "            idClusterBelong = keyClusters\n",
    "            \n",
    "    #print('fin verification fonction belongToCluster')\n",
    "    \n",
    "    return idClusterBelong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculPrecisionPers(idPers, idClusterBelongPers, listClusters, dictPersClusters, intNbChifArrondi) :\n",
    "    #Renvoie la precion de labelisation du clustering des personnage \n",
    "    \n",
    "    #Variables de la fonction\n",
    "    floatPrecision = 0.0\n",
    "    intNbOccuClusterAppPersTPFP = 0\n",
    "    intNbOccuAssoCorrecteTP = 0\n",
    "    \n",
    "    #corps de la fonction\n",
    "    \n",
    "    #print('Debut verification calcul de la fonction calculPrecisionPers')\n",
    "    #print('idPers-->', idPers)\n",
    "    \n",
    "    #calcul nb occurences de association de Pers idPers avec son cluster appartenance idClusterBelongPers\n",
    "    dictClusterPersCourant = dictPersClusters[idPers]\n",
    "    intNbOccuAssoCorrecteTP = dictClusterPersCourant[idClusterBelongPers]\n",
    "    intNbOccuClusterAppPersTPFP = np.count_nonzero(listClusters == idClusterBelongPers)\n",
    "    \n",
    "    #print('intNbOccuAssoCorrecteTP-->', intNbOccuAssoCorrecteTP)\n",
    "    #print('intNbOccuClusterAppPersTPFP-->', intNbOccuClusterAppPersTPFP)\n",
    "    try :\n",
    "        floatPrecision = intNbOccuAssoCorrecteTP/intNbOccuClusterAppPersTPFP\n",
    "    except :\n",
    "        print(\"erreur denombrement cluster, division par zero, return de calculPrecisionPers precision = 0\")\n",
    "    \n",
    "    #print('fin verification calcul de la fonction calculPrecisionPers')\n",
    "    \n",
    "    return round(floatPrecision, intNbChifArrondi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculRappelPers(idPers, idClusterBelongPers, listClusters, dictPersClusters, intNbChifArrondi) :\n",
    "    #Renvoie le rappel de labelisation du clustering des personnage \n",
    "    \n",
    "    #Bibliotheques necessaires\n",
    "    import numpy as np\n",
    "    \n",
    "    \n",
    "    #Variables de la fonction\n",
    "    floatRappel = 0.0\n",
    "    intNbOccuPersTPTN = 0\n",
    "    intNbOccuAssoCorrecteTP = 0\n",
    "    dictCluster ={}\n",
    "    \n",
    "    #corps de la fonction\n",
    "    #print('Debut verification calcul de la fonction calculRappelPers')\n",
    "    #print('idPers-->', idPers)\n",
    "    \n",
    "    #calcul nb occurences de association de Pers idPers avec son cluster appartenance idClusterBelongPers\n",
    "    dictClusterPersCourant = dictPersClusters[idPers]\n",
    "    intNbOccuAssoCorrecteTP = dictClusterPersCourant[idClusterBelongPers]\n",
    "    \n",
    "    #print('intNbOccuAssoCorrecteTP-->', intNbOccuAssoCorrecteTP)\n",
    "    \n",
    "    #Calcul du nb occurences du personnages Pers sur tout les clusters\n",
    "    try :\n",
    "        dictCluster = dictPersClusters[idPers]\n",
    "    except :\n",
    "        print('idPers introuvable dans le dico dictPersClusters, retour de calculRappelPers = 0.0')\n",
    "        return 0.0\n",
    "    \n",
    "    for keyClusters in dictCluster.keys() :\n",
    "        #Boucle de parcours des clusters attribues au personnage\n",
    "        #Ajout valeurs occurence\n",
    "        intNbOccuPersTPTN += dictCluster[keyClusters]\n",
    "    \n",
    "    #print('intNbOccuPersTPTN-->', intNbOccuPersTPTN)\n",
    "    \n",
    "    #Calcul du rappel\n",
    "    try :\n",
    "        floatRappel = intNbOccuAssoCorrecteTP/intNbOccuPersTPTN\n",
    "    except :\n",
    "        print(\"erreur denombrement personnage, division par zero, return de calculRappelPers rappel = 0\")\n",
    "    \n",
    "    return round(floatRappel, intNbChifArrondi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtDicoPersPrecisionRappel(dictPersClusters, npArrayClusters) :\n",
    "    #Renvoie un dico de personnages avec tout leurs clusters d'occurences, leur precision et leur rappel\n",
    "    \n",
    "    #Bibliotheques necessaires\n",
    "    \n",
    "    #Fonctions necessaires\n",
    "    #calculPrecisionPers (idPers, idClusterBelongPers, listClusters, dictPersClusters)\n",
    "    #calculRappelPers(idPers, idClusterBelongPers, listClusters, dictPersClusters)\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    dictPersCluPreRap ={}\n",
    "    dictPersCourant = {}\n",
    "    dictPrecisionRappel ={}\n",
    "    keyPers = ' _'\n",
    "    intNbChifArrondi = 2\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut verification fonction builtDicoPersPrecisionRappel')\n",
    "    #print('dictPersClusters.keys-->', dictPersClusters.keys())\n",
    "    \n",
    "    for keyPers in dictPersClusters.keys() :\n",
    "        #Boucle de parcours des id des personnages\n",
    "        #Reinitialisation des variables\n",
    "        dictPersCourant = {}\n",
    "        dictPrecisionRappel ={}\n",
    "        #Appel des fonctions de collectes donnees\n",
    "        \n",
    "        #Recuperation cluster appartenance personnage\n",
    "        \n",
    "        #print('keyPers-->', keyPers)\n",
    "        #print('dictPersClusters-->', dictPersClusters)\t\t\n",
    "        \n",
    "        if(type(dictPersClusters[keyPers]) == type({}) and dictPersClusters[keyPers] != {}) :\n",
    "            # Verification que le dictionnaire des clusters existe et est non vide\n",
    "            #print('dico clusters non vide')\n",
    "            idClusterBelongPers = belongToCluster(keyPers, dictPersClusters)\n",
    "            \n",
    "            #Calcul Precision\n",
    "            floatPrecisionPers = calculPrecisionPers(keyPers, idClusterBelongPers, npArrayClusters, dictPersClusters, intNbChifArrondi)\n",
    "            #Calcul Rappel\n",
    "            floatRappelPers = calculRappelPers(keyPers, idClusterBelongPers, npArrayClusters, dictPersClusters, intNbChifArrondi)\n",
    "            #Construction dico personnage courant {clusters, precision, rappel}\n",
    "            dictPersCourant.update(dictPersClusters[keyPers])\n",
    "            #precision et rappel\n",
    "            dictPrecisionRappel = {'Precision' : floatPrecisionPers, 'Rappel' : floatRappelPers}\n",
    "            dictPersCourant.update(dictPrecisionRappel)\n",
    "            #Update dico de retour\n",
    "            dictPersCluPreRap.update({keyPers : dictPersCourant})\n",
    "        \n",
    "    #print('Fin verification fonction builtDicoPersPrecisionRappel')\n",
    "    \n",
    "    return dictPersCluPreRap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtVectResumeDescripteur(dictPersCluPreRap, keyPrec, keyRap, intNbClusters, intDimCoteFeat, strNomDescripteur,\n",
    "                              intNbChifArrondi) :\n",
    "    #Renvoie un vecter de synthese du descripteur\n",
    "    # Nom du descripteur ; nombre de caracteristiques ; moyenne precision ; moyenne rappel ; moyenne f-mesure\n",
    "    \n",
    "    #Variable de la fonction\n",
    "    listVectResume = []\n",
    "    floatMoyPrecision = 0.0\n",
    "    floatMoyRappel = 0.0\n",
    "    floatMoyFmesure = 0.0\n",
    "    intNbPers = 0\n",
    "    \n",
    "    #Corps\n",
    "    #print('Debut verification de la verification de la fonction builtVectResumeDescripteur')\n",
    "    for dictPers in dicoPersCluPreRap.values() :\n",
    "        #Boucle parcours des personnages\n",
    "        #incrementation des valeur de comptage\n",
    "        intNbPers +=1\n",
    "        floatMoyPrecision += dictPers[keyPrec]\n",
    "        floatMoyRappel += dictPers[keyRap]\n",
    "    #Calcul post boucle\n",
    "    try :\n",
    "        floatMoyPrecision = floatMoyPrecision / intNbPers\n",
    "        floatMoyRappel = floatMoyRappel / intNbPers\n",
    "        floatMoyPrecision = round(floatMoyPrecision,intNbChifArrondi)\n",
    "        floatMoyRappel = round(floatMoyRappel,intNbChifArrondi)\n",
    "        \n",
    "    except :\n",
    "        print('Erreur division par 0 de la fonction builtVectResumeDescripteur')\n",
    "        print('Nb Personnage est de 0')\n",
    "        print('Retour liste vide')\n",
    "        return []\n",
    "    floatMoyFmesure = 2*((floatMoyPrecision*floatMoyRappel)/(floatMoyPrecision+floatMoyRappel))\n",
    "    floatMoyFmesure = round(floatMoyFmesure,intNbChifArrondi)\n",
    "    #print('Fin verification de la verification de la fonction builtVectResumeDescripteur')\n",
    "    #retour de vecteur de resume\n",
    "    return [strNomDescripteur, intDimCoteFeat, floatMoyPrecision, floatMoyRappel, floatMoyFmesure]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtDicoTamisPoidsPers(dictPersClusters, intNbClusters, intSeuilNbSeg) :\n",
    "    #Revoie un dico des personnages ayant un nombre de segment superieur au seuil fixe intSeuilNbSeg\n",
    "    \n",
    "    #Variable de la fonction\n",
    "    dictPersSupSeuil ={}\n",
    "    intTotalSegPersCour = 0\n",
    "    \n",
    "    #Corps\n",
    "    #print('Debut verification de la fonction builtDicoTamisPoidsPers ')\n",
    "    #print('dictPersClusters.keys-->', dictPersClusters.keys())\n",
    "    for keyPers in dictPersClusters :\n",
    "        #print('keyPers-->', keyPers)\n",
    "        #Boucle parcours des personnages\n",
    "        #reinitialisation des valeurs\n",
    "        dictPers = dictPersClusters[keyPers]\n",
    "        #print('dictPers-->', dictPers)\n",
    "        intTotalSegPersCour = 0\n",
    "        for keyCluster in dictPers.keys() :\n",
    "            #Parcours des clusters attribues au personnage courant\n",
    "            #Verification valeurs du clusters sont bien des entiersn pour filtrer les keys 'Precision' et 'Rappel'\n",
    "            if(isinstance(dictPers[keyCluster], int)) :\n",
    "                intTotalSegPersCour += dictPers[keyCluster]\n",
    "                #print('dictPers[keyCluster]-->', dictPers[keyCluster])\n",
    "        #Verification si personnage courant est eligible au dico en construction\n",
    "        if (intTotalSegPersCour>intSeuilNbSeg) :\n",
    "            #print('intTotalSegPersCour-->', intTotalSegPersCour)\n",
    "            dictPersSupSeuil.update({keyPers : dictPers})\n",
    "    #print('fin verification de la fonction builtDicoTamisPoidsPers ')\n",
    "    #Retour du dictionnaire construit\n",
    "    return dictPersSupSeuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtArrayPersCluFromDictPersClu(dictPersClusters, intNbClusters) :\n",
    "    #Renvoie un tableau des personnages et de leurs occurences dans chaque clusters, a partir de un \n",
    "    #dico dictPersClusters\n",
    "    \n",
    "    #Bibliotheques necessaires\n",
    "    import numpy as np\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    listPersClusters = []\n",
    "    vectPersCourant = []\n",
    "    vectOccurPersClusters = [0] * intNbClusters\n",
    "    vectLigneTotalClusters = ['Total']\n",
    "    dictClustersCourant = {}\n",
    "    intSumNbParolePersCourant = 0\n",
    "    intTailleVectPersCourant = intNbClusters + 1\n",
    "    intPosCluInLigTotal = 0\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #print('Debut de la verification de la fonction builtArrayPersCluFromDictPersClu')\n",
    "    \n",
    "    #Initialisation de la ligne des totaux de clusters et de paroles vectLigneTotalClusters\n",
    "    vectLigneTotalClusters += ([0] * intTailleVectPersCourant)\n",
    "    \n",
    "    for keyPers in dictPersClusters.keys() :\n",
    "        #Boucle de parcours des id des personnages\n",
    "        #Reinitialisation des variables\n",
    "        vectPersCourant = []\n",
    "        vectOccurPersClusters = [0] * intNbClusters\n",
    "        \n",
    "        #Construction du vecteur de donnees Personnage (nom du personnage et ses occurences dans clusters)\n",
    "        if(type(dictPersClusters[keyPers]) == type({}) and dictPersClusters[keyPers] != {}) :\n",
    "            # Verification que le dictionnaire des clusters existe et est non vide\n",
    "            \n",
    "            #Intialisation avant boucle\n",
    "            dictClustersCourant = dictPersClusters[keyPers]\n",
    "            intSumNbParolePersCourant = 0\n",
    "            #Nom\n",
    "            vectPersCourant.append(keyPers)\n",
    "            for keyCluster in dictClustersCourant.keys() :\n",
    "                intPosCluInLigTotal = keyCluster + 1\n",
    "                #Boucle de parcours des id clusters\n",
    "                try :\n",
    "                    #Verification que les id clusters sont des indices valides de la liste vectOccurClusters\n",
    "                    #Traitement valeurs des clusters\n",
    "                    vectOccurPersClusters[keyCluster] = dictClustersCourant[keyCluster]\n",
    "                    intSumNbParolePersCourant +=  vectOccurPersClusters[keyCluster]\n",
    "                    vectLigneTotalClusters[intPosCluInLigTotal] +=  vectOccurPersClusters[keyCluster]\n",
    "                except :\n",
    "                    print('Erreur de coherence indexation builtArrayPersCluFromDictPersClu')\n",
    "                    print('Erreur index clusters element liste, retour de la liste vide')\n",
    "                    return []\n",
    "                \n",
    "            #Ajout du vecteur vectOccurClusters a vectPersCourant aplat sans boucle, element par element\n",
    "            vectPersCourant = vectPersCourant + vectOccurPersClusters\n",
    "            #Ajout du nombre total de paroles prononcees par le personnage courant\n",
    "            vectPersCourant.append(intSumNbParolePersCourant)\n",
    "            vectLigneTotalClusters[intTailleVectPersCourant] += intSumNbParolePersCourant\n",
    "            #Ajout du vecteur personnage courant a la liste des vecteurs de personnage, de tout les personnages\n",
    "            listPersClusters.append(vectPersCourant)\n",
    "        \n",
    "    #Ajout de la ligne des totaux\n",
    "    listPersClusters.append(vectLigneTotalClusters)\n",
    "    #print('listPersClusters-->', listPersClusters)\n",
    "    \n",
    "    #print('Fin de la verification de la fonction builtArrayPersCluFromDictPersClu')\n",
    "    #Retour de la liste globale\n",
    "    return listPersClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSaveDiapoClusterPers(corpusFeatPers1, corpusFeatPers2, corpusFeatPers3, intNbMaxClusters, intFeatX, intFeatY):\n",
    "    #Represente et sauve evolution de cluster de nombre 1 vers intNbMaxClusters sur 3 personnages en meme temps\n",
    "    \n",
    "    #Bibliotheques necessaires \n",
    "    import sklearn\n",
    "    from sklearn.cluster import KMeans\n",
    "\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    intLenVectFeatPers1 = 0\n",
    "    intLenVectFeatPers2 = 0\n",
    "    intLenVectFeatPers3 = 0\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    \n",
    "    #Verification coherence des parametres de la fonction\n",
    "    try :\n",
    "        #Verification de la non nulite des parametre\n",
    "        #Affectation longueur des vecteurs de features\n",
    "        intLenVectFeatPers1 = len(corpusFeatPers1[0])\n",
    "        intLenVectFeatPers2 = len(corpusFeatPers2[0])\n",
    "        intLenVectFeatPers3 = len(corpusFeatPers3[0])\n",
    "        if((intLenVectFeatPers1 != intLenVectFeatPers2) and (intLenVectFeatPers2 != intLenVectFeatPers3)) :\n",
    "            print(\"incoherance de parametres de la fonction showSaveDiapoClusterPers\")\n",
    "            print('Tailles de vecteurs de features non identiques, fin fonction et retour 0')\n",
    "            return 0\n",
    "    except :\n",
    "        print('Erreur de parametres de la fonction showSaveDiapoClusterPers')\n",
    "        print('Corpus null en parametre, fin fonction et retour 0')\n",
    "        return 0\n",
    "    \n",
    "    #Preparation avant boucle de test\n",
    "    npProsodie = np.array(corpusFeatPers1 + corpusFeatPers2 + corpusFeatPers3)\n",
    "    \n",
    "    for nbCourantClusters in range(1, intNbMaxClusters+1) :\n",
    "        #Parcours de test de different nombre de clusters\n",
    "        #Obtention des clusters\n",
    "        kmeansClusterPers = KMeans(n_clusters=2, random_state=0).fit(npProsodie)\n",
    "        #Obtention des labels de clusters\n",
    "        listLabelsClusters = kmeansClusterPers.labels_\n",
    "        #Prediction sur le jeu train\n",
    "        y_kmeansClusterPers = kmeansClusterPers.predict(npProsodie)\n",
    "        #Obtention des centres des clusters\n",
    "        centers = kmeansClusterPers.cluster_centers_\n",
    "    \n",
    "        #Tracé des points-parole de chaque personnage dans chaque clusters\n",
    "        plt.scatter(npProsodie[:, intFeatX], npProsodie[:, intFeatY], c=y_kmeansClusterPers, s=25, cmap='viridis')\n",
    "        plt.scatter(npProsodie[:, intFeatX], npProsodie[:, intFeatY], c=y_kmeansClusterPers, s=25, cmap='viridis')\n",
    "        plt.scatter(npProsodie[:, intFeatX], npProsodie[:, intFeatY], c=y_kmeansClusterPers, s=25, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builtKmeansFromCorpus(intNbClustersChosi, npCorpusFit, npCorpusPredict) :\n",
    "    #Retourne des objets sklearn kmeans, kmeansFit et kmeansPredict : kmeans.fit(X) ; y_kmeans.predict(Y)\n",
    "    \n",
    "    #Importation bibliotheques necessaires\n",
    "    import sklearn\n",
    "    from sklearn.cluster import KMeans\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    intNbMinForKmeans = 1\n",
    "    tupleDimNpCorpusFit = ()\n",
    "    tupleDimNpCorpusPredict = ()\n",
    "    listIndiceNpCorpusFit = []\n",
    "    listMatCompletee = []\n",
    "    npCorpusInterneKmeansX = npCorpusFit\n",
    "    npCorpusInterneKmeansY = npCorpusPredict\n",
    "    \n",
    "    \n",
    "    #Corps de la fonction\n",
    "    #print('Debut verification de la fonction builtKmeansFromCorpus')\n",
    "    \n",
    "    #Verification des parametres\n",
    "    if(intNbClustersChosi< intNbMinForKmeans) :\n",
    "        print('Erreur de parametre Nombre Clusters de la fonction builtKmeansFromCorpus')\n",
    "        print('Nombre de clusters choisis doit etre superieur a 0 pour execution KMeans')\n",
    "        print('retour 0')\n",
    "        return 0\n",
    "    if(intNbClustersChosi == intNbMinForKmeans) :\n",
    "        print('Avertissement nombre de clusters choisis-->', intNbClustersChosi)\n",
    "    \n",
    "    try :\n",
    "        #Verification des corpus parametres npCorpusFit et npCorpusPredict\n",
    "        tupleDimNpCorpusFit = npCorpusFit.shape\n",
    "        tupleDimNpCorpusPredict = npCorpusPredict.shape\n",
    "        if (tupleDimNpCorpusFit == () or tupleDimNpCorpusPredict == ()) :\n",
    "            #Verification non matrice des parametres npCorpusFit et npCorpusPredict\n",
    "            print('Erreur taille parametres npCorpusFit et npCorpusPredict de la fonction builtKmeansFromCorpus ')\n",
    "            print('La matrice de chacun des parametres npCorpus, doit contenir plus de un element')\n",
    "            print('retour 0')\n",
    "            return 0\n",
    "    except :\n",
    "        print('Erreur de type non matrice des parametres npCorpus de la fonction builtKmeansFromCorpus')\n",
    "        print('Les matrices doivent etre des numpy matrices')\n",
    "        print ('retour 0')\n",
    "    \n",
    "    #Modification corpus npCorpusFit si unidimensionnelle pour le KMeans\n",
    "    if(len(tupleDimNpCorpusFit) == intNbMinForKmeans) :\n",
    "        # Ajout de la dimension des indices du corpus au corpus pour obtenir matrice 2D\n",
    "        print('corpus npCorpusFit unidimensionnel : Ajout une dimension des indices et predict sur lui-meme ')\n",
    "        # Generation liste indices corpus\n",
    "        listIndiceNpCorpusFit = list(range(tupleDimNpCorpusFit[0]))\n",
    "        #print('TailleListIndiceNpCorpusFit-->', len(listIndiceNpCorpusFit))\n",
    "        for indice in listIndiceNpCorpusFit :\n",
    "            #Boucle parcours des indices pour construction matrice de vecteurs[indiceCorpus, valeur Corpus[indice]]\n",
    "            listMatCompletee.append([npCorpusFit[indice], indice])\n",
    "        #Transformation liste listMatCompletee en matrice numpy\n",
    "        npMatCompletee = np.array(listMatCompletee)\n",
    "        #Affection au corpus interne de la fonction auquel le KMeans est applique\n",
    "        npCorpusInterneKmeansX = npMatCompletee\n",
    "        npCorpusInterneKmeansY = npMatCompletee\n",
    "        #print('npCorpusInterneKmeansX.shape-->', npCorpusInterneKmeansX.shape)\n",
    "    \n",
    "    #Creation objets Kmeans, kmeansFit(appris) et kmeansPredict(predit)\n",
    "    kmeansFit = KMeans(n_clusters=intNbClustersChosi, random_state=0).fit(npCorpusInterneKmeansX)\n",
    "    y_kmeansPredict = kmeansFit.predict(npCorpusInterneKmeansY)\n",
    "    \n",
    "    #print('Fin de la verification de la fonction builtKmeansFromCorpus')\n",
    "    return kmeansFit, y_kmeansPredict, npCorpusInterneKmeansX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildListEvalFromDataFrameMultiCorpus(dfPersClusters, intNbClusters, strNomColPers, strNomClusters, strIdTotal) :\n",
    "    #Renvoie une liste avec des evaluations de rapport entre features en pourcentage\n",
    "    #La dataframe en parametre dfPersClusters contient :\n",
    "    #En ligne : le nombre de parole de un personnage dans les clusters et son total de paroles en derniere colonne\n",
    "    #En colonne : le nombre de parole de un cluster dans les personnages et son total de parole en derniere ligne\n",
    "    \n",
    "    #Bibliotheques necessaires\n",
    "    import pandas as pd\n",
    "    import string\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    listNbParolRapportPersClus =[]\n",
    "    listVectLignePers = []\n",
    "    listMatEvalPersClus = []\n",
    "    intTotalParoleClusCour = 0\n",
    "    intTotalParolePersCour = 0\n",
    "    intParolePersClusCour = 0\n",
    "    intNbLigDataFrame = 0\n",
    "    intNbDecalIndex = 1\n",
    "    intNbChif = 4\n",
    "    intIndLigTotalClusCour = 0\n",
    "    floatRapportPersClusSurClusTotal =0.00\n",
    "    floatRapportPersClusSurPersTotal = 0.00\n",
    "    strNomColCour = ''\n",
    "    strEspace = ' '\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    #print('Debut de la verification de la fonction buildListEvalFromDataFrame ')\n",
    "    #print('Fonction en construction')\n",
    "    if (not(isinstance(dfPersClusters, pd.DataFrame))):\n",
    "        #Verification nature \n",
    "        print('Erreur nature DataFrame de la fonction buildListEvalFromDataFrameFeat')\n",
    "        print('le parametre passe dfPersClusters doit etre une dataframe valide de la bibliotheque Python pandas')\n",
    "        print('retour liste vide')\n",
    "        return []\n",
    "        \n",
    "    #Creation de la pandas DataFrame avec evaluation indices (pourcentages)\n",
    "    #Initialialisation\n",
    "    dfPersClusIndicesEval = dfPersClusters.copy()\n",
    "    intNbLigDataFrame = len(dfPersClusters)\n",
    "    intIndLigTotalClusCour = intNbLigDataFrame - intNbDecalIndex #Indice ligne des totaux des clusters\n",
    "    listMatEvalPersClus = []\n",
    "    \n",
    "    #print('Entree boucle intIndexLig')\n",
    "    #Boucles de parcours de la dataframe\n",
    "    for intIndexLig in range(intNbLigDataFrame):\n",
    "        #Parcours des lignes\n",
    "        #print('Entree try')\n",
    "        try :\n",
    "            #Reinitialisation\n",
    "            intTotalParolePersCour = dfPersClusIndicesEval[strIdTotal][intIndexLig]\n",
    "            listVectLignePers = []\n",
    "        except :\n",
    "            print('Erreur nommage interne dataframe dfPersClusIndicesEval de la fonction buildListEvalFromDataFrame')\n",
    "            print('retour de la liste vide')\n",
    "            return []\n",
    "        #Construction du vecteur ligne [NomPers, Clusters, Total]\n",
    "        listVectLignePers.append(dfPersClusIndicesEval[strNomColPers][intIndexLig])\n",
    "        #print('listVectLignePers -->', listVectLignePers)\n",
    "        #Ajout des clusters et leur evaluation en liste\n",
    "        for intIndexClus in range(intNbClusters):\n",
    "            #Parcours des colonnes de clusters strNomClusters\n",
    "            #Reinitialisation des variables\n",
    "            listNbParolRapportPersClus =[]\n",
    "            #Construction Nom colonne courante \n",
    "            strNomColCour = strNomClusters + strEspace + str(intIndexClus)\n",
    "            #Application des indices evaluation\n",
    "            #Recuperation des donnees\n",
    "            intParolePersClusCour = dfPersClusIndicesEval[strNomColCour][intIndexLig]\n",
    "            intTotalParoleClusCour = dfPersClusIndicesEval[strNomColCour][intIndLigTotalClusCour]\n",
    "            #Calcul des indices(pourcentage) pour evaluation\n",
    "            #print('intTotalParoleClusCour-->', intTotalParoleClusCour)\n",
    "            floatRapportPersClusSurClusTotal = intParolePersClusCour/intTotalParoleClusCour\n",
    "            floatRapportPersClusSurPersTotal = intParolePersClusCour/intTotalParolePersCour\n",
    "            #print('floatRapportPersClusSurPersTotal -->', floatRapportPersClusSurPersTotal)\n",
    "            #Construction liste pourcentages et nombre de paroles du personnage dans le cluster\n",
    "            listNbParolRapportPersClus.append(round(floatRapportPersClusSurPersTotal, intNbChif))\n",
    "            listNbParolRapportPersClus.append(round(floatRapportPersClusSurClusTotal, intNbChif))\n",
    "            #listNbParolRapportPersClus.append(intParolePersClusCour)\n",
    "            #Affectation de la liste cluster evalue listNbParolRapportPersClus au vecteur ligne listVectLignePers\n",
    "            listVectLignePers.append(listNbParolRapportPersClus)\n",
    "        #Fin de la boucle de parcours des colonnes de clusters\n",
    "        #Ajout du total des paroles du personnage courant\n",
    "        listVectLignePers.append(dfPersClusIndicesEval[strIdTotal][intIndexLig])\n",
    "        #Ajout du vecteur ligne a la matrice tableau evaluation\n",
    "        listMatEvalPersClus.append(listVectLignePers)\n",
    "    \n",
    "    #print('Fin de la verification de la fonction buildListEvalFromDataFrame')\n",
    "    #Retour de la fonction\n",
    "    return listMatEvalPersClus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildListEvalFromDataFrame(dfPersClusters, intNbClusters, strNomColPers, strNomClusters, strIdTotal) :\n",
    "    #Renvoie une liste avec des evaluations de rapport entre features en pourcentage\n",
    "    #La dataframe en parametre dfPersClusters contient :\n",
    "    #En ligne : le nombre de parole de un personnage dans les clusters et son total de paroles en derniere colonne\n",
    "    #En colonne : le nombre de parole de un cluster dans les personnages et son total de parole en derniere ligne\n",
    "    \n",
    "    #Bibliotheques necessaires\n",
    "    import pandas as pd\n",
    "    import string\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    listNbParolRapportPersClus =[]\n",
    "    listVectLignePers = []\n",
    "    listMatEvalPersClus = []\n",
    "    intTotalParoleClusCour = 0\n",
    "    intTotalParolePersCour = 0\n",
    "    intParolePersClusCour = 0\n",
    "    intNbLigDataFrame = 0\n",
    "    intNbDecalIndex = 1\n",
    "    intNbChif = 4\n",
    "    intIndLigTotalClusCour = 0\n",
    "    floatRapportPersClusSurClusTotal =0.00\n",
    "    floatRapportPersClusSurPersTotal = 0.00\n",
    "    strNomColCour = ''\n",
    "    strEspace = ' '\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    #print('Debut de la verification de la fonction buildListEvalFromDataFrame ')\n",
    "    #print('Fonction en construction')\n",
    "    if (not(isinstance(dfPersClusters, pd.DataFrame))):\n",
    "        #Verification nature \n",
    "        print('Erreur nature DataFrame de la fonction buildListEvalFromDataFrameFeat')\n",
    "        print('le parametre passe dfPersClusters doit etre une dataframe valide de la bibliotheque Python pandas')\n",
    "        print('retour liste vide')\n",
    "        return []\n",
    "        \n",
    "    #Creation de la pandas DataFrame avec evaluation indices (pourcentages)\n",
    "    #Initialialisation\n",
    "    dfPersClusIndicesEval = dfPersClusters.copy()\n",
    "    intNbLigDataFrame = len(dfPersClusters)\n",
    "    intIndLigTotalClusCour = intNbLigDataFrame - intNbDecalIndex #Indice ligne des totaux des clusters\n",
    "    listMatEvalPersClus = []\n",
    "    \n",
    "    #print('Entree boucle intIndexLig')\n",
    "    #Boucles de parcours de la dataframe\n",
    "    for intIndexLig in range(intNbLigDataFrame):\n",
    "        #Parcours des lignes\n",
    "        #print('Entree try')\n",
    "        try :\n",
    "            #Reinitialisation\n",
    "            intTotalParolePersCour = dfPersClusIndicesEval[strIdTotal][intIndexLig]\n",
    "            listVectLignePers = []\n",
    "        except :\n",
    "            print('Erreur nommage interne dataframe dfPersClusIndicesEval de la fonction buildListEvalFromDataFrame')\n",
    "            print('retour de la liste vide')\n",
    "            return []\n",
    "        #Construction du vecteur ligne [NomPers, Clusters, Total]\n",
    "        listVectLignePers.append(dfPersClusIndicesEval[strNomColPers][intIndexLig])\n",
    "        #print('listVectLignePers -->', listVectLignePers)\n",
    "        #Ajout des clusters et leur evaluation en liste\n",
    "        for intIndexClus in range(intNbClusters):\n",
    "            #Parcours des colonnes de clusters strNomClusters\n",
    "            #Reinitialisation des variables\n",
    "            listNbParolRapportPersClus =[]\n",
    "            #Construction Nom colonne courante \n",
    "            strNomColCour = strNomClusters + strEspace + str(intIndexClus)\n",
    "            #Application des indices evaluation\n",
    "            #Recuperation des donnees\n",
    "            intParolePersClusCour = dfPersClusIndicesEval[strNomColCour][intIndexLig]\n",
    "            intTotalParoleClusCour = dfPersClusIndicesEval[strNomColCour][intIndLigTotalClusCour]\n",
    "            #Calcul des indices(pourcentage) pour evaluation\n",
    "            #print('intTotalParoleClusCour-->', intTotalParoleClusCour)\n",
    "            floatRapportPersClusSurClusTotal = intParolePersClusCour/intTotalParoleClusCour\n",
    "            floatRapportPersClusSurPersTotal = intParolePersClusCour/intTotalParolePersCour\n",
    "            #print('floatRapportPersClusSurPersTotal -->', floatRapportPersClusSurPersTotal)\n",
    "            #Construction liste pourcentages et nombre de paroles du personnage dans le cluster\n",
    "            listNbParolRapportPersClus.append(round(floatRapportPersClusSurPersTotal, intNbChif))\n",
    "            listNbParolRapportPersClus.append(round(floatRapportPersClusSurClusTotal, intNbChif))\n",
    "            listNbParolRapportPersClus.append(intParolePersClusCour)\n",
    "            #Affectation de la liste cluster evalue listNbParolRapportPersClus au vecteur ligne listVectLignePers\n",
    "            listVectLignePers.append(listNbParolRapportPersClus)\n",
    "        #Fin de la boucle de parcours des colonnes de clusters\n",
    "        #Ajout du total des paroles du personnage courant\n",
    "        listVectLignePers.append(dfPersClusIndicesEval[strIdTotal][intIndexLig])\n",
    "        #Ajout du vecteur ligne a la matrice tableau evaluation\n",
    "        listMatEvalPersClus.append(listVectLignePers)\n",
    "    \n",
    "    #print('Fin de la verification de la fonction buildListEvalFromDataFrame')\n",
    "    #Retour de la fonction\n",
    "    return listMatEvalPersClus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFileToListLig(pwdRepFile, pwdNomFile, pwdExtFile) :\n",
    "    #Renvoie la liste des lignes contenues dans un fichier\n",
    "    \n",
    "    #Importation des bibliotheques necesaires\n",
    "    import os, sys\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    inReadLigConc_file = ''\n",
    "    listLigFile = []\n",
    "    listLigSansSaut =[]\n",
    "    intChoixSelec = 0\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    #print('Debut verification de la fonction readFileToListLig')\n",
    "    #Creation chemin access\n",
    "    inReadLigConc_file = pwdRepFile + '/' + pwdNomFile + '.' + pwdExtFile\n",
    "    \n",
    "    try :\n",
    "        #Ouverture du fichier\n",
    "        fo = open(inReadLigConc_file, 'r')\n",
    "    except :\n",
    "        print ('Erreur parametre chemin access de la fonction readFileToListLig')\n",
    "        print('retour liste vide')\n",
    "        return []\n",
    "    \n",
    "    for line in fo :\n",
    "        #lecture ligne par ligne du fichier et ajout a la liste\n",
    "        listLigSansSaut = line.split('\\n')\n",
    "        listLigFile.append(listLigSansSaut[intChoixSelec])\n",
    "    \n",
    "    #Instruction de fermeture\n",
    "    fo.close()\n",
    "    \n",
    "    #print('Fin verification de la fonction readFileToListLig')\n",
    "    #Retour de la fonction\n",
    "    return listLigFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCorpusFromFile(pwdRepRessources, strNomOeuvre, pwdNomFileRes, pwdExtSourceRes) :\n",
    "    #Extrait les corpus corpusCsvTexte, corpusLabelPers et corpusProsodie de un fichier conteneur de corpus\n",
    "    \n",
    "    #Variables de la fonction\n",
    "    corpusCsvTexte = [] \n",
    "    corpusLabelPers = [] \n",
    "    corpusProsodie =[]\n",
    "    \n",
    "    #Corps de la fonction\n",
    "    #print('Debut de verification de la fonction extractCorpusFromFile')\n",
    "    #Construction chemin access\n",
    "    inProsodieConc_file = pwdRepRessources + '/' + strNomOeuvre + '_' + pwdNomFileRes + '.' + pwdExtSourceRes\n",
    "    #Ouverture du fichier\n",
    "    fo = open(inProsodieConc_file, 'r')\n",
    "    #Lecture premiere ligne sauvegarde np\n",
    "    #print('Lecture du corpus sous forme textuel de base, du fichier')\n",
    "    ligTxtCorpusProsodyNumPy=fo.readline()\n",
    "    sep=fo.readline()\n",
    "    for line in fo :\n",
    "        #lecture ligne par ligne du fichier\n",
    "        \n",
    "        corpusCsvTexte.append(line)\n",
    "        reLine = line.replace(\"[\", \"\")\n",
    "        reLineBis = reLine.replace(\"]\", \"\")\n",
    "        reLine = reLineBis.replace(\"'\", \"\")\n",
    "        corpusLabelPers.append(reLine.split(',')[0:3])\n",
    "        corpusProsodie.append(reLine.split(',')[3:])\n",
    "    \n",
    "    #print('Fin de verification de la fonction extractCorpusFromFile')\n",
    "    #Retour fonction\n",
    "    return corpusCsvTexte, corpusLabelPers, corpusProsodie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloc Fonctions : OK\n"
     ]
    }
   ],
   "source": [
    "print('Bloc Fonctions : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programme Principal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Exemple et Essai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelCluster---> [1 1 1 0 0 0]\n",
      "predictBelongCluster---> [1 0]\n",
      "centerClusters---> [[10.  2.]\n",
      " [ 1.  2.]]\n",
      "Bloc Exemple et Essai : OK\n"
     ]
    }
   ],
   "source": [
    "#Bloc exemple et essai\n",
    "# Programme Principal\n",
    "#Exemple\n",
    "X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "\t\t[10, 2], [10, 4], [10, 0]])\n",
    "kmeans2 = KMeans(n_clusters=2, random_state=0).fit(X)\n",
    "print('labelCluster--->', kmeans2.labels_)\n",
    "print('predictBelongCluster--->', kmeans2.predict([[0, 0], [12, 3]]))\n",
    "print('centerClusters--->', kmeans2.cluster_centers_)\n",
    "\n",
    "#ExempleEssai\n",
    "Xessai = np.array([[173.08, 0.18, 1.7, 0.51, -2.2, 6.09, 1.95, 2.71, -2.45, 1.12, -2.86, 1.73, -0.93, 0.58, -2.3, 1.09, 14.31, -4.62, 0.86, 3.59, 2.1, -2.98, 5.42, -2.3, 3.01, -5.5, 8.67, -2.3, 3.54, 0.21, -8.67, 3.81, 14.9, 9.28, -9.81, 19.39, -5.89, 12.34, -21.15, 28.06, -6.39, 14.89, 1.54, 14.18, -2.99, -10.02, -7.26, 12.36, -20.3, 9.43, -9.9, 16.98, -30.09, 9.35, -12.44, 0.36, 5.33, 0.36, 1.84, 0.36, 23.55], \n",
    "\t\t\t[301.67, 0.14, 1.14, 0.53, 3.3, -2.56, -6.87, -3.36, -7.36, 1.29, -4.96, -2.37, -1.31, -4.3, -5.34, 0.93, 17.84, 1.79, -2.66, -1.22, -1.89, -1.08, 5.07, -1.2, -2.44, -4.9, -1.2, -0.94, 5.04, 0.1, 3.76, -6.75, -2.3, -2.87, -3.01, 17.58, -2.64, -7.3, -9.39, -2.56, -1.45, 13.77, 1.23, -6.21, 6.49, 3.17, 6.01, 3.53, -9.98, 5.13, 8.2, 10.5, 4.06, 2.92, -11.88, 0.64, 5.74, 0.44, 1.74, 0.46, 1.78], \n",
    "\t\t\t[201.94, 0.23, 1.85, 0.47, 0.06, 6.94, 1.17, 1.67, -4.08, -0.09, -3.73, 0.95, -2.12, -0.24, -2.85, 0.78, 15.36, 164.32, 0.82, 6.11, 3.52, -1.72, -70.1, -1.64, 5.98, -2.42, -22.41, -1.72, 5.05, 0.19, 284.08, 4.13, 23.83, 13.47, -5.46, -281.92, -5.41, 22.25, -7.89, -70.19, -5.73, 22.05, 1.52, -510.53, -1.86, -17.28, -12.7, 7.43, 240.78, 7.45, -21.74, 9.54, 86.35, 8.35, -17.58, 0.66, 5.28, 0.26, 1.55, 0.47, 23.45]])\t\t#\t[3 = np.array(listArrayCalibree) = np.array(listArrayCalibree)37.29, 0.09, 1.17, 0.52, -1.19, 0.17, -4.35, -2.79, -8.82, -0.9, -3.12, -2.31, -1.04, -3.27, -2.08, -1.0, 15.53, -6.7, 28.97, -1.91, -2.47, -0.94, -8.14, -1.81, -2.79, -5.26, -1.59, -2.27, -4.19, 0.24, -9.05, 87.01, -4.77, -3.92, -1.06, -23.64, -3.67, -5.31, -13.44, -4.58, -4.65, -9.69, 1.36, 22.38, -87.15, 4.18, 7.24, 3.45, 22.61, 5.26, 8.97, 12.95, 5.43, 8.01, 12.25, 0.66, 5.58, 0.42, 1.63, 0.41, 2.63]])\n",
    "\n",
    "#kmeansEssai = KMeans(n_clusters=2, random_state=0).fit(Xessai)\n",
    "#print('labelCluster--->', kmeansEssai.labels_)\n",
    "#print('predictBelongCluster--->', kmeans.predict([[0, 0], [12, 3]]))\n",
    "#print('centerClusters--->', kmeansEssai.cluster_centers_)\n",
    "\n",
    "print('Bloc Exemple et Essai : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Arguments Programme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#bloc arguments programme\n",
    "\n",
    "#parser permet de definir les argument du run du fichier python\n",
    "parser = argparse.ArgumentParser(description='Lecture Tableau Prosodie Personnage')\n",
    "parser.add_argument('inProsodie_file', type=str, help='input prosodie descriptor csv file name')\n",
    "parser.add_argument('vocabulaire_file', type=str, help='dict vocab txt file name')\n",
    "parser.add_argument('dtp_file', type=str, help='document term pers txt file name')\n",
    "\n",
    "#Creation du tableau d'argument du run :\n",
    "# echo est un argument de run du fichier : -$ python nomFichier.py echo\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Recuperation des arguments du run\n",
    "inProsodie_file = args.inProsodie_file\t\n",
    "vocabulaire_file = args.vocabulaire_file\n",
    "dtp_file = args.dtp_file\n",
    "\n",
    "print('Bloc Arguments Programme : OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviation Bloc Arguments Programme : OK\n"
     ]
    }
   ],
   "source": [
    "#Particularite de Jupyter NoteBook\n",
    "#pwd des fichier a ouvrir\n",
    "inProsodie_file = './RessourceData/chevalier_filledupirate_tabDesAudioProsodieX.csv'\n",
    "print('Deviation Bloc Arguments Programme : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Variables Programme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloc Variables Programme : OK\n"
     ]
    }
   ],
   "source": [
    "#Variables du programme\n",
    "corpusCsvTexte =[]\n",
    "corpusLabelPers =[]\n",
    "corpusProsodie =[]\n",
    "corpusFloatProsodie =[]\n",
    "corpusSVM = []\n",
    "descripteur = []\n",
    "descripteurData = []\n",
    "descripteurTarget = []\n",
    "y_test=[]\n",
    "y_train = []\n",
    "X_train = []\n",
    "X_test = []\n",
    "npProsodie =[]\n",
    "npProsodieAnoteComplet = []\n",
    "listPersClusters = []\n",
    "listIndSelectFeat = []\n",
    "listVectSegAnotComplet = []\n",
    "listVectCourSVM = []\n",
    "listVectLigTab = []\n",
    "listIdClasseSVM = []\n",
    "listTabAnalyseSVM =[]\n",
    "listTabAnalyseCrossValSVM = []\n",
    "listTabPourcentCrossValSVM =[]\n",
    "listComposeNomOeuvre = []\n",
    "intCoteDimVectF0_SpRa = 4\n",
    "intCoteDimVectMfcc = 52\n",
    "intCoteDimVectDuree = 1\n",
    "intPosFeatF0 =0\n",
    "intPosFeatMFCC =1\n",
    "intPosFeatSpRa =2\n",
    "intPosFeatDuree =3\n",
    "intPosIdPers = 1\n",
    "intPosIdOeuvre = 0\n",
    "intPosLabelPers = 4\n",
    "intPosFeatProsodie = 1\n",
    "intPosClusMaj = 3\n",
    "intPosLabelCluster = 2\n",
    "intPosClasseSVM = 1\n",
    "intPosDesData = 0\n",
    "intPosDesTarget = 1\n",
    "intPosAuteur = 0\n",
    "intPosTitreOeuvre = 1\n",
    "intNbChifArrondi = 2\n",
    "intNbFeatLabelPers = 3 # partie du vecteur correspondant a idPers, Utterance, Nom Oeuvre - Chapitre\n",
    "intNbClusters = 6\n",
    "intNbClasseSVM = 0\n",
    "intDimCoteFeat = 0\n",
    "intSeuilNbSeg = 20\n",
    "intCompteur =0\n",
    "intIndexLigTabSVM = 0\n",
    "intIndexColTabSVM = 0\n",
    "intIdClusterMagoritaire = -1\n",
    "intIdClasseSVM = -1\n",
    "intTailleSetAnalyseSVM = 0\n",
    "intRapportAdaptClasse = -1\n",
    "floatProportPourcent = 0.00\n",
    "dicoPersClusters ={}\n",
    "dictClasseSVM = {}\n",
    "strIdNaratteur = ' _'\n",
    "strIdNonNar = 'NonNarrateur' \n",
    "strIdFauxPersDesacord = '/t'\n",
    "strLabelMfcc = 'Mfcc'\n",
    "strLabelF0 = 'F0'\n",
    "strLabelSpeechRate = 'SpRa'\n",
    "strLabelDureeParole = 'Duree'\n",
    "strLabelToutProsodie = 'ToutProsodie'\n",
    "strTypeIndEval = 'PourcentRep'\n",
    "strNomColPers = 'Pers'\n",
    "strNomClusters = 'Cluster'\n",
    "strIdTotal = 'Total'\n",
    "strNomOeuvre = 'zeltner_contes'\n",
    "strTyCo = 'multi'\n",
    "strTyGrNarNonNar = 'PersGroupGrNarNonNar'\n",
    "strTyGrPersNonNar = 'PersGroupNonNarrateur'\n",
    "strKeyPrec = 'Precision'\n",
    "strKeyRap = 'Rappel'\n",
    "strIdCompletPersCour = 'Pers.Oeuvre'\n",
    "strNomOeuvre = 'Oeuvre'\n",
    "strSepIntOeuvre = '_'\n",
    "pwdRepRessources = './RessourceData'\n",
    "pwdNomFileRes = 'tabDesAudioProsodieX'\n",
    "pwdExtSourceRes ='csv'\n",
    "pwdDesFileTabClassSVM = 'TabClassSVM'\n",
    "pwdDesFileTabCrossValSVM = 'TabCrossVal'\n",
    "pwdTypeProp = 'EnPourcent'\n",
    "boolSameStrictPers = False \n",
    "\n",
    "print('Bloc Variables Programme : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Corps du Programme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Composition Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloc Composition Variables : OK\n"
     ]
    }
   ],
   "source": [
    "intDimToutFeatProsodie = intCoteDimVectF0_SpRa + intCoteDimVectF0_SpRa + intCoteDimVectMfcc + intCoteDimVectDuree\n",
    "\n",
    "print('Bloc Composition Variables : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Chemin Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Identiques. Ressources data --> ./RessourceData/ensemble_oeuvres_tabDesAudioProsodieX.csv\n",
      "pwdFileMatricePersClustersCsv--> ./ResultatNoteBook/TestBrouillon/MatTestT210BrNbClusters6_PersGroupNonNarrateur_F0_ensemble_oeuvres.csv\n",
      "pwdFileMatricePersClustersExcel--> ./ResultatNoteBook/FormatExcel/MatTestT210BrNbClusters6_PersGroupNonNarrateur_F0_ensemble_oeuvres.xlsx\n",
      "pwdFileImgPersClusters--> ./ResultatNoteBook/FormatImage/MatTestT210BrNbClusters6_PersGroupNonNarrateur_F0_ensemble_oeuvres.png\n",
      "pwdFileMatricePersClustersIndEvalCsv--> ./ResultatNoteBook/TestBrouillon/MatTestT210BrNbClusters6_PourcentRep_PersGroupNonNarrateur_F0_ensemble_oeuvres.csv\n",
      "pwdFileMatricePersClustersIndEvalExcel--> ./ResultatNoteBook/FormatExcel/MatTestT210BrNbClusters6_PourcentRep_PersGroupNonNarrateur_F0_ensemble_oeuvres.xlsx\n",
      "Bloc Chemin Access : OK\n"
     ]
    }
   ],
   "source": [
    "#Creation des chemin access\n",
    "#Exemple Chemin access\n",
    "inProsodie_file = './RessourceData/chevalier_filledupirate_tabDesAudioProsodieX.csv'\n",
    "#fig.savefig('./ResultatNoteBook/FormatImage/MatClus2PersgroupGrNonNarrPersF0_filleDuPirate.png')\n",
    "pwdFileMatricePersClustersCsv = './ResultatNoteBook/FormatCsv/MatClus2PersgroupGrNonNarrPersF0_filleDuPirate.csv'\n",
    "pwdFileMatricePersClustersExcel = './ResultatNoteBook/FormatExcel/MatClus2PersgroupGrNonNarrPersF0_filleDuPirate.xlsx'\n",
    "\n",
    "#Concatenation des elements des chemins access sur les modeles exemples\n",
    "#Variables de partie changeante des chemins access\n",
    "strNomOeuvre = 'ensemble_oeuvres'\n",
    "strTypeGroupe = 'PersGroupNonNarrateur'\n",
    "strFeatureUsed = 'F0'\n",
    "pwdExtSourceRes ='csv'\n",
    "pwdExtResTab = 'xlsx'\n",
    "pwdExtResImg = 'png'\n",
    "\n",
    "#Constantes\n",
    "pwdRepRessources = './RessourceData'\n",
    "pwdRepResultatParent = './ResultatNoteBook'\n",
    "pwdNomFileRes = 'tabDesAudioProsodieX'\n",
    "pwdRepFormatCsv = 'TestBrouillon'\n",
    "pwdRepFormatExcel = 'FormatExcel'\n",
    "pwdRepFormatImg = 'FormatImage'\n",
    "pwdDescFileRes = 'MatTestT210BrNbClusters'\n",
    "pwdDesFileTabClassSVM = 'TabClassSVM'\n",
    "pwdDesFileTabCrossValSVM = 'TabCrossVal'\n",
    "pwdTypeProp = 'EnPourcent'\n",
    "pwdDesFileDicoClasse = 'DicoClasseSVM'\n",
    "pwdDesFileCorpusRes = 'CorpusRes'\n",
    "\n",
    "#Creation\n",
    "inProsodieConc_file = pwdRepRessources + '/' + strNomOeuvre + '_' + pwdNomFileRes + '.' + pwdExtSourceRes\n",
    "pwdFileMatricePersClustersCsv = pwdRepResultatParent + '/' + pwdRepFormatCsv + '/' + pwdDescFileRes + str(intNbClusters) + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtSourceRes\n",
    "pwdFileMatricePersClustersExcel = pwdRepResultatParent + '/' + pwdRepFormatExcel + '/' + pwdDescFileRes + str(intNbClusters) + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtResTab\n",
    "pwdFileImgPersClusters = pwdRepResultatParent + '/' + pwdRepFormatImg + '/' + pwdDescFileRes + str(intNbClusters) + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtResImg\n",
    "\n",
    "pwdFileMatricePersClustersIndEvalCsv = pwdRepResultatParent + '/' + pwdRepFormatCsv + '/' + pwdDescFileRes + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtSourceRes\n",
    "pwdFileMatricePersClustersIndEvalExcel = pwdRepResultatParent + '/' + pwdRepFormatExcel + '/' + pwdDescFileRes + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtResTab\n",
    "\n",
    "pwdFileMatriceClassSvmCsv = pwdRepResultatParent + '/' + pwdRepFormatCsv + '/' + pwdDesFileTabClassSVM + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtSourceRes\n",
    "pwdFileMatriceCrossValSvmCsv = pwdRepResultatParent + '/' + pwdRepFormatCsv + '/' + pwdDesFileTabCrossValSVM + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtSourceRes\n",
    "\n",
    "pwdFileMatricePourcentClassSvmCsv = pwdRepResultatParent + '/' + pwdRepFormatCsv + '/' + pwdDesFileTabClassSVM + pwdTypeProp + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtSourceRes\n",
    "pwdFileMatricePourcentCrossValSvmCsv = pwdRepResultatParent + '/' + pwdRepFormatCsv + '/' + pwdDesFileTabCrossValSVM + pwdTypeProp + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtSourceRes\n",
    "\n",
    "pwdFileDicoClasseSvmCsv = pwdRepResultatParent + '/' + pwdRepFormatCsv + '/' + pwdDesFileDicoClasse + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtSourceRes\n",
    "pwdFileCorpusResCsv = pwdRepResultatParent + '/' + pwdRepFormatCsv + '/' + pwdDesFileCorpusRes + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtSourceRes\n",
    "pwdFileDicoClasseSvmExcel = pwdRepResultatParent + '/' + pwdRepFormatExcel + '/' + pwdDesFileDicoClasse + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtResTab\n",
    "pwdFileCorpusResExcel = pwdRepResultatParent + '/' + pwdRepFormatExcel + '/' + pwdDesFileCorpusRes + str(intNbClusters) + '_' + strTypeIndEval + '_' + strTypeGroupe + '_' +  strFeatureUsed + '_' + strNomOeuvre + '.' + pwdExtResTab\n",
    "\n",
    "\n",
    "#Verification\n",
    "if inProsodieConc_file == inProsodie_file :\n",
    "    print('identique : ',inProsodieConc_file )\n",
    "else :\n",
    "    print('Non Identiques. Ressources data -->', inProsodieConc_file)\n",
    "\n",
    "#Affichage\n",
    "print('pwdFileMatricePersClustersCsv-->', pwdFileMatricePersClustersCsv)\n",
    "print('pwdFileMatricePersClustersExcel-->', pwdFileMatricePersClustersExcel)\n",
    "print('pwdFileImgPersClusters-->', pwdFileImgPersClusters)\n",
    "print('pwdFileMatricePersClustersIndEvalCsv-->', pwdFileMatricePersClustersIndEvalCsv)\n",
    "print('pwdFileMatricePersClustersIndEvalExcel-->', pwdFileMatricePersClustersIndEvalExcel)\n",
    "\n",
    "print('Bloc Chemin Access : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Ouverture Fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture individuelle non valide -> ouverture ensemble de fichiers\n",
      "Bloc Ouverture Fichier : OK\n"
     ]
    }
   ],
   "source": [
    "#Ouverture du fichier\n",
    "try :\n",
    "    fo = open(inProsodieConc_file, 'r')\n",
    "except :\n",
    "    print('Ouverture individuelle non valide -> ouverture ensemble de fichiers')\n",
    "    \n",
    "print('Bloc Ouverture Fichier : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Lecture Fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture du corpus sous forme textuel de base, du fichier\n",
      "Ouverture individuelle non valide -> ouverture ensemble de fichiers\n",
      "Bloc Lecture Fichier : OK\n"
     ]
    }
   ],
   "source": [
    "#Lecture premiere ligne sauvegarde np\n",
    "try :\n",
    "    print('Lecture du corpus sous forme textuel de base, du fichier')\n",
    "    ligTxtCorpusProsodyNumPy=fo.readline()\n",
    "    #corpusProsodyNumPy = np.fromfile(ligTxtCorpusProsodyNumPy)\n",
    "    #print('corpusProsodyNumPy[0]-->', corpusProsodyNumPy[0])\n",
    "    sep=fo.readline()\n",
    "    for line in fo :\n",
    "        #lecture ligne par ligne du fichier\n",
    "        \n",
    "        corpusCsvTexte.append(line)\n",
    "        reLine = line.replace(\"[\", \"\")\n",
    "        reLineBis = reLine.replace(\"]\", \"\")\n",
    "        reLine = reLineBis.replace(\"'\", \"\")\n",
    "        corpusLabelPers.append(reLine.split(',')[0:3])\n",
    "        corpusProsodie.append(reLine.split(',')[3:])\n",
    "except :\n",
    "   \n",
    "    print('Ouverture individuelle non valide -> ouverture ensemble de fichiers')\n",
    "\n",
    "print('Bloc Lecture Fichier : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Traitement Global et Automatique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listCorpusBaseLabelPers[0]--> ['feval_vampire_00', ' _', ' 0']\n",
      "Debut de la verification de la fonction builtCorpusGroupeSansPers\n",
      "intPosBoucle--> 1967\n",
      "Fin de la verification de la fonction builtCorpusGroupeSansPers\n",
      "listLigFile--> ['feval_vampire', 'chevalier_filledupirate', 'flaubert_madamebovary', 'merimee_carmen', 'merimee_venusdille', 'zeltner_contes']\n",
      "strNomOeuvre--> zeltner_contes\n",
      "corpusLabelPers[0]--> ['feval_vampire_00', ' papaSeverin', ' 20']\n",
      "Bloc Traitement Global et Automatique : OK\n"
     ]
    }
   ],
   "source": [
    "#Variables\n",
    "listLigFile = []\n",
    "pwdNomFile = 'listeOeuvresUtiliseesStage2019'\n",
    "pwdExtFile = 'csv'\n",
    "\n",
    "#Constantes\n",
    "pwdRepFile = './RessourceData/InfoCorpus'\n",
    "listCorpusBaseProsodie = []\n",
    "listCorpusGroupeProsodie = []\n",
    "listCorpusBaseLabelPers = []\n",
    "listCorpusGroupeLabelPers = []\n",
    "listCorpusBaseCsvTexte = []\n",
    "listCorpusGroupeCsvTexte = []\n",
    "\n",
    "\n",
    "#Appel fonction de lecture fichier liste oeuvres\n",
    "listLigFile = readFileToListLig(pwdRepFile, pwdNomFile, pwdExtFile)\n",
    "for oeuvre in listLigFile :\n",
    "    #Boucle de parcours liste de noms oeuvres\n",
    "    strNomOeuvre = oeuvre\n",
    "    corpusCsvTexte, corpusLabelPers, corpusProsodie = extractCorpusFromFile(pwdRepRessources, strNomOeuvre, pwdNomFileRes, pwdExtSourceRes)\n",
    "    #print('corpusProsodie-->', corpusProsodie)\n",
    "    #Regroupement de corpus\n",
    "    listCorpusGroupeProsodie = builtFusionCorpusList(listCorpusBaseProsodie, corpusProsodie)\n",
    "    listCorpusGroupeLabelPers = builtFusionCorpusList(listCorpusBaseLabelPers, corpusLabelPers)\n",
    "    listCorpusGroupeCsvTexte = builtFusionCorpusList(listCorpusBaseCsvTexte, corpusCsvTexte)\n",
    "    #Affectation nouveau corpus base\n",
    "    listCorpusBaseProsodie = listCorpusGroupeProsodie\n",
    "    listCorpusBaseLabelPers = listCorpusGroupeLabelPers\n",
    "    listCorpusBaseCsvTexte = listCorpusGroupeCsvTexte\n",
    " \n",
    "#Affectation poursuite\n",
    "corpusProsodie = listCorpusBaseProsodie\n",
    "corpusLabelPers = listCorpusBaseLabelPers\n",
    "corpusCsvTexte = listCorpusBaseCsvTexte\n",
    "\n",
    "#Point de controle\n",
    "print('listCorpusBaseLabelPers[0]-->', listCorpusBaseLabelPers[0])\n",
    "\n",
    "#Regroupement\n",
    "if strTypeGroupe == strTyGrNarNonNar :\n",
    "    #Verification type de regroupement\n",
    "    #Appel fonction de regroupement de personnages\n",
    "    corpusLabelPersRegroupe = builtCorpusGroupePersEtNonPers(corpusLabelPers, intPosIdOeuvre, intPosIdPers, strIdNaratteur, strIdNonNar, strTyCo)\n",
    "    #Reaffectation\n",
    "    corpusLabelPers = corpusLabelPersRegroupe\n",
    "if  strTypeGroupe == strTyGrPersNonNar :\n",
    "    #Verification type de regroupement\n",
    "    #Appel fonction de regroupement de personnages\n",
    "    corpusLabelPersRegroupe, corpusProsodieRegroupe = builtCorpusGroupeSansPers(corpusLabelPers, corpusProsodie, intPosIdOeuvre, intPosIdPers, strIdNaratteur, strTyCo)\n",
    "    #Reafectation\n",
    "    corpusLabelPers = corpusLabelPersRegroupe\n",
    "    corpusProsodie = corpusProsodieRegroupe\n",
    "    \n",
    "#Affichage\n",
    "print('listLigFile-->', listLigFile)\n",
    "print('strNomOeuvre-->', strNomOeuvre)\n",
    "print('corpusLabelPers[0]-->', corpusLabelPers[0])\n",
    "\n",
    "print('Bloc Traitement Global et Automatique : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Construction Clusters - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature-->  \n",
      "tailleDcorpusFloatProsodie--> 845\n",
      "debut de la verification de la fonction builtCalibreArrayFromListCorpus\n",
      "tupleDimArray--> (845, 4)\n",
      "Fin de la verification de la fonction builtCalibreArrayFromListCorpus\n",
      "debut de la verification de la fonction builtCalibreArrayFromListCorpus\n",
      "tupleDimArray--> (845, 4)\n",
      "Fin de la verification de la fonction builtCalibreArrayFromListCorpus\n",
      "debut de la verification de la fonction builtCalibreArrayFromListCorpus\n",
      "tupleDimArray--> (845,)\n",
      "Sous Bloc Construction Matrices Numpy Features Prosodiques >< Clustering : OK \n",
      "tupleDimArrayFusion--> (845, 56)\n",
      "tupleDimArrayFusion--> (845, 60)\n",
      "tupleDimArrayFusion--> (845, 61)\n",
      "tupleDimArrayFusion--> (845, 8)\n",
      "tupleDimArrayFusion--> (845, 9)\n",
      "tupleDimArrayFusion--> (845, 5)\n",
      "tupleDimArrayFusion--> (845, 56)\n",
      "Sous Bloc Fusion Matrices Numpy Features Prosodiques >< Clustering : OK \n",
      "strLabelF0\n",
      "corpusLabelPers[0]--> ['feval_vampire_00', ' papaSeverin', ' 20']\n",
      "tailleListLabelsClusters--> 845\n",
      "tab shape-->  (845,)\n",
      "listLabelsClusters shape-->  (845,)\n",
      "Bloc Construction Clusters - Clustering : OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "  app.launch_new_instance()\n",
      "/Users/romain/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#clustering\n",
    "\n",
    "corpusFloatProsodie = corpusStringToFloat(corpusProsodie)\n",
    "#print('corpusFloatProsodie[0][:]-->', corpusFloatProsodie[0][:])\n",
    "print('tailleDcorpusFloatProsodie-->', len(corpusFloatProsodie))\n",
    "#listVectPlat = aplanirListMiltiDimToMonoDim(corpusFloatProsodie[0])\n",
    "#npProsodie = np.asarray(corpusFloatProsodie[0])\n",
    "\n",
    "#Selection des donnees\n",
    "intCoteDimMatrice =len(corpusFloatProsodie)\n",
    "\n",
    "intCoteDimVectF0SpRa = intCoteDimVectF0_SpRa + intCoteDimVectF0_SpRa\n",
    "intCoteDimVectF0SpRaDuree = intCoteDimVectF0SpRa + intCoteDimVectDuree\n",
    "intCoteDimVectF0Duree = intCoteDimVectF0_SpRa + intCoteDimVectDuree\n",
    "intCoteDimVectMfccSpRa = intCoteDimVectMfcc + intCoteDimVectF0_SpRa\n",
    "\n",
    "#Construction des matrices numpy des features prosodiques\n",
    "npProsodieFeat1F0 = builtCalibreArrayFromListCorpus(corpusFloatProsodie, intCoteDimVectF0_SpRa, intCoteDimMatrice, intPosFeatF0)\n",
    "npProsodieFeat2Mfcc = builtCalibreArrayFromMatrix3dCorpus(corpusFloatProsodie, intCoteDimVectMfcc, intCoteDimMatrice, intPosFeatMFCC)\n",
    "npProsodieFeat3SpRa = builtCalibreArrayFromListCorpus(corpusFloatProsodie, intCoteDimVectF0_SpRa, intCoteDimMatrice, intPosFeatSpRa)\n",
    "npProsodieFeat4Duree = builtCalibreArrayFromListCorpus(corpusFloatProsodie, intCoteDimVectDuree, intCoteDimMatrice, intPosFeatDuree)\n",
    "\n",
    "print('Sous Bloc Construction Matrices Numpy Features Prosodiques >< Clustering : OK ')\n",
    "\n",
    "#Fusion des matrices numpy de features prosodiques\n",
    "npProsodieFusion = builtFusionArrayCalibre(npProsodieFeat1F0, npProsodieFeat2Mfcc, 56, intCoteDimMatrice)\n",
    "npProsodieFusion2 = builtFusionArrayCalibre(npProsodieFusion, npProsodieFeat3SpRa, 60, intCoteDimMatrice)\n",
    "npProsodieFusion3 = builtFusionArrayCalibre(npProsodieFusion2, npProsodieFeat4Duree, 61, intCoteDimMatrice)\n",
    "\n",
    "npPrososodieFusionF0SpRa = builtFusionArrayCalibre(npProsodieFeat1F0, npProsodieFeat3SpRa, intCoteDimVectF0SpRa,  intCoteDimMatrice)\n",
    "npPrososodieFusionF0SpRaDuree = builtFusionArrayCalibre(npPrososodieFusionF0SpRa, npProsodieFeat4Duree, intCoteDimVectF0SpRaDuree,  intCoteDimMatrice)\n",
    "npPrososodieFusionF0Duree = builtFusionArrayCalibre(npProsodieFeat1F0, npProsodieFeat4Duree, intCoteDimVectF0Duree, intCoteDimMatrice)\n",
    "npPrososodieFusionMfccSpRa = builtFusionArrayCalibre(npProsodieFeat2Mfcc, npProsodieFeat3SpRa, intCoteDimVectMfccSpRa,  intCoteDimMatrice)\n",
    "\n",
    "print('Sous Bloc Fusion Matrices Numpy Features Prosodiques >< Clustering : OK ')\n",
    "\n",
    "\n",
    "#Listes indices de paroles\n",
    "listIndTouteParole = list(range(intCoteDimMatrice))\n",
    "\n",
    "listIndParoleNarr = builtListIndVectParolePers(corpusLabelPers, intPosIdPers, strIdNaratteur, boolSameStrictPers)\n",
    "listIndParoleNonNarr = retirerListeL2deListeL1(listIndTouteParole, listIndParoleNarr)\n",
    "\n",
    "listIndParolePers0 = builtListIndVectParolePers(corpusLabelPers, intPosIdPers, ' pers0', boolSameStrictPers)\n",
    "listIndParolePers1 = builtListIndVectParolePers(corpusLabelPers, intPosIdPers, ' pers1', boolSameStrictPers)\n",
    "listIndParolePers2 = builtListIndVectParolePers(corpusLabelPers, intPosIdPers, ' pers2', boolSameStrictPers)\n",
    "listIndParolePers3 = builtListIndVectParolePers(corpusLabelPers, intPosIdPers, ' pers3', boolSameStrictPers)\n",
    "listIndParolePers4 = builtListIndVectParolePers(corpusLabelPers, intPosIdPers, ' pers4', boolSameStrictPers)\n",
    "\n",
    "listIndParoleNarrRegroup = listIndParolePers0 + listIndParoleNarr\n",
    "listIndParoleNonNarr = retirerListeL2deListeL1(listIndTouteParole, listIndParoleNarrRegroup)\n",
    "\n",
    "\n",
    "#Vecteur de indices de selection de donnees\n",
    "#listIndSelectFeat =\n",
    "#Generateur de indices\n",
    "#listIndSelectFeat = list(range(intCoteDimVectMfcc))\n",
    "listIndSelectVect = list(range(intCoteDimMatrice))\n",
    "\n",
    "listIndSelectFeatLabelPers =list(range(intNbFeatLabelPers))\n",
    "\n",
    "\n",
    "#Selection des donnees\n",
    "#Chargement Ensemble des donnees\n",
    "#npProsodie = builtSelectVectFeatArrayCalibree(npProsodieFeat2Mfcc, listIndSelectVect, listIndSelectFeat)\n",
    "#Corpus de decoupage Ensemble des donnees\n",
    "#npProsodieNonNarr =builtSelectVectFeatArrayCalibree(npProsodieFeat1F0, listIndParoleNonNarr, listIndSelectFeat)\n",
    "#npProsodieNarr =builtSelectVectFeatArrayCalibree(npProsodieFeat1F0, listIndParoleNarr, listIndSelectFeat)\n",
    "#npProsodie = npProsodieNonNarr\n",
    "\n",
    "\n",
    "if(strFeatureUsed == strLabelF0) :\n",
    "    #Choix de la feature selectionnee F0\n",
    "    #Generateur de indices\n",
    "    print('strLabelF0')\n",
    "    listIndSelectFeat = list(range(intCoteDimVectF0_SpRa))\n",
    "    #Chargement Ensemble des donnees\n",
    "    npProsodie = builtSelectVectFeatArrayCalibree(npProsodieFeat1F0, listIndSelectVect, listIndSelectFeat)\n",
    "\n",
    "if(strFeatureUsed == strLabelSpeechRate) :\n",
    "    #Choix de la feature selectionnee Speech Rate\n",
    "    #Generateur de indices\n",
    "    print('strLabelSpeechRate')\n",
    "    listIndSelectFeat = list(range(intCoteDimVectF0_SpRa))\n",
    "    #Chargement Ensemble des donnees\n",
    "    npProsodie = builtSelectVectFeatArrayCalibree(npProsodieFeat3SpRa, listIndSelectVect, listIndSelectFeat)\n",
    "\n",
    "if(strFeatureUsed == strLabelMfcc) :\n",
    "    #Choix de la feature selectionnee MFCC\n",
    "    print('strLabelMfcc')\n",
    "    #Generateur de indices\n",
    "    listIndSelectFeat = list(range(intCoteDimVectMfcc))\n",
    "    #Chargement Ensemble des donnees\n",
    "    npProsodie = builtSelectVectFeatArrayCalibree(npProsodieFeat2Mfcc, listIndSelectVect, listIndSelectFeat)\n",
    "    print('choixFeature-intCoteDimVectMfcc-->', intCoteDimVectMfcc)\n",
    "\n",
    "if(strFeatureUsed == strLabelDureeParole) :\n",
    "    #Choix de features selectionnee duree de la parole\n",
    "    print('strLabelDureeParole')\n",
    "    #Generateur de indices\n",
    "    listIndSelectFeat = list(range(intCoteDimVectDuree))\n",
    "    #Chargement Ensemble des donnees\n",
    "    npProsodie = builtSelectVectFeatArrayCalibree(npProsodieFeat4Duree, listIndSelectVect, listIndSelectFeat)\n",
    "\n",
    "if(strFeatureUsed == strLabelToutProsodie) :\n",
    "    #Choix de l ensemble features selectionnees prosodiques\n",
    "    print('strLabelToutProsodie')\n",
    "    #Generateur de indices\n",
    "    listIndSelectFeat = list(range(intDimToutFeatProsodie))\n",
    "    #Chargement Ensemble des donnees\n",
    "    print('len listIndSelectVect-->', len(listIndSelectVect))\n",
    "    npProsodie = builtSelectVectFeatArrayCalibree(npProsodieFusion3, listIndSelectVect, listIndSelectFeat)\n",
    "    \n",
    "if strFeatureUsed == (strLabelF0 + strLabelSpeechRate + strLabelDureeParole) :\n",
    "    #Choix de l ensemble features prosodiques sans MFCC\n",
    "    print('strLabelF0 + strLabelSpeechRate + strLabelDureeParole')\n",
    "    #Generateur de indices\n",
    "    listIndSelectFeat = list(range(intCoteDimVectF0SpRaDuree))\n",
    "    #Chargement Ensemble des donnees\n",
    "    print('len listIndSelectVect-->', len(listIndSelectVect))\n",
    "    npProsodie = builtSelectVectFeatArrayCalibree(npPrososodieFusionF0SpRaDuree, listIndSelectVect, listIndSelectFeat)\n",
    "\n",
    "if strFeatureUsed == (strLabelF0 + strLabelDureeParole) :\n",
    "    #Choix de l union features prosodiques F0 et Duree\n",
    "    print('strLabelF0 + strLabelDureeParole')\n",
    "    #Generateur de indices\n",
    "    listIndSelectFeat = list(range(intCoteDimVectF0Duree))\n",
    "    #Chargement Ensemble des donnees\n",
    "    print('len listIndSelectVect-->', len(listIndSelectVect))\n",
    "    npProsodie = builtSelectVectFeatArrayCalibree(npPrososodieFusionF0Duree, listIndSelectVect, listIndSelectFeat)\n",
    "\n",
    "if strFeatureUsed == (strLabelMfcc + strLabelSpeechRate) :\n",
    "    #Choix de l ensemble features prosodiques MFCC et Speech Rate\n",
    "    print('strLabelMfcc + strLabelSpeechRate')\n",
    "    #Generateur de indices\n",
    "    listIndSelectFeat = list(range(intCoteDimVectMfccSpRa))\n",
    "    #Chargement Ensemble des donnees\n",
    "    print('len listIndSelectVect-->', len(listIndSelectVect))\n",
    "    npProsodie = builtSelectVectFeatArrayCalibree(npPrososodieFusionMfccSpRa, listIndSelectVect, listIndSelectFeat)\n",
    "\n",
    "#Affectation post choix des descripteurs etudies\n",
    "intDimCoteFeat = len(listIndSelectFeat)\n",
    "    \n",
    "#Regroupement des personnages identiques\n",
    "listLabelPersReg = builtCorpusRegroupePersDesacord(corpusLabelPers, intPosIdPers, strIdFauxPersDesacord)\n",
    "listLabelPersReg2 = builtCorpusRegroupePers1EnPers2(listLabelPersReg, intPosIdPers, ' pers0', strIdNaratteur)\n",
    "print('corpusLabelPers[0]-->', corpusLabelPers[0])\n",
    "\n",
    "#Liste des labels a adapter a la taille du groupe de personnages etudies\n",
    "listLabelPers = builtSelectVectFeatArrayCalibree(np.array(listLabelPersReg2), listIndTouteParole, listIndSelectFeatLabelPers)\n",
    "\n",
    "#print('listIndParoleNarr-->', listIndParoleNarr)\n",
    "\n",
    "#Chargement Donnees choisies\n",
    "#npProsodie = builtSelectVectFeatArrayCalibree(npProsodieFusion, listIndParoleNarr, listIndSelectFeat)\n",
    "#listLabelPers = builtListSelectVectFromListCorpus(corpusLabelPers, listIndParoleNarr)\n",
    "\n",
    "#print('npProsodie-->', npProsodie)\n",
    "#print('listVectPlat-->', listVectPlat)\n",
    "\n",
    "#Creation Kmeans avec un npCorpus modifiee pour besoins Kmeans si npCorpus de depart unidimensionnel\n",
    "kmeansClusterPersBuild, y_kmeansClusterPers, npProsodie = builtKmeansFromCorpus(intNbClusters, npProsodie, npProsodie)\n",
    "listLabelsClusters = kmeansClusterPersBuild.labels_\n",
    "print('tailleListLabelsClusters-->', len(listLabelsClusters))\n",
    "\n",
    "#Prediction sur le jeu train partitions\n",
    "#y_kmeansClusterPersNarr = kmeansClusterPers.predict(npProsodieNarr)\n",
    "# y_kmeansClusterPers= kmeansClusterPers.predict(npProsodie) #ndArray\n",
    "\n",
    "#print('predictBelongCluster--->', kmeansClusterPers.predict([[0, 0], [12, 3]]))\n",
    "tab = np.array([x[1] for x in listLabelPers])\n",
    "print('tab shape--> ', tab.shape)\n",
    "print('listLabelsClusters shape--> ', listLabelsClusters.shape)\n",
    "#matrix = sklearn.metrics.confusion_matrix(tab, str(listLabelsClusters))\n",
    "#print('matrix', matrix)\n",
    "#print('centerClustersPers--->', kmeansClusterPers.cluster_centers_)\n",
    "\n",
    "print('Bloc Construction Clusters - Clustering : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Analyse Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TailleDlistLabelsClusters--> 845\n",
      "TailleDlistLabelPers--> 845\n",
      "dicoPersCluPreRap-->  {'feval_vampire. papaSeverin': {4: 2, 'Precision': 0.01, 'Rappel': 1.0}, 'chevalier_filledupirate. pers1': {3: 6, 1: 2, 0: 12, 2: 1, 4: 1, 'Precision': 0.06, 'Rappel': 0.55}, 'chevalier_filledupirate. pers3': {2: 1, 'Precision': 0.01, 'Rappel': 1.0}, 'chevalier_filledupirate. pers5': {3: 1, 1: 1, 'Precision': 0.02, 'Rappel': 0.5}, 'chevalier_filledupirate. pers2': {4: 2, 2: 4, 0: 3, 1: 1, 'Precision': 0.03, 'Rappel': 0.4}, 'chevalier_filledupirate. pers7': {0: 1, 'Precision': 0.01, 'Rappel': 1.0}, 'chevalier_filledupirate. pers8': {3: 1, 'Precision': 0.02, 'Rappel': 1.0}, 'chevalier_filledupirate. pers9': {4: 2, 1: 1, 'Precision': 0.01, 'Rappel': 0.67}, 'chevalier_filledupirate. pers4': {0: 6, 1: 1, 'Precision': 0.03, 'Rappel': 0.86}, 'chevalier_filledupirate. pers6': {0: 7, 4: 4, 2: 2, 'Precision': 0.04, 'Rappel': 0.54}, 'chevalier_filledupirate. pers11': {4: 4, 0: 15, 2: 1, 1: 2, 'Precision': 0.08, 'Rappel': 0.68}, 'chevalier_filledupirate. pers12': {4: 9, 0: 12, 2: 3, 1: 4, 'Precision': 0.06, 'Rappel': 0.43}, 'chevalier_filledupirate. pers13': {4: 1, 2: 1, 'Precision': 0.0, 'Rappel': 0.5}, 'chevalier_filledupirate. pers14': {1: 1, 4: 1, 'Precision': 0.0, 'Rappel': 0.5}, 'chevalier_filledupirate. pers15': {0: 8, 1: 3, 4: 1, 'Precision': 0.04, 'Rappel': 0.67}, 'chevalier_filledupirate. pers16': {0: 1, 3: 1, 'Precision': 0.01, 'Rappel': 0.5}, 'chevalier_filledupirate. pers10': {1: 7, 2: 3, 4: 11, 0: 7, 'Precision': 0.04, 'Rappel': 0.39}, 'chevalier_filledupirate. pers18': {1: 11, 2: 3, 3: 1, 0: 2, 4: 2, 'Precision': 0.05, 'Rappel': 0.58}, 'chevalier_filledupirate. pers19': {0: 2, 1: 1, 2: 1, 'Precision': 0.01, 'Rappel': 0.5}, 'chevalier_filledupirate. pers20': {2: 3, 3: 1, 4: 1, 'Precision': 0.02, 'Rappel': 0.6}, 'chevalier_filledupirate. pers21': {1: 1, 4: 1, 2: 1, 'Precision': 0.0, 'Rappel': 0.33}, 'chevalier_filledupirate. pers22': {4: 1, 1: 1, 'Precision': 0.0, 'Rappel': 0.5}, 'chevalier_filledupirate. pers23': {1: 3, 2: 1, 'Precision': 0.01, 'Rappel': 0.75}, 'chevalier_filledupirate. pers24': {2: 1, 'Precision': 0.01, 'Rappel': 1.0}, 'chevalier_filledupirate. pers25': {4: 11, 1: 21, 2: 7, 0: 6, 3: 2, 'Precision': 0.1, 'Rappel': 0.45}, 'chevalier_filledupirate. pers26': {0: 20, 1: 4, 4: 7, 'Precision': 0.1, 'Rappel': 0.65}, 'chevalier_filledupirate. pers27': {4: 2, 'Precision': 0.01, 'Rappel': 1.0}, 'chevalier_filledupirate. pers28': {1: 2, 'Precision': 0.01, 'Rappel': 1.0}, 'chevalier_filledupirate. _': {1: 2, 4: 24, 0: 5, 'Precision': 0.09, 'Rappel': 0.77}, 'chevalier_filledupirate. pers29': {0: 3, 4: 1, 'Precision': 0.02, 'Rappel': 0.75}, 'chevalier_filledupirate. pers30': {1: 3, 4: 1, 'Precision': 0.01, 'Rappel': 0.75}, 'chevalier_filledupirate. pers31': {4: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'chevalier_filledupirate. pers32': {1: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'chevalier_filledupirate. pers33': {0: 2, 1: 1, 'Precision': 0.01, 'Rappel': 0.67}, 'chevalier_filledupirate. pers34': {2: 2, 'Precision': 0.02, 'Rappel': 1.0}, 'flaubert_madamebovary. pers1': {4: 2, 'Precision': 0.01, 'Rappel': 1.0}, 'flaubert_madamebovary. pers2': {4: 3, 1: 7, 2: 2, 'Precision': 0.03, 'Rappel': 0.58}, 'flaubert_madamebovary. pers3': {4: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'flaubert_madamebovary. pers4': {4: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'flaubert_madamebovary. pers5': {1: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'flaubert_madamebovary. pers6': {4: 2, 2: 1, 1: 2, 'Precision': 0.01, 'Rappel': 0.4}, 'flaubert_madamebovary. pers7': {1: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'flaubert_madamebovary. pers8': {2: 1, 'Precision': 0.01, 'Rappel': 1.0}, 'merimee_carmen. pers1': {4: 5, 0: 7, 1: 2, 'Precision': 0.04, 'Rappel': 0.5}, 'merimee_carmen. _': {4: 8, 1: 9, 2: 2, 0: 5, 'Precision': 0.04, 'Rappel': 0.38}, 'merimee_carmen. pers2': {4: 4, 0: 4, 2: 2, 'Precision': 0.01, 'Rappel': 0.4}, 'merimee_carmen. pers14': {3: 1, 'Precision': 0.02, 'Rappel': 1.0}, 'merimee_carmen. pers4': {3: 2, 'Precision': 0.05, 'Rappel': 1.0}, 'merimee_carmen. pers6': {0: 2, 2: 28, 4: 15, 1: 21, 3: 11, 'Precision': 0.21, 'Rappel': 0.36}, 'merimee_carmen. pers7': {0: 1, 4: 1, 'Precision': 0.01, 'Rappel': 0.5}, 'merimee_carmen. pers3': {4: 20, 0: 11, 1: 6, 2: 8, 'Precision': 0.07, 'Rappel': 0.44}, 'merimee_carmen. pers10': {4: 5, 3: 1, 'Precision': 0.02, 'Rappel': 0.83}, 'merimee_carmen. pers8': {2: 2, 'Precision': 0.02, 'Rappel': 1.0}, 'merimee_carmen. pers9': {0: 6, 4: 1, 'Precision': 0.03, 'Rappel': 0.86}, 'merimee_carmen. pers11': {4: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'merimee_carmen. pers12': {2: 2, 4: 1, 3: 2, 'Precision': 0.02, 'Rappel': 0.4}, 'merimee_carmen. pers13': {2: 1, 1: 3, 'Precision': 0.01, 'Rappel': 0.75}, 'merimee_carmen. pers15': {4: 1, 1: 4, 'Precision': 0.02, 'Rappel': 0.8}, 'merimee_carmen. pers16': {4: 2, 'Precision': 0.01, 'Rappel': 1.0}, 'merimee_venusdille. pers1': {4: 16, 0: 14, 1: 17, 2: 10, 3: 4, 'Precision': 0.08, 'Rappel': 0.28}, 'merimee_venusdille. pers2': {4: 20, 1: 12, 0: 5, 'Precision': 0.07, 'Rappel': 0.54}, 'merimee_venusdille. pers3': {0: 12, 1: 21, 4: 13, 2: 10, 'Precision': 0.1, 'Rappel': 0.38}, 'merimee_venusdille. _': {0: 4, 'Precision': 0.02, 'Rappel': 1.0}, 'merimee_venusdille. pers4': {2: 5, 'Precision': 0.04, 'Rappel': 1.0}, 'merimee_venusdille. pers5': {2: 3, 3: 2, 'Precision': 0.02, 'Rappel': 0.6}, 'merimee_venusdille. pers6': {2: 2, 1: 1, 3: 1, 'Precision': 0.02, 'Rappel': 0.5}, 'merimee_venusdille. pers7': {1: 6, 2: 4, 0: 4, 4: 12, 'Precision': 0.04, 'Rappel': 0.46}, 'merimee_venusdille. pers8': {3: 4, 'Precision': 0.09, 'Rappel': 1.0}, 'merimee_venusdille. pers10': {0: 2, 4: 2, 'Precision': 0.01, 'Rappel': 0.5}, 'merimee_venusdille. pers11': {4: 5, 0: 1, 1: 2, 'Precision': 0.02, 'Rappel': 0.62}, 'merimee_venusdille. pers12': {1: 2, 'Precision': 0.01, 'Rappel': 1.0}, 'merimee_venusdille. pers13': {4: 2, 'Precision': 0.01, 'Rappel': 1.0}, 'zeltner_contes. mere': {2: 1, 'Precision': 0.01, 'Rappel': 1.0}, 'zeltner_contes. Koli': {2: 6, 4: 18, 0: 3, 1: 6, 'Precision': 0.07, 'Rappel': 0.55}, 'zeltner_contes. marchands': {0: 2, 4: 5, 3: 1, 2: 1, 1: 3, 'Precision': 0.02, 'Rappel': 0.42}, 'zeltner_contes. chef': {4: 5, 1: 2, 'Precision': 0.02, 'Rappel': 0.71}, 'zeltner_contes. assistants': {2: 2, 4: 1, 3: 1, 'Precision': 0.02, 'Rappel': 0.5}, 'zeltner_contes. meremarchand': {4: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'zeltner_contes. marchand': {4: 2, 1: 1, 0: 2, 'Precision': 0.01, 'Rappel': 0.4}, 'zeltner_contes. vxpere': {2: 1, 5: 1, 4: 3, 'Precision': 0.01, 'Rappel': 0.6}, 'zeltner_contes. sofas': {4: 1, 'Precision': 0.0, 'Rappel': 1.0}, 'zeltner_contes. roi': {2: 2, 4: 1, 'Precision': 0.02, 'Rappel': 0.67}}\n",
      "listPersClusters[0]--> ['feval_vampire. papaSeverin', 0, 0, 0, 0, 2, 0, 2]\n",
      "listLabelPers[0]--> ['chevalier_filledupirate_001' ' pers1' ' 15']\n",
      "Bloc Analyse Clusters : OK\n"
     ]
    }
   ],
   "source": [
    "#Comparaison des labels de clusters et des idPers\n",
    "print ('TailleDlistLabelsClusters-->', len(listLabelsClusters))\n",
    "print('TailleDlistLabelPers-->', len(listLabelPers))\n",
    "#print ('listLabelsClusters-->', listLabelsClusters)\n",
    "dicoPersClusters = builtDicoPersLabelsClusters(listLabelsClusters, listLabelPers, intPosIdOeuvre, intPosIdPers, strTyCo)\n",
    "#print('dicoPersClusters-->', dicoPersClusters)\n",
    "#idClusterNarrateur = belongToCluster(' _', dicoPersClusters)\t# les id personnages sont des chaines de caracteres ayant un espace au tout debut, ex ' pers1'\n",
    "#print('idClusterNarrateur-->', idClusterNarrateur)\n",
    "#floatPrecisionNarrateur = calculPrecisionPers(' _', idClusterNarrateur, listLabelsClusters, dicoPersClusters, intNbChifArrondi)\n",
    "#print('floatPrecisionNarrateur-->', floatPrecisionNarrateur)\n",
    "#floatRappelNarrateur = calculRappelPers(' _', idClusterNarrateur, listLabelsClusters, dicoPersClusters, intNbChifArrondi)\n",
    "#print('floatRappelNarrateur-->', floatRappelNarrateur)\n",
    "dicoPersCluPreRap = builtDicoPersPrecisionRappel(dicoPersClusters, listLabelsClusters)\n",
    "print('dicoPersCluPreRap--> ', dicoPersCluPreRap)\n",
    "listPersClusters = builtArrayPersCluFromDictPersClu(dicoPersClusters, intNbClusters)\n",
    "print('listPersClusters[0]-->', listPersClusters[0])\n",
    "print('listLabelPers[0]-->', listLabelPers[7])\n",
    "\n",
    "print('Bloc Analyse Clusters : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation Graphique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Representation Graphique Mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Representation Graphique avec la bibliotheque Mglearn\n",
    "discrete_scatter(npProsodie[:, 0], npProsodie[:, 1], kmeans.labels_, markers='o')\n",
    "discrete_scatter(\n",
    "    kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], [0, 1, 2], \n",
    "    markers='^', markeredgewidth=2)\n",
    "\n",
    "print('Bloc Representation Graphique Mglearn : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Representation Graphique Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Representation Graphique Matplotlib\n",
    "# Initialisation figure\n",
    "fig = plt.figure()\n",
    "#Construction figure\n",
    "plt.scatter(npProsodie[:, 0], npProsodie[:, 1], c=y_kmeansClusterPers, s=25, cmap='viridis', marker = 's', label = 'Parole')\n",
    "#plt.scatter(npProsodieNarr[:, 0], npProsodieNarr[:, 1], c=y_kmeansClusterPersNarr, s=25, cmap='viridis', marker = '^')\n",
    "\n",
    "centers = kmeansClusterPersBuild.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5, label = 'centre de cluster')\n",
    "\n",
    "#axes et legendes\n",
    "#plt.ylim(-0.25, 1)\n",
    "#plt.xlim(100, 400)\n",
    "plt.title('Clustering avec KMeans')\n",
    "plt.xlabel(\"F0 Moyenne\")\n",
    "plt.ylabel(\"F0 Ecart-type\")\n",
    "#plt.margins(0.5, 0.5)\n",
    "plt.legend()\n",
    "#Sauvegarde figure\n",
    "fig.savefig(pwdFileImgPersClusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Representation par tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listColumnsDF1--> ['Pers', 'Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5', 'Total']\n",
      "Nom fichier sauvegarde CSV avec type regroupement personnages et autres caracteristiques du clustering -->\n",
      "./ResultatNoteBook/TestBrouillon/MatTestT210BrNbClusters6_PersGroupNonNarrateur_F0_ensemble_oeuvres.csv\n",
      "dfSortedPersClus-->\n",
      "                               Pers  Cluster 0  Cluster 1  Cluster 2  \\\n",
      "41     flaubert_madamebovary. pers7          0          1          0   \n",
      "42     flaubert_madamebovary. pers8          0          0          1   \n",
      "46           merimee_carmen. pers14          0          0          0   \n",
      "37     flaubert_madamebovary. pers3          0          0          0   \n",
      "54           merimee_carmen. pers11          0          0          0   \n",
      "32  chevalier_filledupirate. pers32          0          1          0   \n",
      "39     flaubert_madamebovary. pers5          0          1          0   \n",
      "31  chevalier_filledupirate. pers31          0          0          0   \n",
      "6    chevalier_filledupirate. pers8          0          0          0   \n",
      "5    chevalier_filledupirate. pers7          1          0          0   \n",
      "72             zeltner_contes. mere          0          0          1   \n",
      "77     zeltner_contes. meremarchand          0          0          0   \n",
      "2    chevalier_filledupirate. pers3          0          0          1   \n",
      "80            zeltner_contes. sofas          0          0          0   \n",
      "23  chevalier_filledupirate. pers24          0          0          1   \n",
      "38     flaubert_madamebovary. pers4          0          0          0   \n",
      "34  chevalier_filledupirate. pers34          0          0          2   \n",
      "35     flaubert_madamebovary. pers1          0          0          0   \n",
      "49            merimee_carmen. pers7          1          0          0   \n",
      "27  chevalier_filledupirate. pers28          0          2          0   \n",
      "52            merimee_carmen. pers8          0          0          2   \n",
      "58           merimee_carmen. pers16          0          0          0   \n",
      "70       merimee_venusdille. pers12          0          2          0   \n",
      "71       merimee_venusdille. pers13          0          0          0   \n",
      "47            merimee_carmen. pers4          0          0          0   \n",
      "26  chevalier_filledupirate. pers27          0          0          0   \n",
      "0        feval_vampire. papaSeverin          0          0          0   \n",
      "3    chevalier_filledupirate. pers5          0          1          0   \n",
      "21  chevalier_filledupirate. pers22          0          1          0   \n",
      "12  chevalier_filledupirate. pers13          0          0          1   \n",
      "..                              ...        ...        ...        ...   \n",
      "40     flaubert_madamebovary. pers6          0          2          1   \n",
      "51           merimee_carmen. pers10          0          0          0   \n",
      "8    chevalier_filledupirate. pers4          6          1          0   \n",
      "75             zeltner_contes. chef          0          2          0   \n",
      "53            merimee_carmen. pers9          6          0          0   \n",
      "69       merimee_venusdille. pers11          1          2          0   \n",
      "45            merimee_carmen. pers2          4          0          2   \n",
      "4    chevalier_filledupirate. pers2          3          1          4   \n",
      "74        zeltner_contes. marchands          2          3          1   \n",
      "36     flaubert_madamebovary. pers2          0          7          2   \n",
      "14  chevalier_filledupirate. pers15          8          3          0   \n",
      "9    chevalier_filledupirate. pers6          7          0          2   \n",
      "43            merimee_carmen. pers1          7          2          0   \n",
      "17  chevalier_filledupirate. pers18          2         11          3   \n",
      "10  chevalier_filledupirate. pers11         15          2          1   \n",
      "1    chevalier_filledupirate. pers1         12          2          1   \n",
      "44                merimee_carmen. _          5          9          2   \n",
      "66        merimee_venusdille. pers7          4          6          4   \n",
      "16  chevalier_filledupirate. pers10          7          7          3   \n",
      "11  chevalier_filledupirate. pers12         12          4          3   \n",
      "25  chevalier_filledupirate. pers26         20          4          0   \n",
      "28       chevalier_filledupirate. _          5          2          0   \n",
      "73             zeltner_contes. Koli          3          6          6   \n",
      "60        merimee_venusdille. pers2          5         12          0   \n",
      "50            merimee_carmen. pers3         11          6          8   \n",
      "24  chevalier_filledupirate. pers25          6         21          7   \n",
      "61        merimee_venusdille. pers3         12         21         10   \n",
      "59        merimee_venusdille. pers1         14         17         10   \n",
      "48            merimee_carmen. pers6          2         21         28   \n",
      "82                            Total        197        203        131   \n",
      "\n",
      "    Cluster 3  Cluster 4  Cluster 5  Total  \n",
      "41          0          0          0      1  \n",
      "42          0          0          0      1  \n",
      "46          1          0          0      1  \n",
      "37          0          1          0      1  \n",
      "54          0          1          0      1  \n",
      "32          0          0          0      1  \n",
      "39          0          0          0      1  \n",
      "31          0          1          0      1  \n",
      "6           1          0          0      1  \n",
      "5           0          0          0      1  \n",
      "72          0          0          0      1  \n",
      "77          0          1          0      1  \n",
      "2           0          0          0      1  \n",
      "80          0          1          0      1  \n",
      "23          0          0          0      1  \n",
      "38          0          1          0      1  \n",
      "34          0          0          0      2  \n",
      "35          0          2          0      2  \n",
      "49          0          1          0      2  \n",
      "27          0          0          0      2  \n",
      "52          0          0          0      2  \n",
      "58          0          2          0      2  \n",
      "70          0          0          0      2  \n",
      "71          0          2          0      2  \n",
      "47          2          0          0      2  \n",
      "26          0          2          0      2  \n",
      "0           0          2          0      2  \n",
      "3           1          0          0      2  \n",
      "21          0          1          0      2  \n",
      "12          0          1          0      2  \n",
      "..        ...        ...        ...    ...  \n",
      "40          0          2          0      5  \n",
      "51          1          5          0      6  \n",
      "8           0          0          0      7  \n",
      "75          0          5          0      7  \n",
      "53          0          1          0      7  \n",
      "69          0          5          0      8  \n",
      "45          0          4          0     10  \n",
      "4           0          2          0     10  \n",
      "74          1          5          0     12  \n",
      "36          0          3          0     12  \n",
      "14          0          1          0     12  \n",
      "9           0          4          0     13  \n",
      "43          0          5          0     14  \n",
      "17          1          2          0     19  \n",
      "10          0          4          0     22  \n",
      "1           6          1          0     22  \n",
      "44          0          8          0     24  \n",
      "66          0         12          0     26  \n",
      "16          0         11          0     28  \n",
      "11          0          9          0     28  \n",
      "25          0          7          0     31  \n",
      "28          0         24          0     31  \n",
      "73          0         18          0     33  \n",
      "60          0         20          0     37  \n",
      "50          0         20          0     45  \n",
      "24          2         11          0     47  \n",
      "61          0         13          0     56  \n",
      "59          4         16          0     61  \n",
      "48         11         15          0     77  \n",
      "82         43        270          1    845  \n",
      "\n",
      "[83 rows x 8 columns]\n",
      "Bloc Representation par tableau : OK\n"
     ]
    }
   ],
   "source": [
    "#Tableau Pandas DataFrame\n",
    "listColumnsDF1 = ['Pers'] \n",
    "for numCluster in range(intNbClusters) :\n",
    "    listColumnsDF1.append(str('Cluster ' + str(numCluster)))\n",
    "listColumnsDF1.append('Total')\n",
    "print('listColumnsDF1-->', listColumnsDF1)\n",
    "\n",
    "#DataFrame\n",
    "dfPersClusters = pd.DataFrame(listPersClusters, columns = listColumnsDF1)\n",
    "#Tri\n",
    "dfSortedPersClus = dfPersClusters.sort_values(by = 'Total')\n",
    "#Affichage\n",
    "print('Nom fichier sauvegarde CSV avec type regroupement personnages et autres caracteristiques du clustering -->')\n",
    "print(pwdFileMatricePersClustersCsv)\n",
    "print('dfSortedPersClus-->')\n",
    "print(dfSortedPersClus)\n",
    "\n",
    "#Sauvegarde\n",
    "dfPersClusters.to_csv(pwdFileMatricePersClustersCsv, sep=\"\\t\", encoding=\"utf-8\", index=False )\n",
    "dfPersClusters.to_excel(pwdFileMatricePersClustersExcel, index=False)\n",
    "\n",
    "print('Bloc Representation par tableau : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitement des donnees Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listColumnsDF2--> ['Pers.Livre', 'Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Cluster 5', 'Total Personnage']\n",
      "Nom fichier sauvegarde CSV avec indices evaluation de clustering -->\n",
      "./ResultatNoteBook/TestBrouillon/MatTestT210BrNbClusters6_PourcentRep_PersGroupNonNarrateur_F0_ensemble_oeuvres.csv\n",
      "dataframe avec indices pour evaluation dfPersClusEval -->\n",
      "                         Pers.Livre         Cluster 0         Cluster 1  \\\n",
      "41     flaubert_madamebovary. pers7        [0.0, 0.0]     [1.0, 0.0049]   \n",
      "42     flaubert_madamebovary. pers8        [0.0, 0.0]        [0.0, 0.0]   \n",
      "46           merimee_carmen. pers14        [0.0, 0.0]        [0.0, 0.0]   \n",
      "37     flaubert_madamebovary. pers3        [0.0, 0.0]        [0.0, 0.0]   \n",
      "54           merimee_carmen. pers11        [0.0, 0.0]        [0.0, 0.0]   \n",
      "32  chevalier_filledupirate. pers32        [0.0, 0.0]     [1.0, 0.0049]   \n",
      "39     flaubert_madamebovary. pers5        [0.0, 0.0]     [1.0, 0.0049]   \n",
      "31  chevalier_filledupirate. pers31        [0.0, 0.0]        [0.0, 0.0]   \n",
      "6    chevalier_filledupirate. pers8        [0.0, 0.0]        [0.0, 0.0]   \n",
      "5    chevalier_filledupirate. pers7     [1.0, 0.0051]        [0.0, 0.0]   \n",
      "72             zeltner_contes. mere        [0.0, 0.0]        [0.0, 0.0]   \n",
      "77     zeltner_contes. meremarchand        [0.0, 0.0]        [0.0, 0.0]   \n",
      "2    chevalier_filledupirate. pers3        [0.0, 0.0]        [0.0, 0.0]   \n",
      "80            zeltner_contes. sofas        [0.0, 0.0]        [0.0, 0.0]   \n",
      "23  chevalier_filledupirate. pers24        [0.0, 0.0]        [0.0, 0.0]   \n",
      "38     flaubert_madamebovary. pers4        [0.0, 0.0]        [0.0, 0.0]   \n",
      "34  chevalier_filledupirate. pers34        [0.0, 0.0]        [0.0, 0.0]   \n",
      "35     flaubert_madamebovary. pers1        [0.0, 0.0]        [0.0, 0.0]   \n",
      "49            merimee_carmen. pers7     [0.5, 0.0051]        [0.0, 0.0]   \n",
      "27  chevalier_filledupirate. pers28        [0.0, 0.0]     [1.0, 0.0099]   \n",
      "52            merimee_carmen. pers8        [0.0, 0.0]        [0.0, 0.0]   \n",
      "58           merimee_carmen. pers16        [0.0, 0.0]        [0.0, 0.0]   \n",
      "70       merimee_venusdille. pers12        [0.0, 0.0]     [1.0, 0.0099]   \n",
      "71       merimee_venusdille. pers13        [0.0, 0.0]        [0.0, 0.0]   \n",
      "47            merimee_carmen. pers4        [0.0, 0.0]        [0.0, 0.0]   \n",
      "26  chevalier_filledupirate. pers27        [0.0, 0.0]        [0.0, 0.0]   \n",
      "0        feval_vampire. papaSeverin        [0.0, 0.0]        [0.0, 0.0]   \n",
      "3    chevalier_filledupirate. pers5        [0.0, 0.0]     [0.5, 0.0049]   \n",
      "21  chevalier_filledupirate. pers22        [0.0, 0.0]     [0.5, 0.0049]   \n",
      "12  chevalier_filledupirate. pers13        [0.0, 0.0]        [0.0, 0.0]   \n",
      "..                              ...               ...               ...   \n",
      "40     flaubert_madamebovary. pers6        [0.0, 0.0]     [0.4, 0.0099]   \n",
      "51           merimee_carmen. pers10        [0.0, 0.0]        [0.0, 0.0]   \n",
      "8    chevalier_filledupirate. pers4  [0.8571, 0.0305]  [0.1429, 0.0049]   \n",
      "75             zeltner_contes. chef        [0.0, 0.0]  [0.2857, 0.0099]   \n",
      "53            merimee_carmen. pers9  [0.8571, 0.0305]        [0.0, 0.0]   \n",
      "69       merimee_venusdille. pers11   [0.125, 0.0051]    [0.25, 0.0099]   \n",
      "45            merimee_carmen. pers2     [0.4, 0.0203]        [0.0, 0.0]   \n",
      "4    chevalier_filledupirate. pers2     [0.3, 0.0152]     [0.1, 0.0049]   \n",
      "74        zeltner_contes. marchands  [0.1667, 0.0102]    [0.25, 0.0148]   \n",
      "36     flaubert_madamebovary. pers2        [0.0, 0.0]  [0.5833, 0.0345]   \n",
      "14  chevalier_filledupirate. pers15  [0.6667, 0.0406]    [0.25, 0.0148]   \n",
      "9    chevalier_filledupirate. pers6  [0.5385, 0.0355]        [0.0, 0.0]   \n",
      "43            merimee_carmen. pers1     [0.5, 0.0355]  [0.1429, 0.0099]   \n",
      "17  chevalier_filledupirate. pers18  [0.1053, 0.0102]  [0.5789, 0.0542]   \n",
      "10  chevalier_filledupirate. pers11  [0.6818, 0.0761]  [0.0909, 0.0099]   \n",
      "1    chevalier_filledupirate. pers1  [0.5455, 0.0609]  [0.0909, 0.0099]   \n",
      "44                merimee_carmen. _  [0.2083, 0.0254]   [0.375, 0.0443]   \n",
      "66        merimee_venusdille. pers7  [0.1538, 0.0203]  [0.2308, 0.0296]   \n",
      "16  chevalier_filledupirate. pers10    [0.25, 0.0355]    [0.25, 0.0345]   \n",
      "11  chevalier_filledupirate. pers12  [0.4286, 0.0609]  [0.1429, 0.0197]   \n",
      "25  chevalier_filledupirate. pers26  [0.6452, 0.1015]   [0.129, 0.0197]   \n",
      "28       chevalier_filledupirate. _  [0.1613, 0.0254]  [0.0645, 0.0099]   \n",
      "73             zeltner_contes. Koli  [0.0909, 0.0152]  [0.1818, 0.0296]   \n",
      "60        merimee_venusdille. pers2  [0.1351, 0.0254]  [0.3243, 0.0591]   \n",
      "50            merimee_carmen. pers3  [0.2444, 0.0558]  [0.1333, 0.0296]   \n",
      "24  chevalier_filledupirate. pers25  [0.1277, 0.0305]  [0.4468, 0.1034]   \n",
      "61        merimee_venusdille. pers3  [0.2143, 0.0609]   [0.375, 0.1034]   \n",
      "59        merimee_venusdille. pers1  [0.2295, 0.0711]  [0.2787, 0.0837]   \n",
      "48            merimee_carmen. pers6   [0.026, 0.0102]  [0.2727, 0.1034]   \n",
      "82                            Total     [0.2331, 1.0]     [0.2402, 1.0]   \n",
      "\n",
      "           Cluster 2         Cluster 3         Cluster 4      Cluster 5  \\\n",
      "41        [0.0, 0.0]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "42     [1.0, 0.0076]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "46        [0.0, 0.0]     [1.0, 0.0233]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "37        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0037]     [0.0, 0.0]   \n",
      "54        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0037]     [0.0, 0.0]   \n",
      "32        [0.0, 0.0]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "39        [0.0, 0.0]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "31        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0037]     [0.0, 0.0]   \n",
      "6         [0.0, 0.0]     [1.0, 0.0233]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "5         [0.0, 0.0]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "72     [1.0, 0.0076]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "77        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0037]     [0.0, 0.0]   \n",
      "2      [1.0, 0.0076]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "80        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0037]     [0.0, 0.0]   \n",
      "23     [1.0, 0.0076]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "38        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0037]     [0.0, 0.0]   \n",
      "34     [1.0, 0.0153]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "35        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0074]     [0.0, 0.0]   \n",
      "49        [0.0, 0.0]        [0.0, 0.0]     [0.5, 0.0037]     [0.0, 0.0]   \n",
      "27        [0.0, 0.0]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "52     [1.0, 0.0153]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "58        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0074]     [0.0, 0.0]   \n",
      "70        [0.0, 0.0]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "71        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0074]     [0.0, 0.0]   \n",
      "47        [0.0, 0.0]     [1.0, 0.0465]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "26        [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0074]     [0.0, 0.0]   \n",
      "0         [0.0, 0.0]        [0.0, 0.0]     [1.0, 0.0074]     [0.0, 0.0]   \n",
      "3         [0.0, 0.0]     [0.5, 0.0233]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "21        [0.0, 0.0]        [0.0, 0.0]     [0.5, 0.0037]     [0.0, 0.0]   \n",
      "12     [0.5, 0.0076]        [0.0, 0.0]     [0.5, 0.0037]     [0.0, 0.0]   \n",
      "..               ...               ...               ...            ...   \n",
      "40     [0.2, 0.0076]        [0.0, 0.0]     [0.4, 0.0074]     [0.0, 0.0]   \n",
      "51        [0.0, 0.0]  [0.1667, 0.0233]  [0.8333, 0.0185]     [0.0, 0.0]   \n",
      "8         [0.0, 0.0]        [0.0, 0.0]        [0.0, 0.0]     [0.0, 0.0]   \n",
      "75        [0.0, 0.0]        [0.0, 0.0]  [0.7143, 0.0185]     [0.0, 0.0]   \n",
      "53        [0.0, 0.0]        [0.0, 0.0]  [0.1429, 0.0037]     [0.0, 0.0]   \n",
      "69        [0.0, 0.0]        [0.0, 0.0]   [0.625, 0.0185]     [0.0, 0.0]   \n",
      "45     [0.2, 0.0153]        [0.0, 0.0]     [0.4, 0.0148]     [0.0, 0.0]   \n",
      "4      [0.4, 0.0305]        [0.0, 0.0]     [0.2, 0.0074]     [0.0, 0.0]   \n",
      "74  [0.0833, 0.0076]  [0.0833, 0.0233]  [0.4167, 0.0185]     [0.0, 0.0]   \n",
      "36  [0.1667, 0.0153]        [0.0, 0.0]    [0.25, 0.0111]     [0.0, 0.0]   \n",
      "14        [0.0, 0.0]        [0.0, 0.0]  [0.0833, 0.0037]     [0.0, 0.0]   \n",
      "9   [0.1538, 0.0153]        [0.0, 0.0]  [0.3077, 0.0148]     [0.0, 0.0]   \n",
      "43        [0.0, 0.0]        [0.0, 0.0]  [0.3571, 0.0185]     [0.0, 0.0]   \n",
      "17  [0.1579, 0.0229]  [0.0526, 0.0233]  [0.1053, 0.0074]     [0.0, 0.0]   \n",
      "10  [0.0455, 0.0076]        [0.0, 0.0]  [0.1818, 0.0148]     [0.0, 0.0]   \n",
      "1   [0.0455, 0.0076]  [0.2727, 0.1395]  [0.0455, 0.0037]     [0.0, 0.0]   \n",
      "44  [0.0833, 0.0153]        [0.0, 0.0]  [0.3333, 0.0296]     [0.0, 0.0]   \n",
      "66  [0.1538, 0.0305]        [0.0, 0.0]  [0.4615, 0.0444]     [0.0, 0.0]   \n",
      "16  [0.1071, 0.0229]        [0.0, 0.0]  [0.3929, 0.0407]     [0.0, 0.0]   \n",
      "11  [0.1071, 0.0229]        [0.0, 0.0]  [0.3214, 0.0333]     [0.0, 0.0]   \n",
      "25        [0.0, 0.0]        [0.0, 0.0]  [0.2258, 0.0259]     [0.0, 0.0]   \n",
      "28        [0.0, 0.0]        [0.0, 0.0]  [0.7742, 0.0889]     [0.0, 0.0]   \n",
      "73  [0.1818, 0.0458]        [0.0, 0.0]  [0.5455, 0.0667]     [0.0, 0.0]   \n",
      "60        [0.0, 0.0]        [0.0, 0.0]  [0.5405, 0.0741]     [0.0, 0.0]   \n",
      "50  [0.1778, 0.0611]        [0.0, 0.0]  [0.4444, 0.0741]     [0.0, 0.0]   \n",
      "24  [0.1489, 0.0534]  [0.0426, 0.0465]   [0.234, 0.0407]     [0.0, 0.0]   \n",
      "61  [0.1786, 0.0763]        [0.0, 0.0]  [0.2321, 0.0481]     [0.0, 0.0]   \n",
      "59  [0.1639, 0.0763]   [0.0656, 0.093]  [0.2623, 0.0593]     [0.0, 0.0]   \n",
      "48  [0.3636, 0.2137]  [0.1429, 0.2558]  [0.1948, 0.0556]     [0.0, 0.0]   \n",
      "82      [0.155, 1.0]     [0.0509, 1.0]     [0.3195, 1.0]  [0.0012, 1.0]   \n",
      "\n",
      "    Total Personnage  \n",
      "41                 1  \n",
      "42                 1  \n",
      "46                 1  \n",
      "37                 1  \n",
      "54                 1  \n",
      "32                 1  \n",
      "39                 1  \n",
      "31                 1  \n",
      "6                  1  \n",
      "5                  1  \n",
      "72                 1  \n",
      "77                 1  \n",
      "2                  1  \n",
      "80                 1  \n",
      "23                 1  \n",
      "38                 1  \n",
      "34                 2  \n",
      "35                 2  \n",
      "49                 2  \n",
      "27                 2  \n",
      "52                 2  \n",
      "58                 2  \n",
      "70                 2  \n",
      "71                 2  \n",
      "47                 2  \n",
      "26                 2  \n",
      "0                  2  \n",
      "3                  2  \n",
      "21                 2  \n",
      "12                 2  \n",
      "..               ...  \n",
      "40                 5  \n",
      "51                 6  \n",
      "8                  7  \n",
      "75                 7  \n",
      "53                 7  \n",
      "69                 8  \n",
      "45                10  \n",
      "4                 10  \n",
      "74                12  \n",
      "36                12  \n",
      "14                12  \n",
      "9                 13  \n",
      "43                14  \n",
      "17                19  \n",
      "10                22  \n",
      "1                 22  \n",
      "44                24  \n",
      "66                26  \n",
      "16                28  \n",
      "11                28  \n",
      "25                31  \n",
      "28                31  \n",
      "73                33  \n",
      "60                37  \n",
      "50                45  \n",
      "24                47  \n",
      "61                56  \n",
      "59                61  \n",
      "48                77  \n",
      "82               845  \n",
      "\n",
      "[83 rows x 8 columns]\n",
      "Bloc Traitement Donnees Tableau : OK\n"
     ]
    }
   ],
   "source": [
    "#Appel des fonctions de traitement\n",
    "listPersClusEval = buildListEvalFromDataFrameMultiCorpus(dfSortedPersClus, intNbClusters, strNomColPers, strNomClusters, strIdTotal)\n",
    "#print('listPersClusEval-->', listPersClusEval)\n",
    "\n",
    "#Tableau Pandas DataFrame\n",
    "listColumnsDF2 = ['Pers.Livre'] \n",
    "for numCluster in range(intNbClusters) :\n",
    "    listColumnsDF2.append(str('Cluster ' + str(numCluster)))\n",
    "listColumnsDF2.append('Total Personnage')\n",
    "print('listColumnsDF2-->', listColumnsDF2)\n",
    "\n",
    "#DataFrame\n",
    "dfPersClustersIndEval = pd.DataFrame(listPersClusEval, columns = listColumnsDF2)\n",
    "#Tri\n",
    "dfSortedPersClusIndEval = dfPersClustersIndEval.sort_values(by = 'Total Personnage')\n",
    "#Affichage\n",
    "print('Nom fichier sauvegarde CSV avec indices evaluation de clustering -->')\n",
    "print(pwdFileMatricePersClustersIndEvalCsv)\n",
    "print('dataframe avec indices pour evaluation dfPersClusEval -->')\n",
    "print(dfSortedPersClusIndEval)\n",
    "\n",
    "#Sauvegarde\n",
    "dfPersClustersIndEval.to_csv(pwdFileMatricePersClustersIndEvalCsv, sep=\"\\t\", encoding=\"utf-8\", index=False )\n",
    "dfPersClustersIndEval.to_excel(pwdFileMatricePersClustersIndEvalExcel, index=False)\n",
    "\n",
    "print('Bloc Traitement Donnees Tableau : OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictPersSupSeuil--> {'chevalier_filledupirate. pers1': {3: 6, 1: 2, 0: 12, 2: 1, 4: 1, 'Precision': 0.06, 'Rappel': 0.55}, 'chevalier_filledupirate. pers11': {4: 4, 0: 15, 2: 1, 1: 2, 'Precision': 0.08, 'Rappel': 0.68}, 'chevalier_filledupirate. pers12': {4: 9, 0: 12, 2: 3, 1: 4, 'Precision': 0.06, 'Rappel': 0.43}, 'chevalier_filledupirate. pers10': {1: 7, 2: 3, 4: 11, 0: 7, 'Precision': 0.04, 'Rappel': 0.39}, 'chevalier_filledupirate. pers25': {4: 11, 1: 21, 2: 7, 0: 6, 3: 2, 'Precision': 0.1, 'Rappel': 0.45}, 'chevalier_filledupirate. pers26': {0: 20, 1: 4, 4: 7, 'Precision': 0.1, 'Rappel': 0.65}, 'chevalier_filledupirate. _': {1: 2, 4: 24, 0: 5, 'Precision': 0.09, 'Rappel': 0.77}, 'merimee_carmen. _': {4: 8, 1: 9, 2: 2, 0: 5, 'Precision': 0.04, 'Rappel': 0.38}, 'merimee_carmen. pers6': {0: 2, 2: 28, 4: 15, 1: 21, 3: 11, 'Precision': 0.21, 'Rappel': 0.36}, 'merimee_carmen. pers3': {4: 20, 0: 11, 1: 6, 2: 8, 'Precision': 0.07, 'Rappel': 0.44}, 'merimee_venusdille. pers1': {4: 16, 0: 14, 1: 17, 2: 10, 3: 4, 'Precision': 0.08, 'Rappel': 0.28}, 'merimee_venusdille. pers2': {4: 20, 1: 12, 0: 5, 'Precision': 0.07, 'Rappel': 0.54}, 'merimee_venusdille. pers3': {0: 12, 1: 21, 4: 13, 2: 10, 'Precision': 0.1, 'Rappel': 0.38}, 'merimee_venusdille. pers7': {1: 6, 2: 4, 0: 4, 4: 12, 'Precision': 0.04, 'Rappel': 0.46}, 'zeltner_contes. Koli': {2: 6, 4: 18, 0: 3, 1: 6, 'Precision': 0.07, 'Rappel': 0.55}}\n",
      "listPersClusEval--> ['F0', 4, 0.03, 0.71, 0.06]\n",
      "centers clusters --> [[ 1.59580406e+02  1.25228426e-01  1.34619289e+00  7.93299492e-01]\n",
      " [ 2.03468966e+02  1.97586207e-01  1.51970443e+00  6.63940887e-01]\n",
      " [ 2.33378092e+02  1.87862595e-01  1.39801527e+00  6.63893130e-01]\n",
      " [ 2.84859767e+02  1.83023256e-01  1.30744186e+00  6.46279070e-01]\n",
      " [ 1.83314185e+02  1.83740741e-01  1.55759259e+00  6.85888889e-01]\n",
      " [-1.14700000e+01  3.08000000e+00 -5.30000000e-01  1.94000000e+00]]\n",
      "npProsodie[0]--> [1.8134e+02 1.4000e-01 1.3300e+00 6.3000e-01]\n",
      "listPersClusters[0]--> ['feval_vampire. papaSeverin', 0, 0, 0, 0, 2, 0, 2]\n",
      "listLabelPers[0]--> ['feval_vampire_00' ' papaSeverin' ' 20']\n",
      "Bloc Synthese Donnees Tableau : OK\n"
     ]
    }
   ],
   "source": [
    "#Appel des fonctions de synthese\n",
    "\n",
    "dictPersSupSeuil = builtDicoTamisPoidsPers(dicoPersCluPreRap, intNbClusters, intSeuilNbSeg)\n",
    "print('dictPersSupSeuil-->', dictPersSupSeuil)\n",
    "listPersClusEval = builtVectResumeDescripteur(dictPersSupSeuil, strKeyPrec, strKeyRap, intNbClusters, \n",
    "                                              intDimCoteFeat, strFeatureUsed, intNbChifArrondi)\n",
    "print('listPersClusEval-->', listPersClusEval)\n",
    "print('centers clusters -->', centers)\n",
    "print('npProsodie[0]-->', npProsodie[0])\n",
    "print('listPersClusters[0]-->', listPersClusters[0])\n",
    "print('listLabelPers[0]-->', listLabelPers[0])\n",
    "\n",
    "\n",
    "print('Bloc Synthese Donnees Tableau : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc preparation Apprentissage Supervise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Creation du corpus de descripteur feature annote complet\n",
    "bloc converti en la fonction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de npProsodie--> 845\n",
      "Taille de listLabelsClusters--> 845\n",
      "Taille de listLabelPers--> 845\n",
      "dicoPersClusters--> {'feval_vampire. papaSeverin': {4: 2}, 4: 18, 'chevalier_filledupirate. pers1': {3: 6, 1: 2, 0: 12, 2: 1, 4: 1}, 3: 1, 'chevalier_filledupirate. pers3': {2: 1}, 'chevalier_filledupirate. pers5': {3: 1, 1: 1}, 1: 6, 'chevalier_filledupirate. pers2': {4: 2, 2: 4, 0: 3, 1: 1}, 0: 3, 'chevalier_filledupirate. pers7': {0: 1}, 'chevalier_filledupirate. pers8': {3: 1}, 2: 6, 'chevalier_filledupirate. pers9': {4: 2, 1: 1}, 'chevalier_filledupirate. pers4': {0: 6, 1: 1}, 'chevalier_filledupirate. pers6': {0: 7, 4: 4, 2: 2}, 'chevalier_filledupirate. pers11': {4: 4, 0: 15, 2: 1, 1: 2}, 'chevalier_filledupirate. pers12': {4: 9, 0: 12, 2: 3, 1: 4}, 'chevalier_filledupirate. pers13': {4: 1, 2: 1}, 'chevalier_filledupirate. pers14': {1: 1, 4: 1}, 'chevalier_filledupirate. pers15': {0: 8, 1: 3, 4: 1}, 'chevalier_filledupirate. pers16': {0: 1, 3: 1}, 'chevalier_filledupirate. pers10': {1: 7, 2: 3, 4: 11, 0: 7}, 'chevalier_filledupirate. pers18': {1: 11, 2: 3, 3: 1, 0: 2, 4: 2}, 'chevalier_filledupirate. pers19': {0: 2, 1: 1, 2: 1}, 'chevalier_filledupirate. pers20': {2: 3, 3: 1, 4: 1}, 'chevalier_filledupirate. pers21': {1: 1, 4: 1, 2: 1}, 'chevalier_filledupirate. pers22': {4: 1, 1: 1}, 'chevalier_filledupirate. pers23': {1: 3, 2: 1}, 'chevalier_filledupirate. pers24': {2: 1}, 'chevalier_filledupirate. pers25': {4: 11, 1: 21, 2: 7, 0: 6, 3: 2}, 'chevalier_filledupirate. pers26': {0: 20, 1: 4, 4: 7}, 'chevalier_filledupirate. pers27': {4: 2}, 'chevalier_filledupirate. pers28': {1: 2}, 'chevalier_filledupirate. _': {1: 2, 4: 24, 0: 5}, 'chevalier_filledupirate. pers29': {0: 3, 4: 1}, 'chevalier_filledupirate. pers30': {1: 3, 4: 1}, 'chevalier_filledupirate. pers31': {4: 1}, 'chevalier_filledupirate. pers32': {1: 1}, 'chevalier_filledupirate. pers33': {0: 2, 1: 1}, 'chevalier_filledupirate. pers34': {2: 2}, 'flaubert_madamebovary. pers1': {4: 2}, 'flaubert_madamebovary. pers2': {4: 3, 1: 7, 2: 2}, 'flaubert_madamebovary. pers3': {4: 1}, 'flaubert_madamebovary. pers4': {4: 1}, 'flaubert_madamebovary. pers5': {1: 1}, 'flaubert_madamebovary. pers6': {4: 2, 2: 1, 1: 2}, 'flaubert_madamebovary. pers7': {1: 1}, 'flaubert_madamebovary. pers8': {2: 1}, 'merimee_carmen. pers1': {4: 5, 0: 7, 1: 2}, 'merimee_carmen. _': {4: 8, 1: 9, 2: 2, 0: 5}, 'merimee_carmen. pers2': {4: 4, 0: 4, 2: 2}, 'merimee_carmen. pers14': {3: 1}, 'merimee_carmen. pers4': {3: 2}, 'merimee_carmen. pers6': {0: 2, 2: 28, 4: 15, 1: 21, 3: 11}, 'merimee_carmen. pers7': {0: 1, 4: 1}, 'merimee_carmen. pers3': {4: 20, 0: 11, 1: 6, 2: 8}, 'merimee_carmen. pers10': {4: 5, 3: 1}, 'merimee_carmen. pers8': {2: 2}, 'merimee_carmen. pers9': {0: 6, 4: 1}, 'merimee_carmen. pers11': {4: 1}, 'merimee_carmen. pers12': {2: 2, 4: 1, 3: 2}, 'merimee_carmen. pers13': {2: 1, 1: 3}, 'merimee_carmen. pers15': {4: 1, 1: 4}, 'merimee_carmen. pers16': {4: 2}, 'merimee_venusdille. pers1': {4: 16, 0: 14, 1: 17, 2: 10, 3: 4}, 'merimee_venusdille. pers2': {4: 20, 1: 12, 0: 5}, 'merimee_venusdille. pers3': {0: 12, 1: 21, 4: 13, 2: 10}, 'merimee_venusdille. _': {0: 4}, 'merimee_venusdille. pers4': {2: 5}, 'merimee_venusdille. pers5': {2: 3, 3: 2}, 'merimee_venusdille. pers6': {2: 2, 1: 1, 3: 1}, 'merimee_venusdille. pers7': {1: 6, 2: 4, 0: 4, 4: 12}, 'merimee_venusdille. pers8': {3: 4}, 'merimee_venusdille. pers10': {0: 2, 4: 2}, 'merimee_venusdille. pers11': {4: 5, 0: 1, 1: 2}, 'merimee_venusdille. pers12': {1: 2}, 'merimee_venusdille. pers13': {4: 2}, 'zeltner_contes. mere': {2: 1}, 'zeltner_contes. Koli': {2: 6, 4: 18, 0: 3, 1: 6}, 'zeltner_contes. marchands': {0: 2, 4: 5, 3: 1, 2: 1, 1: 3}, 'zeltner_contes. chef': {4: 5, 1: 2}, 'zeltner_contes. assistants': {2: 2, 4: 1, 3: 1}, 'zeltner_contes. meremarchand': {4: 1}, 'zeltner_contes. marchand': {4: 2, 1: 1, 0: 2}, 'zeltner_contes. vxpere': {2: 1, 5: 1, 4: 3}, 5: 1, 'zeltner_contes. sofas': {4: 1}, 'zeltner_contes. roi': {2: 2, 4: 1}}\n",
      "listLabelPers[intCompteur][intPosIdPers]-->   papaSeverin\n",
      "Taille de npProsodieAnoteComplet--> 845\n",
      "listColumnsDF04--> ['IdSeg', 'F0', 'Cluster Kmean', 'Classe Pers', 'Label linguistique Pers']\n",
      "Nom fichier sauvegarde CSV avec Corpus de Resultat -->\n",
      "./ResultatNoteBook/TestBrouillon/CorpusRes6_PourcentRep_PersGroupNonNarrateur_F0_ensemble_oeuvres.csv\n",
      "dataframe dfCorpusRes -->\n",
      "     IdSeg                           F0  Cluster Kmean  Classe Pers  \\\n",
      "0        0   [181.34, 0.14, 1.33, 0.63]              4            4   \n",
      "1        1   [182.03, 0.15, 1.24, 0.63]              4            4   \n",
      "2        2   [301.67, 0.14, 1.14, 0.53]              3            0   \n",
      "3        3   [337.29, 0.09, 1.17, 0.52]              3            0   \n",
      "4        4   [335.01, 0.25, 1.21, 0.42]              3            0   \n",
      "5        5   [231.97, 0.16, 1.43, 0.69]              2            2   \n",
      "6        6   [269.45, 0.21, 1.29, 0.55]              3            0   \n",
      "7        7   [277.26, 0.19, 1.21, 0.58]              3            0   \n",
      "8        8   [260.02, 0.19, 1.27, 0.48]              3            3   \n",
      "9        9   [214.74, 0.12, 1.16, 0.72]              1            0   \n",
      "10      10   [214.74, 0.12, 1.16, 0.72]              1            0   \n",
      "11      11   [209.77, 0.14, 1.49, 0.46]              1            3   \n",
      "12      12     [298.83, 0.08, 1.2, 0.8]              3            0   \n",
      "13      13    [182.1, 0.07, 1.17, 0.87]              4            2   \n",
      "14      14   [156.62, 0.17, 1.48, 0.55]              0            0   \n",
      "15      15   [147.46, 0.04, 1.07, 0.92]              0            0   \n",
      "16      16   [148.78, 0.08, 1.18, 0.84]              0            0   \n",
      "17      17    [265.32, 0.14, 1.3, 0.69]              3            3   \n",
      "18      18   [220.09, 0.19, 1.46, 0.67]              2            2   \n",
      "19      19   [234.38, 0.13, 1.26, 0.79]              2            0   \n",
      "20      20    [185.41, 0.11, 1.24, 0.8]              4            2   \n",
      "21      21    [168.02, 0.12, 1.91, 0.7]              0            0   \n",
      "22      22   [169.65, 0.04, 1.12, 0.97]              0            2   \n",
      "23      23   [169.65, 0.04, 1.12, 0.97]              0            2   \n",
      "24      24    [165.5, 0.09, 1.16, 0.85]              0            0   \n",
      "25      25    [165.5, 0.09, 1.16, 0.85]              0            0   \n",
      "26      26    [248.77, 0.18, 1.3, 0.71]              2            2   \n",
      "27      27    [248.77, 0.18, 1.3, 0.71]              2            2   \n",
      "28      28    [186.08, 0.11, 1.18, 0.7]              4            0   \n",
      "29      29   [235.81, 0.09, 1.23, 0.77]              2            2   \n",
      "..     ...                          ...            ...          ...   \n",
      "815    815   [199.47, 0.16, 1.34, 0.85]              1            4   \n",
      "816    816   [199.47, 0.16, 1.34, 0.85]              1            4   \n",
      "817    817   [209.63, 0.13, 1.31, 0.77]              1            4   \n",
      "818    818   [238.19, 0.36, 1.81, 0.68]              2            4   \n",
      "819    819  [-11.47, 3.08, -0.53, 1.94]              5            4   \n",
      "820    820   [210.79, 0.24, 1.64, 0.68]              1            4   \n",
      "821    821    [185.96, 0.2, 1.52, 0.63]              4            4   \n",
      "822    822   [181.13, 0.26, 1.62, 0.76]              4            4   \n",
      "823    823   [182.79, 0.15, 1.31, 0.82]              4            4   \n",
      "824    824   [225.04, 0.19, 1.32, 0.76]              2            4   \n",
      "825    825   [192.87, 0.14, 1.48, 0.69]              4            4   \n",
      "826    826   [171.68, 0.26, 1.83, 0.78]              4            4   \n",
      "827    827   [185.44, 0.15, 1.29, 0.86]              4            4   \n",
      "828    828    [178.93, 0.17, 1.32, 0.7]              4            4   \n",
      "829    829   [174.79, 0.16, 1.36, 0.71]              4            4   \n",
      "830    830   [165.15, 0.16, 1.55, 0.69]              0            4   \n",
      "831    831   [195.68, 0.14, 1.22, 0.79]              1            4   \n",
      "832    832     [194.1, 0.23, 1.42, 0.7]              1            4   \n",
      "833    833   [193.13, 0.36, 1.89, 0.66]              4            4   \n",
      "834    834   [140.59, 0.11, 1.29, 0.81]              0            4   \n",
      "835    835   [179.43, 0.23, 1.61, 0.78]              4            4   \n",
      "836    836     [182.5, 0.15, 1.2, 0.82]              4            4   \n",
      "837    837   [230.99, 0.16, 1.54, 0.61]              2            4   \n",
      "838    838    [196.81, 0.2, 1.47, 0.66]              1            4   \n",
      "839    839   [235.45, 0.24, 1.47, 0.65]              2            2   \n",
      "840    840   [235.45, 0.24, 1.47, 0.65]              2            2   \n",
      "841    841   [159.69, 0.13, 1.47, 0.79]              0            4   \n",
      "842    842   [186.19, 0.17, 1.38, 0.55]              4            2   \n",
      "843    843   [190.06, 0.22, 1.76, 0.64]              4            4   \n",
      "844    844    [188.8, 0.25, 1.98, 0.71]              4            4   \n",
      "\n",
      "                        Label linguistique Pers  \n",
      "0         [feval_vampire_00,  papaSeverin,  20]  \n",
      "1         [feval_vampire_00,  papaSeverin,  22]  \n",
      "2     [chevalier_filledupirate_001,  pers1,  1]  \n",
      "3     [chevalier_filledupirate_001,  pers1,  3]  \n",
      "4     [chevalier_filledupirate_001,  pers1,  8]  \n",
      "5    [chevalier_filledupirate_001,  pers3,  10]  \n",
      "6    [chevalier_filledupirate_001,  pers1,  11]  \n",
      "7    [chevalier_filledupirate_001,  pers1,  15]  \n",
      "8    [chevalier_filledupirate_001,  pers5,  18]  \n",
      "9    [chevalier_filledupirate_001,  pers1,  19]  \n",
      "10   [chevalier_filledupirate_001,  pers1,  19]  \n",
      "11   [chevalier_filledupirate_001,  pers5,  20]  \n",
      "12   [chevalier_filledupirate_001,  pers1,  21]  \n",
      "13    [chevalier_filledupirate_003,  pers2,  9]  \n",
      "14   [chevalier_filledupirate_003,  pers1,  10]  \n",
      "15   [chevalier_filledupirate_003,  pers1,  12]  \n",
      "16   [chevalier_filledupirate_003,  pers7,  14]  \n",
      "17   [chevalier_filledupirate_003,  pers8,  15]  \n",
      "18   [chevalier_filledupirate_003,  pers2,  16]  \n",
      "19   [chevalier_filledupirate_003,  pers1,  17]  \n",
      "20   [chevalier_filledupirate_003,  pers2,  18]  \n",
      "21   [chevalier_filledupirate_003,  pers1,  19]  \n",
      "22   [chevalier_filledupirate_003,  pers2,  20]  \n",
      "23   [chevalier_filledupirate_003,  pers2,  20]  \n",
      "24   [chevalier_filledupirate_003,  pers1,  21]  \n",
      "25   [chevalier_filledupirate_003,  pers1,  21]  \n",
      "26   [chevalier_filledupirate_003,  pers2,  23]  \n",
      "27   [chevalier_filledupirate_003,  pers2,  23]  \n",
      "28   [chevalier_filledupirate_003,  pers1,  25]  \n",
      "29   [chevalier_filledupirate_003,  pers2,  27]  \n",
      "..                                          ...  \n",
      "815          [zeltner_contes_02_18,  chef,  82]  \n",
      "816          [zeltner_contes_02_18,  chef,  82]  \n",
      "817          [zeltner_contes_02_18,  Koli,  84]  \n",
      "818        [zeltner_contes_02_18,  vxpere,  86]  \n",
      "819        [zeltner_contes_02_18,  vxpere,  87]  \n",
      "820          [zeltner_contes_02_18,  Koli,  87]  \n",
      "821        [zeltner_contes_02_18,  vxpere,  88]  \n",
      "822          [zeltner_contes_02_18,  Koli,  90]  \n",
      "823          [zeltner_contes_02_18,  chef,  91]  \n",
      "824          [zeltner_contes_02_18,  Koli,  92]  \n",
      "825        [zeltner_contes_02_18,  vxpere,  93]  \n",
      "826          [zeltner_contes_02_18,  Koli,  94]  \n",
      "827          [zeltner_contes_02_18,  chef,  95]  \n",
      "828          [zeltner_contes_02_18,  Koli,  97]  \n",
      "829        [zeltner_contes_02_18,  vxpere,  99]  \n",
      "830     [zeltner_contes_02_18,  marchand,  101]  \n",
      "831    [zeltner_contes_02_18,  marchands,  102]  \n",
      "832    [zeltner_contes_02_18,  marchands,  104]  \n",
      "833     [zeltner_contes_02_18,  marchand,  106]  \n",
      "834     [zeltner_contes_02_18,  marchand,  108]  \n",
      "835         [zeltner_contes_02_18,  Koli,  110]  \n",
      "836        [zeltner_contes_02_18,  sofas,  111]  \n",
      "837         [zeltner_contes_02_18,  Koli,  113]  \n",
      "838    [zeltner_contes_02_18,  marchands,  115]  \n",
      "839          [zeltner_contes_02_18,  roi,  116]  \n",
      "840          [zeltner_contes_02_18,  roi,  116]  \n",
      "841    [zeltner_contes_02_18,  marchands,  118]  \n",
      "842          [zeltner_contes_02_18,  roi,  120]  \n",
      "843         [zeltner_contes_02_18,  Koli,  122]  \n",
      "844         [zeltner_contes_02_18,  Koli,  124]  \n",
      "\n",
      "[845 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloc Creation du corpus de descripteur feature annote complet : OK\n"
     ]
    }
   ],
   "source": [
    "#Creation corpus apprentissage supervise de classification\n",
    "#Reinitialisation variable bloc\n",
    "intCompteur = 0\n",
    "#Verification taille coherentes element du corpus\n",
    "print('Taille de npProsodie-->', len(npProsodie))\n",
    "print('Taille de listLabelsClusters-->', len(listLabelsClusters))\n",
    "print('Taille de listLabelPers-->', len(listLabelPers))\n",
    "print('dicoPersClusters-->', dicoPersClusters)\n",
    "#Essai Vérification\n",
    "print('listLabelPers[intCompteur][intPosIdPers]--> ', listLabelPers[intCompteur][intPosIdPers])\n",
    "#initialisation des variable avant la boucle\n",
    "intCompteur = 0\n",
    "npProsodieAnoteComplet = []\n",
    "\n",
    "for vectSegment in npProsodie :\n",
    "    #Boucle de parcours des segments, vecteur composant le corpus npProsodie\n",
    "    #Creation du vecteur listVectSegAnotComplet, segment annote de label donnant la composition suivante :\n",
    "    # IdSeg, npProsodie[IdSeg], listLabelsClusters[idSeg], Id de cluster majoritaire pour Pers-classe de Pers, \n",
    "    #listLabelPers avec idPers\n",
    "    #Reinitialisation des variables\n",
    "    listVectSegAnotComplet = []\n",
    "    #Construction du vecteur listVectSegAnotComplet\n",
    "    #Determination Id complet de Pers courant\n",
    "    #print('blocage')\n",
    "    if strTypeGroupe == 'PersGroupGrNarNonNar' :\n",
    "        #Verification modele Pers Oeuvre sans espace point\n",
    "        strIdCompletPersCour = listLabelPers[intCompteur][intPosIdOeuvre] + '.' + listLabelPers[intCompteur][intPosIdPers]\n",
    "    else :\n",
    "        #Decoupage nom oeuvre\n",
    "        strNomOeuvre = listLabelPers[intCompteur][intPosIdOeuvre]\n",
    "        listComposeNomOeuvre = strNomOeuvre.split(strSepIntOeuvre)\n",
    "        strNomOeuvre = listComposeNomOeuvre[intPosAuteur] + strSepIntOeuvre + listComposeNomOeuvre[intPosTitreOeuvre]\n",
    "        strIdCompletPersCour = strNomOeuvre + '.' + listLabelPers[intCompteur][intPosIdPers]\n",
    "\n",
    "    #print('strIdCompletPersCour--> ', strIdCompletPersCour)\n",
    "    \n",
    "    #Determination du cluster majoritaire pour le Pers du segment courant\n",
    "    intIdClusterMagoritaire = belongToCluster(strIdCompletPersCour, dicoPersClusters)\n",
    "    #print('intIdClusterMagoritaire-->', intIdClusterMagoritaire)\n",
    "    #Ajout des element constitutifs du vecteur\n",
    "    listVectSegAnotComplet.append(intCompteur)\n",
    "    listVectSegAnotComplet.append(vectSegment)\n",
    "    listVectSegAnotComplet.append(listLabelsClusters[intCompteur])\n",
    "    \n",
    "    #Verification erreur bloc fonction\n",
    "    #if listLabelsClusters[intCompteur] == 1 :\n",
    "        #Verification > 1 classe\n",
    "     #   print('Classe 1 a index-->', intCompteur)\n",
    "    \n",
    "    listVectSegAnotComplet.append(intIdClusterMagoritaire)\n",
    "    listVectSegAnotComplet.append(listLabelPers[intCompteur])\n",
    "    #Ajout du vecteur listVectSegAnotComplet au corpus npProsodieAnoteComplet et ajout pour passage boucle\n",
    "    npProsodieAnoteComplet.append(listVectSegAnotComplet)\n",
    "    intCompteur = intCompteur +1\n",
    "    \n",
    "#Verification taille et premiere ligne de npProsodieAnoteComplet\n",
    "print('Taille de npProsodieAnoteComplet-->', len(npProsodieAnoteComplet))\n",
    "#print('npProsodieAnoteComplet[:][2]-->', npProsodieAnoteComplet[:][2])\n",
    "#print('npProsodieAnoteComplet-->', npProsodieAnoteComplet)       \n",
    "\n",
    "#Pretraitement de sauvegade\n",
    "#Tableau Pandas DataFrame\n",
    "listColumnsDF04 = ['IdSeg', strFeatureUsed]\n",
    "listColumnsDF04.append('Cluster Kmean')\n",
    "listColumnsDF04.append('Classe Pers')\n",
    "listColumnsDF04.append('Label linguistique Pers')\n",
    "print('listColumnsDF04-->', listColumnsDF04)\n",
    "\n",
    "#DataFrame\n",
    "dfCorpusRes = pd.DataFrame(npProsodieAnoteComplet, columns = listColumnsDF04)\n",
    "\n",
    "#Affichage\n",
    "print('Nom fichier sauvegarde CSV avec Corpus de Resultat -->')\n",
    "print(pwdFileCorpusResCsv)\n",
    "print('dataframe dfCorpusRes -->')\n",
    "print(dfCorpusRes)\n",
    "\n",
    "#Sauvegarde\n",
    "dfCorpusRes.to_csv(pwdFileCorpusResCsv, sep=\"\\t\", encoding=\"utf-8\", index=False )\n",
    "dfCorpusRes.to_excel(pwdFileCorpusResExcel, index=False)\n",
    "\n",
    "print('Bloc Creation du corpus de descripteur feature annote complet : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Creation corpus train et test pour la SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation classe dico dictClasseSVM\n",
      "Creation classe dico dictClasseSVM\n",
      "Creation classe dico dictClasseSVM\n",
      "Creation classe dico dictClasseSVM\n",
      "Taille de corpusSVM--> 568\n",
      "listIdClasseSVM--> [0, 4, 1, 2]\n",
      "Nombre de classe intNbClasseSVM--> 6\n",
      "corpusSVM[2]--> [array([3.3501e+02, 2.5000e-01, 1.2100e+00, 4.2000e-01]), 0]\n",
      "Bloc Creation corpus train et test pour la SVM : OK\n"
     ]
    }
   ],
   "source": [
    "#Fonction utilisees en annexe\n",
    "#dictPersSupSeuil = builtDicoTamisPoidsPers(dicoPersCluPreRap, intNbClusters, intSeuilNbSeg)\n",
    "#Reinitialisation des variables avant boucle\n",
    "corpusSVM =[]\n",
    "listVectCourSVM =[]\n",
    "dictClasseSVM = {}\n",
    "listIdClasseSVM = []\n",
    "intNbClasseSVM = 0\n",
    "intCompteur =0\n",
    "intRapportAdaptClasse = -1\n",
    "\n",
    "for listVectSegAnotComplet in npProsodieAnoteComplet :\n",
    "    #Boucle parcours npProsodieAnoteComplet\n",
    "    #Determination Id complet de Pers courant\n",
    "    strIdCompletPersCour = listVectSegAnotComplet[intPosLabelPers][intPosIdOeuvre] + '. ' + listVectSegAnotComplet[intPosLabelPers][intPosIdPers]\n",
    "    if strTypeGroupe == 'PersGroupGrNarNonNar' :\n",
    "        #Verification modele Pers Oeuvre sans espace point\n",
    "        strIdCompletPersCour = listVectSegAnotComplet[intPosLabelPers][intPosIdOeuvre] + '.' + listVectSegAnotComplet[intPosLabelPers][intPosIdPers]\n",
    "    else :\n",
    "        #Decoupage nom oeuvre\n",
    "        strNomOeuvre = listVectSegAnotComplet[intPosLabelPers][intPosIdOeuvre]\n",
    "        listComposeNomOeuvre = strNomOeuvre.split(strSepIntOeuvre)\n",
    "        strNomOeuvre = listComposeNomOeuvre[intPosAuteur] + strSepIntOeuvre + listComposeNomOeuvre[intPosTitreOeuvre]\n",
    "        strIdCompletPersCour = strNomOeuvre + '.' + listVectSegAnotComplet[intPosLabelPers][intPosIdPers]\n",
    "    #Verification Pers courant depasse seuil personnage notable dans recit avec dictPersSupSeuil\n",
    "    if strIdCompletPersCour in dictPersSupSeuil :\n",
    "        #Ajout mention persoonage notable dans tableau des data de tous les segments annotes \n",
    "        listVectSegAnotComplet.append('Oui')\n",
    "        #Ajout au corpus pour la SVM du vecteur nececessaire listVectCourSVM\n",
    "        \n",
    "        #Determination de la classe pour SVM du segment courant listVectSegAnotComplet\n",
    "        if strTypeGroupe == 'PersGroupGrNarNonNar' :\n",
    "            #Dans ce cas Narrateur et Non narrateur ont le meme cluster majoritaire; donc la classe est le cluster du\n",
    "            #KMeans, nomme Label de Cluster qui est contenu dans la listLabelsClusters\n",
    "            intIdClasseSVM =listVectSegAnotComplet[intPosLabelCluster]\n",
    "        else :\n",
    "            #Le cluster majoritaire du Pers est sa classe\n",
    "            intIdClasseSVM = listVectSegAnotComplet[intPosClusMaj]\n",
    "        \n",
    "        #Reinitialisation du vecteur listVectCourSVM\n",
    "        listVectCourSVM =[]\n",
    "        #Composition du vecteur listVectCourSVM avec le descripteur et la classe-cluster majoritaire du Pers du segment\n",
    "        listVectCourSVM.append(listVectSegAnotComplet[intPosFeatProsodie])\n",
    "        listVectCourSVM.append(intIdClasseSVM)\n",
    "        \n",
    "        #Ajout au corpus corpusSVM\n",
    "        corpusSVM.append(listVectCourSVM)\n",
    "        \n",
    "        #Mise a jour du dico des occurences des classes pour le classifieur SVM dans apprentissage supervise\n",
    "        #Adoption de la key courante du dico des classe pour svm par la classe du segment courant\n",
    "        keyClasse = intIdClasseSVM\n",
    "        #Verification si presence de la classe\n",
    "        if keyClasse in dictClasseSVM :\n",
    "            #Mise a jour des occurences du cluster pour le personnage\n",
    "            dictClasseSVM[keyClasse] +=1\n",
    "        else :\n",
    "            #Creation entree de la nouvelle classe pour le dico des classe\n",
    "            print('Creation classe dico dictClasseSVM')\n",
    "            dictClasseSVM[keyClasse] =1\n",
    "    \n",
    "    else :\n",
    "        #Ajout mention personnage non notable\n",
    "        listVectSegAnotComplet.append('Non')\n",
    "    \n",
    "#Creation liste des id des classes pour apprentissage supervise classifieur SVM \n",
    "listIdClasseSVM = list(dictClasseSVM.keys())\n",
    "intNbClasseSVM = len(listIdClasseSVM)\n",
    "#Verification si nb cluter > nb classes\n",
    "if intNbClasseSVM < intNbClusters :\n",
    "    #Adaptation Id Classe SVM\n",
    "    try :\n",
    "        #Test division par zero\n",
    "        intRapportAdaptClasse = intNbClasseSVM / intNbClusters\n",
    "    except :\n",
    "        print('Division par 0, retour intRapportAdaptClasse = -1 ')\n",
    "        intRapportAdaptClasse = -1\n",
    "    #Correspondance simplifiee si garde meme nb classe que clusters avec classe vide\n",
    "    intNbClasseSVM = intNbClusters\n",
    "\n",
    "#Verification taille et premiere ligne de npProsodieAnoteComplet\n",
    "print('Taille de corpusSVM-->', len(corpusSVM))\n",
    "print('listIdClasseSVM-->', listIdClasseSVM)\n",
    "print('Nombre de classe intNbClasseSVM-->',intNbClasseSVM)\n",
    "print('corpusSVM[2]-->', corpusSVM[2])\n",
    "\n",
    "print('Bloc Creation corpus train et test pour la SVM : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Decoupage des Donnees - Splitting Data\n",
    "X : descripteur.data; y : descripteur.target - X_train; X_test; y_train; y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloc Decoupage Données : OK\n"
     ]
    }
   ],
   "source": [
    "#Reinitialisation des variables avant boucle\n",
    "descripteurData = []\n",
    "descripteurTarget = []\n",
    "for vectData in corpusSVM :\n",
    "    #Boucle de split dans ls listes data et target - donnees et classes cibles\n",
    "    descripteurData.append(vectData[intPosDesData])\n",
    "    descripteurTarget.append(vectData[intPosDesTarget])\n",
    "    \n",
    "#Decoupage du dataset en set de train et set de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(descripteurData, descripteurTarget, random_state=0)\n",
    "\n",
    "#print('y_train-->', y_train)\n",
    "#print('y_test', y_test)\n",
    "\n",
    "print('Bloc Decoupage Données : OK')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Genaration Modele SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predict--> [1 2 4 1 1 4 1 4 4 1 1 2 4 4 2 4 1 4 1 2 4 4 1 4 4 4 4 4 4 1 4 2 1 1 4 4 1\n",
      " 4 4 1 4 4 1 4 1 4 4 1 4 4 4 4 1 1 1 4 4 1 4 4 4 4 1 4 4 4 4 2 4 4 1 4 2 4\n",
      " 4 2 4 4 4 1 1 1 4 4 4 1 2 1 2 4 4 4 4 1 4 1 4 4 4 4 4 1 4 4 1 4 4 4 1 4 4\n",
      " 4 4 4 1 1 4 1 4 1 4 4 4 1 1 4 4 4 1 4 4 4 1 1 1 4 4 4 4 4 4 4]\n",
      "len(y_predict)--> 142\n",
      "Bloc Genaration Modele SVM : OK\n"
     ]
    }
   ],
   "source": [
    "#Genaation du modele\n",
    "clf = svm.SVC(kernel='linear') #Kernel lineai du modele\n",
    "\n",
    "#Entrainement du modele avec les donnees d entrainement\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Prediction par le modele de la classe de Pers sur le set de test (30% du corpus des segments)\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "print('y_predict-->', y_predict)\n",
    "print('len(y_predict)-->', len(y_predict))\n",
    "\n",
    "print('Bloc Genaration Modele SVM : OK')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Tableau Analyse Modele SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialisation listTabAnalyseSVM--> [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
      "Taille des set identique pour SVM intTailleSetAnalyseSVM--> 142\n",
      "analyse effectuee : Liste tableau listTabAnalyseSVM--> [[0, 0, 0, 0, 0, 0], [4, 12, 8, 0, 19, 0], [1, 4, 5, 0, 0, 0], [0, 0, 0, 0, 0, 0], [17, 34, 9, 0, 29, 0], [0, 0, 0, 0, 0, 0]]\n",
      "listTabPourcentSVM--> [[0, 0, 0, 0, 0, 0], [3, 8, 6, 0, 13, 0], [1, 3, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0], [12, 24, 6, 0, 20, 0], [0, 0, 0, 0, 0, 0]]\n",
      "Bloc Tableau Analyse Modele SVM : OK\n"
     ]
    }
   ],
   "source": [
    "#Creation tableau : \n",
    "#Horizontal entete colonne : classe par y_test, issu kmeans clustering\n",
    "#Verticale entete ligne : classe par y_predict, issu SVM classification\n",
    "# Pour Groupe Narrateur - Non narrateur, le cluster majoritaire est le meme pour les Narrateur et les Non narrateur\n",
    "# La classe des Pers est donc celle des labels de cluster par Kmeans et non le cluster majoritaire du personnage\n",
    "\n",
    "#Reinitialisation variable bloc\n",
    "intCompteur = 0\n",
    "intIndexLigTabSVM = 0\n",
    "intIndexColTabSVM = 0\n",
    "#Variable de structure du tableau analyse du modele SVM\n",
    "listTabAnalyseSVM =[[0] * intNbClasseSVM for _ in range(intNbClasseSVM)]\n",
    "#Verification structure tableau et coherence taille des set\n",
    "print('initialisation listTabAnalyseSVM-->', listTabAnalyseSVM)\n",
    "if(len(y_test) == len(y_predict)) :\n",
    "    #Si taille identique des deux set\n",
    "    intTailleSetAnalyseSVM = len(y_predict)\n",
    "else :\n",
    "    #Taille non identique, set non comparables\n",
    "    intTailleSetAnalyseSVM = -1\n",
    "\n",
    "print('Taille des set identique pour SVM intTailleSetAnalyseSVM-->', intTailleSetAnalyseSVM)\n",
    "\n",
    "for index in y_test :\n",
    "    #Boucle de parcours de classe correcte du set de test de apprentissage\n",
    "    intIndexLigTabSVM = y_predict[intCompteur]\n",
    "    intIndexColTabSVM = y_test[intCompteur]\n",
    "    #Remplissage cellule du tableau analyse SVM listTabAnalyseSVM\n",
    "    listTabAnalyseSVM[intIndexLigTabSVM][intIndexColTabSVM] +=1\n",
    "    \n",
    "    #Augmention compteur\n",
    "    intCompteur = intCompteur + 1\n",
    "    \n",
    "#Affichage Tableau Analyse SVM Effectuee\n",
    "print('analyse effectuee : Liste tableau listTabAnalyseSVM-->', listTabAnalyseSVM)\n",
    "\n",
    "#Transformation Pourcentage tableau\n",
    "#Reinitialisation des variable avant boucle\n",
    "listTabPourcentSVM = deepcopy(listTabAnalyseSVM)\n",
    "intIndexLigTabSVM = 0\n",
    "intIndexColTabSVM = 0\n",
    "#Calcul proportion pour obtenir pourcentage sous forme nombre entier\n",
    "floatProportPourcent = 100/intTailleSetAnalyseSVM\n",
    "\n",
    "for ligTab in listTabAnalyseSVM :\n",
    "    #Reinitialisitation index colonne\n",
    "    intIndexColTabSVM = 0\n",
    "    #Boucle parcours ligne de tableau\n",
    "    for colTab in ligTab :\n",
    "        #Boucle parcours colonnes de tableau\n",
    "        #Calcul pourcentage cellule courante\n",
    "        intCellTabPourcent = int(round((colTab * floatProportPourcent), 0))\n",
    "        #Ajout du pourcentage dans le tableau des poucentage\n",
    "        listTabPourcentSVM[intIndexLigTabSVM][intIndexColTabSVM] = intCellTabPourcent\n",
    "        #Incrementation index colonnes\n",
    "        intIndexColTabSVM = intIndexColTabSVM + 1\n",
    "    #Incrementation index lignes\n",
    "    intIndexLigTabSVM = intIndexLigTabSVM + 1\n",
    "    \n",
    "print('listTabPourcentSVM-->', listTabPourcentSVM)\n",
    "\n",
    "print('Bloc Tableau Analyse Modele SVM : OK')\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Evaluation Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.323943661971831\n",
      "listColumnsDF05--> ['C0', 'C1', 'C2', 'C3', 'C4', 'C5']\n",
      "listColumnsDF06--> ['C0', 'C1', 'C2', 'C3', 'C4', 'C5']\n",
      "Nom fichier sauvegarde CSV avec Pourcent SVM Classique -->\n",
      "./ResultatNoteBook/TestBrouillon/TabClassSVMEnPourcent6_PourcentRep_PersGroupNonNarrateur_F0_ensemble_oeuvres.csv\n",
      "dataframe dfPourcentClassSVM -->\n",
      "   C0  C1  C2  C3  C4  C5\n",
      "0   0   0   0   0   0   0\n",
      "1   3   8   6   0  13   0\n",
      "2   1   3   4   0   0   0\n",
      "3   0   0   0   0   0   0\n",
      "4  12  24   6   0  20   0\n",
      "5   0   0   0   0   0   0\n",
      "Bloc Evaluation Modele : OK\n"
     ]
    }
   ],
   "source": [
    "#Model Accuracy\n",
    "# Justesse, exactitude ou precision de la prediction du modele appris\n",
    "#Combien de fois le modele a fait une prediction correcte\n",
    "accurancyModel = metrics.accuracy_score(y_test, y_predict)\n",
    "print('Accuracy : ', accurancyModel)\n",
    "\n",
    "#Pretraitement Sauvergarde\n",
    "#Tableaux Pandas DataFrame segment et pourcent\n",
    "listColumnsDF05 = []\n",
    "listColumnsDF06 = []\n",
    "for numCluster in range(intNbClusters) :\n",
    "    listColumnsDF05.append(str('C' + str(numCluster)))\n",
    "    listColumnsDF06.append(str('C' + str(numCluster)))\n",
    "print('listColumnsDF05-->', listColumnsDF05)\n",
    "print('listColumnsDF06-->', listColumnsDF06)\n",
    "\n",
    "#Union du tableau des segment a la liste accurancy du model\n",
    "#listTabAnalyseSVM.append([accurancyModel])\n",
    "#Transformation\n",
    "\n",
    "#DataFrame\n",
    "#dfClassSVM = pd.DataFrame(listTabAnalyseSVM, columns = listColumnsDF05)\n",
    "dfPourcentClassSVM = pd.DataFrame(listTabPourcentSVM, columns = listColumnsDF06)\n",
    "\n",
    "#Affichage\n",
    "#print('Nom fichier sauvegarde CSV avec SVM Classique -->')\n",
    "#print(pwdFileMatriceClassSvmCsv)\n",
    "print('Nom fichier sauvegarde CSV avec Pourcent SVM Classique -->')\n",
    "print(pwdFileMatricePourcentClassSvmCsv)\n",
    "#print('dataframe dfClassSVM -->')\n",
    "#print(dfClassSVM)\n",
    "print('dataframe dfPourcentClassSVM -->')\n",
    "print(dfPourcentClassSVM)\n",
    "\n",
    "#Sauvegarde\n",
    "#dfClassSVM.to_csv(pwdFileMatriceClassSvmCsv, sep=\"\\t\", encoding=\"utf-8\", index=False )\n",
    "dfPourcentClassSVM.to_csv(pwdFileMatricePourcentClassSvmCsv, sep=\"\\t\", encoding=\"utf-8\", index=False )\n",
    "#dfPersClustersIndEval.to_excel(pwdFileMatricePersClustersIndEvalExcel, index=False)\n",
    "\n",
    "print('Bloc Evaluation Modele : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Cross-Validation SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Entrainement en Cross Validation et Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.51832461 0.27894737 0.36898396]\n",
      "predictions--> [2 2 2 2 2 4 4 2 0 0 1 4 0 0 4 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 1 4 1 1\n",
      " 1 4 1 4 1 4 1 1 4 4 0 1 0 1 4 1 4 1 4 0 0 4 0 4 1 0 4 0 0 4 0 4 1 4 4 4 1\n",
      " 4 4 4 4 1 4 4 4 1 4 1 4 4 0 1 2 2 4 4 4 4 1 4 0 1 0 4 4 4 1 0 1 4 4 4 4 4\n",
      " 4 4 4 4 4 0 0 4 0 1 4 4 1 1 4 1 0 1 4 4 4 1 4 4 4 4 4 4 4 0 0 1 1 4 4 1 0\n",
      " 2 1 4 4 0 4 4 4 4 4 4 4 1 4 4 4 1 4 1 4 4 4 1 4 4 4 4 4 4 4 4 4 1 1 4 4 4\n",
      " 4 4 4 4 1 4 4 4 1 1 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 1 1 1 4 4 1 1 4 4 4 0\n",
      " 4 1 1 4 4 0 0 4 4 4 4 0 1 1 4 4 2 2 4 2 4 2 4 2 2 4 4 2 2 1 1 0 2 1 1 4 4\n",
      " 4 4 1 1 1 2 2 4 1 4 1 4 4 4 1 1 4 4 1 1 1 1 1 4 4 1 1 1 1 0 4 1 1 4 4 4 1\n",
      " 1 4 1 1 1 1 1 1 1 0 1 2 2 4 0 0 4 4 4 1 1 1 1 4 2 2 4 1 1 1 1 1 1 0 0 0 0\n",
      " 1 1 0 0 1 1 1 1 1 1 4 4 1 0 1 4 4 4 4 1 1 2 4 4 4 4 4 4 4 4 4 4 1 1 4 4 0\n",
      " 4 4 4 4 4 4 4 4 1 4 1 4 1 4 1 4 1 4 1 4 1 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 0\n",
      " 0 1 1 4 4 4 4 4 4 4 4 4 4 4 1 1 1 4 4 4 1 1 1 4 4 4 4 0 0 0 0 4 4 4 4 4 1\n",
      " 1 1 4 4 4 1 1 4 4 4 1 4 4 2 2 1 1 4 1 1 1 1 1 1 4 4 4 4 1 1 4 4 4 4 1 1 1\n",
      " 1 1 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 4 4 1 4 4 4 4 4 4 1 4 4 4 4 4\n",
      " 4 4 4 1 1 1 1 4 4 4 4 2 2 4 4 1 4 1 1 4 4 4 4 1 4 4 4 4 1 1 4 4 4 4 4 4 1\n",
      " 4 4 1 1 1 4 1 4 4 4 1 4 4]\n",
      "len(predictions) 568\n",
      "Bloc Entrainement en Cross Validation et Scoring : OK\n"
     ]
    }
   ],
   "source": [
    "#Entrainements du modele en cross validation et evalution par score\n",
    "scores = cross_val_score(clf, descripteurData, descripteurTarget)\n",
    "print('Cross-validation scores: {}'.format(scores))\n",
    "\n",
    "#Prediction du modele entrainer en cross validation\n",
    "predictions = cross_val_predict(clf, descripteurData, descripteurTarget)\n",
    "\n",
    "print('predictions-->', predictions)\n",
    "print('len(predictions)', len(predictions))\n",
    "\n",
    "print('Bloc Entrainement en Cross Validation et Scoring : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Tableau Analyse Modele SVM Entrainee par Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialisation listTabAnalyseCrossValSVM--> [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
      "Taille des set identique pour SVM intTailleSetAnalyseCossValSVM--> 568\n",
      "intCompteur--> 568\n",
      "analyse effectuee : Liste tableau cross Validation listTabAnalyseCrossValSVM--> [[30, 15, 2, 0, 19, 0], [17, 54, 35, 0, 60, 0], [6, 7, 16, 0, 0, 0], [0, 0, 0, 0, 0, 0], [50, 112, 24, 0, 121, 0], [0, 0, 0, 0, 0, 0]]\n",
      "listTabPourcentCrossValSVM--> [[5, 3, 0, 0, 3, 0], [3, 10, 6, 0, 11, 0], [1, 1, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0], [9, 20, 4, 0, 21, 0], [0, 0, 0, 0, 0, 0]]\n",
      "listColumnsDF07--> ['C0', 'C1', 'C2', 'C3', 'C4', 'C5']\n",
      "listColumnsDF08--> ['C0', 'C1', 'C2', 'C3', 'C4', 'C5']\n",
      "dataframe dfPourcentCrossValSVM -->\n",
      "   C0  C1  C2  C3  C4  C5\n",
      "0   5   3   0   0   3   0\n",
      "1   3  10   6   0  11   0\n",
      "2   1   1   3   0   0   0\n",
      "3   0   0   0   0   0   0\n",
      "4   9  20   4   0  21   0\n",
      "5   0   0   0   0   0   0\n",
      "Bloc Tableau Analyse Modele SVM Entrainee par Cross-Validation : OK\n",
      "Bloc Cross Validation SVM : OK\n"
     ]
    }
   ],
   "source": [
    "#Creation tableau : \n",
    "#Horizontal entete colonne : classe par descripteurTarget, issu kmeans clustering\n",
    "#Verticale entete ligne : classe par predictions, issu SVM classification\n",
    "# Pour Groupe Narrateur - Non narrateur, le cluster majoritaire est le meme pour les Narrateur et les Non narrateur\n",
    "# La classe des Pers est donc celle des labels de cluster par Kmeans et non le cluster majoritaire du personnage\n",
    "\n",
    "#Reinitialisation variable bloc\n",
    "intCompteur = 0\n",
    "intIndexLigTabSVM = 0\n",
    "intIndexColTabSVM = 0\n",
    "#Variable de structure du tableau analyse du modele SVM\n",
    "\n",
    "listTabAnalyseCrossValSVM =[[0] * intNbClasseSVM for _ in range(intNbClasseSVM)]\n",
    "#Verification structure tableau et coherence taille des set\n",
    "print('initialisation listTabAnalyseCrossValSVM-->', listTabAnalyseCrossValSVM)\n",
    "if(len(descripteurTarget) == len(predictions)) :\n",
    "    #Si taille identique des deux set\n",
    "    intTailleSetAnalyseCossValSVM = len(predictions)\n",
    "else :\n",
    "    #Taille non identique, set non comparables\n",
    "    print('set non comparable')\n",
    "    intTailleSetAnalyseCossValSVM = -1\n",
    "\n",
    "print('Taille des set identique pour SVM intTailleSetAnalyseCossValSVM-->', intTailleSetAnalyseCossValSVM)\n",
    "#print('listTabAnalyseCrossValSVM-->', listTabAnalyseCrossValSVM)\n",
    "\n",
    "for index in descripteurTarget :\n",
    "    #Boucle de parcours de classe correcte du set de test de apprentissage\n",
    "    intIndexLigTabSVM = predictions[intCompteur]\n",
    "    intIndexColTabSVM = descripteurTarget[intCompteur]\n",
    "    #Remplissage cellule du tableau analyse SVM listTabAnalyseSVM\n",
    "    listTabAnalyseCrossValSVM[intIndexLigTabSVM][intIndexColTabSVM] +=1\n",
    "    \n",
    "    #Verification du bloc fonction\n",
    "    #print('listTabAnalyseCrossValSVM-->', listTabAnalyseCrossValSVM)\n",
    "    \n",
    "    #Augmention compteur\n",
    "    intCompteur = intCompteur + 1\n",
    "\n",
    "print('intCompteur-->', intCompteur)\n",
    "#Affichage Tableau Analyse SVM Effectuee\n",
    "print('analyse effectuee : Liste tableau cross Validation listTabAnalyseCrossValSVM-->', listTabAnalyseCrossValSVM)\n",
    "\n",
    "#Transformation Pourcentage tableau\n",
    "#Reinitialisation des variable avant boucle\n",
    "listTabPourcentCrossValSVM = deepcopy(listTabAnalyseCrossValSVM)\n",
    "intIndexLigTabSVM = 0\n",
    "intIndexColTabSVM = 0\n",
    "#Calcul proportion pour obtenir pourcentage sous forme nombre entier\n",
    "floatProportPourcent = 100/intTailleSetAnalyseCossValSVM\n",
    "\n",
    "for ligTab in listTabAnalyseCrossValSVM :\n",
    "    \n",
    "    #Reinitialisitation index colonne\n",
    "    intIndexColTabSVM = 0\n",
    "    #Boucle parcours ligne de tableau\n",
    "    for colTab in ligTab :\n",
    "        #Boucle parcours colonnes de tableau\n",
    "        #Calcul pourcentage cellule courante\n",
    "        intCellTabPourcent = int(round((colTab * floatProportPourcent), 0))\n",
    "        #Ajout du pourcentage dans le tableau des poucentage\n",
    "        listTabPourcentCrossValSVM[intIndexLigTabSVM][intIndexColTabSVM] = intCellTabPourcent\n",
    "        #Incrementation index colonnes\n",
    "        intIndexColTabSVM = intIndexColTabSVM + 1\n",
    "    #Incrementation index lignes\n",
    "    intIndexLigTabSVM = intIndexLigTabSVM + 1\n",
    "    \n",
    "print('listTabPourcentCrossValSVM-->', listTabPourcentCrossValSVM)\n",
    "\n",
    "#Pretraitement de sauvegarde\n",
    "#Tableaux Pandas DataFrame segment et pourcent\n",
    "listColumnsDF07 = []\n",
    "listColumnsDF08 = []\n",
    "for numCluster in range(intNbClusters) :\n",
    "    listColumnsDF07.append(str('C' + str(numCluster)))\n",
    "    listColumnsDF08.append(str('C' + str(numCluster)))\n",
    "print('listColumnsDF07-->', listColumnsDF07)\n",
    "print('listColumnsDF08-->', listColumnsDF08)\n",
    "\n",
    "#Union du tableau des segment a la liste accurancy du model\n",
    "listTabAnalyseCrossValSVM.append(scores)\n",
    "\n",
    "#DataFrame\n",
    "#dfCrossValSVM = pd.DataFrame(listTabAnalyseCrossValSVM, columns = listColumnsDF07)\n",
    "dfPourcentCrossValSVM = pd.DataFrame(listTabPourcentCrossValSVM, columns = listColumnsDF08)\n",
    "\n",
    "#Affichage\n",
    "#print('Nom fichier sauvegarde CSV avec SVM Cross-Validation -->')\n",
    "#print(pwdFileMatriceCrossValSvmCsv)\n",
    "#print('Nom fichier sauvegarde CSV avec Pourcent SVM Cross-Validation -->')\n",
    "#print(pwdFileMatricePourcentCrossValSvmCsv)\n",
    "#print('dataframe dfCrossValSVM -->')\n",
    "#print(dfCrossValSVM)\n",
    "print('dataframe dfPourcentCrossValSVM -->')\n",
    "print(dfPourcentCrossValSVM)\n",
    "\n",
    "#Sauvegarde\n",
    "#dfCrossValSVM.to_csv(pwdFileMatriceCrossValSvmCsv, sep=\"\\t\", encoding=\"utf-8\", index=False )\n",
    "dfPourcentCrossValSVM.to_csv(pwdFileMatricePourcentCrossValSvmCsv, sep=\"\\t\", encoding=\"utf-8\", index=False )\n",
    "#dfPersClustersIndEval.to_excel(pwdFileMatricePersClustersIndEvalExcel, index=False)\n",
    "\n",
    "print('Bloc Tableau Analyse Modele SVM Entrainee par Cross-Validation : OK')\n",
    "print('Bloc Cross Validation SVM : OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bloc ExpCours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Fermeture Fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouverture individuelle non valide -> ouverture ensemble de fichiers\n",
      "Bloc Fermeture Fichier : OK\n"
     ]
    }
   ],
   "source": [
    "#Instruction de fermeture\n",
    "try :\n",
    "    fo.close()\n",
    "except :\n",
    "    print('Ouverture individuelle non valide -> ouverture ensemble de fichiers')\n",
    "    \n",
    "print('Bloc Fermeture Fichier : OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bloc Elsa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.Image object>\n",
      "Bloc Elsa : OK\n"
     ]
    }
   ],
   "source": [
    "imageElsa=ImgPIL.open(\"./ressources/imagesElsa001.jpeg\")\n",
    "imageElsa.show()\n",
    "imageV02Elsa=Image(\"./ressources/imagesElsa001.jpeg\")\n",
    "display(imageV02Elsa)\n",
    "print(imageV02Elsa)\n",
    "\n",
    "print('Bloc Elsa : OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
